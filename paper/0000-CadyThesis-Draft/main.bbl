% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{nyt/global//global/global}
    \entry{agrawalLearningWhenTrust2023}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=bfdf7cfed2931b695b0ec2d70a3331a4}{%
           family={Agrawal},
           familyi={A\bibinitperiod},
           given={Aakriti},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4558f7f2d9343618f380fdda2279e321}{%
           family={Rao},
           familyi={R\bibinitperiod},
           given={Milind},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=230b471a7c8c406b360a8044fe687eba}{%
           family={Sahu},
           familyi={S\bibinitperiod},
           given={Anit\bibnamedelima Kumar},
           giveni={A\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1a7c4a4ef0b592c66e33bea9fc2106d8}{%
           family={Chennupati},
           familyi={C\bibinitperiod},
           given={Gopinath},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8b60cd3ee633c8d1d585f08b92fefbf4}{%
           family={Stolcke},
           familyi={S\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{0ca54fbd7d16b1891b65f8a017e4bef7}
      \strng{fullhash}{61a2049bce9601e1a5b4be983d986970}
      \strng{bibnamehash}{61a2049bce9601e1a5b4be983d986970}
      \strng{authorbibnamehash}{61a2049bce9601e1a5b4be983d986970}
      \strng{authornamehash}{0ca54fbd7d16b1891b65f8a017e4bef7}
      \strng{authorfullhash}{61a2049bce9601e1a5b4be983d986970}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Automatic speech recognition (ASR) training can utilize multiple experts as teacher models, each trained on a specific domain or accent. Teacher models may be opaque in nature since their architecture may be not be known or their training cadence is different from that of the student ASR model. Still, the student models are updated incrementally using the pseudo-labels generated independently by the expert teachers. In this paper, we exploit supervision from multiple domain experts in training student ASR models. This training strategy is especially useful in scenarios where few or no human transcriptions are available. To that end, we propose a Smart-Weighter mechanism that selects an appropriate expert based on the input audio, and then trains the student model in an unsupervised setting. We show the efficacy of our approach using LibriSpeech and LibriLight benchmarks and find an improvement of 4 to 25\% over baselines that uniformly weight all the experts, use a single expert model, or combine experts using ROVER.}
      \field{booktitle}{{{INTERSPEECH}} 2023}
      \field{day}{20}
      \field{eventtitle}{{{INTERSPEECH}} 2023}
      \field{langid}{english}
      \field{month}{8}
      \field{title}{Learning {{When}} to {{Trust Which Teacher}} for {{Weakly Supervised ASR}}}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{381\bibrangedash 385}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2023-2205
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/LCGXDWE2/Agrawal et al. - 2023 - Learning When to Trust Which Teacher for Weakly Supervised ASR.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2023/agrawal23_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2023/agrawal23_interspeech.html
      \endverb
    \endentry
    \entry{alrashoudiImprovingMispronunciationDetection2025}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=6efbf84aae11e577a617ca2fbed0a566}{%
           family={Alrashoudi},
           familyi={A\bibinitperiod},
           given={Norah},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9bf3d74523ad71f3cd87991dcc3d9b00}{%
           family={Al-Khalifa},
           familyi={A\bibinithyphendelim K\bibinitperiod},
           given={Hend},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d2991ec516951c68a1fbb544b3cc34f0}{%
           family={Alotaibi},
           familyi={A\bibinitperiod},
           given={Yousef},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{26565a89146ab29d2c55777ccc14f6be}
      \strng{fullhash}{76d92e68cb3f8dda1e99b697f5545959}
      \strng{bibnamehash}{76d92e68cb3f8dda1e99b697f5545959}
      \strng{authorbibnamehash}{76d92e68cb3f8dda1e99b697f5545959}
      \strng{authornamehash}{26565a89146ab29d2c55777ccc14f6be}
      \strng{authorfullhash}{76d92e68cb3f8dda1e99b697f5545959}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Mispronunciation detection and diagnosis (MDD) is a core component of computer-assisted pronunciation training (CAPT), which aims to provide opportunities for second language learners (L2) to learn and practice their speaking skills. Arabic is one of the most widespread languages in the world, with more than 422 million speakers. It is the language of the Holy Quran, which increases the importance of learning Arabic. Most existing Arabic MDD systems focus on learningbased techniques rather than state-of-the-art deep-learning methods. Most existing Arabic MDD systems are primarily relying on traditional learning techniques. However, integrating Transformer-based algorithms into the system is crucial, as it can significantly enhance the accuracy, efficiency, and overall performance of the Arabic MDD systems. This paper introduces an Arabic MDD system using transformer-based techniques for non-native learners of spoken Arabic language to enhance their learning of Arabic and help non-native speakers practice their pronunciation skills. The study focuses on detecting mispronunciation phonemes and analyzing these pronunciation errors, by identifying the type of each error, whether it was insertion, deletion, or substitution error. To train the MDD system, we constructed a speech dataset for native and non-native Arabic speakers. The performance evaluation was obtained based on the phoneme recognition and MDD performance, and we achieved a phoneme error rate of 3.1\%, 80.8\%, and 91.3\% for diagnosis accuracy and detection accuracy, respectively. Additionally, we conducted a human perceptual test to assess human proficiency in detecting pronunciation errors and compare their evaluations with automatic verification. The automatic verification surpassed human verification, achieving a detection accuracy of 97.0\% and a diagnosis accuracy of 80.4\%.}
      \field{day}{6}
      \field{issn}{2948-2992}
      \field{journaltitle}{Discover Computing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{Discov Computing}
      \field{title}{Improving Mispronunciation Detection and Diagnosis for Non- Native Learners of the {{Arabic}} Language}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{volume}{28}
      \field{year}{2025}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1007/s10791-024-09489-8
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/399UNCQL/Alrashoudi et al. - 2025 - Improving mispronunciation detection and diagnosis for non- native learners of the Arabic language.pdf
      \endverb
      \verb{urlraw}
      \verb https://link.springer.com/10.1007/s10791-024-09489-8
      \endverb
      \verb{url}
      \verb https://link.springer.com/10.1007/s10791-024-09489-8
      \endverb
    \endentry
    \entry{amrateComputerassistedPronunciationTraining2025}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=4eada953e3209b83e519779479997086}{%
           family={Amrate},
           familyi={A\bibinitperiod},
           given={Moustafa},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7b7a351da1b703053c26b520bb77dd10}{%
           family={Tsai},
           familyi={T\bibinitperiod},
           given={Pi-hua},
           giveni={P\bibinithyphendelim h\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{f4c6c3968b5e2877ba9db2dc2e743e4b}
      \strng{fullhash}{f4c6c3968b5e2877ba9db2dc2e743e4b}
      \strng{bibnamehash}{f4c6c3968b5e2877ba9db2dc2e743e4b}
      \strng{authorbibnamehash}{f4c6c3968b5e2877ba9db2dc2e743e4b}
      \strng{authornamehash}{f4c6c3968b5e2877ba9db2dc2e743e4b}
      \strng{authorfullhash}{f4c6c3968b5e2877ba9db2dc2e743e4b}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This systematic review maps the trends of computer-assisted pronunciation training (CAPT) research based on the pedagogy of second language (L2) pronunciation instruction and assessment. The review was limited to empirical studies investigating the effects of CAPT on healthy L2 learners’ pronunciation. Thirty peer-reviewed journal articles published between 1999 and 2022 were selected based on specific inclusion and exclusion criteria. Data were collected about the studies’ contexts, participants, experimental designs, CAPT systems, pronunciation training scopes and approaches, pronunciation assessment practices, and learning measures. Using a pedagogically informed codebook, the pronunciation training and assessment practices were classified and evaluated based on established L2 pronunciation teaching guidelines. The findings indicated that most of the studies focused on the pronunciation training of adult English learners with an emphasis on the production of segmental features (i.e. vowels and consonants) rather than suprasegmental features (i.e. stress, intonation, and rhythm). Despite the innovation promised by CAPT technology, pronunciation practice in the studies reviewed was characterized by the predominant use of drilling through listen-and-repeat and read-aloud activities. As for assessment, most CAPT studies relied on human listeners to measure the accurate production of discrete pronunciation features (i.e. segmental and suprasegmental accuracy). Meanwhile, few studies employed global pronunciation learning measures such as intelligibility and comprehensibility. Recommendations for future research are provided based on the discussion of these results.}
      \field{issn}{0958-3440, 1474-0109}
      \field{journaltitle}{ReCALL}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{ReCALL}
      \field{shorttitle}{Computer-Assisted Pronunciation Training}
      \field{title}{Computer-Assisted Pronunciation Training: {{A}} Systematic Review}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{37}
      \field{year}{2025}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{22\bibrangedash 42}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1017/S0958344024000181
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/NS4AH864/Amrate and Tsai - 2025 - Computer-assisted pronunciation training A systematic review.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.cambridge.org/core/product/identifier/S0958344024000181/type/journal_article
      \endverb
      \verb{url}
      \verb https://www.cambridge.org/core/product/identifier/S0958344024000181/type/journal_article
      \endverb
    \endentry
    \entry{ardilaCommonVoiceMassivelyMultilingual2020}{online}{}
      \name{author}{10}{}{%
        {{un=0,uniquepart=base,hash=7321bb4e1da541b5a6e891e020264c63}{%
           family={Ardila},
           familyi={A\bibinitperiod},
           given={Rosana},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=846f981fc6e97b5a84fa1ebdc8085a9d}{%
           family={Branson},
           familyi={B\bibinitperiod},
           given={Megan},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d92773f085a9e80944dd7f898767b3e9}{%
           family={Davis},
           familyi={D\bibinitperiod},
           given={Kelly},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8986d50512e32eaf81d70367977bf7e8}{%
           family={Henretty},
           familyi={H\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bf19183a0bad2eff52167e01391227d5}{%
           family={Kohler},
           familyi={K\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c61fec18fc73e757e4b7cbf3347e0616}{%
           family={Meyer},
           familyi={M\bibinitperiod},
           given={Josh},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=affe60f86582a0b0d4d7b0dc5f69ddcd}{%
           family={Morais},
           familyi={M\bibinitperiod},
           given={Reuben},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8485ef8e8a382a4dcb8edc45951e8948}{%
           family={Saunders},
           familyi={S\bibinitperiod},
           given={Lindsay},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e8a05c165e02340ed918110411776e8e}{%
           family={Tyers},
           familyi={T\bibinitperiod},
           given={Francis\bibnamedelima M.},
           giveni={F\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dc7da550cf5c28937bb0f55221f957a4}{%
           family={Weber},
           familyi={W\bibinitperiod},
           given={Gregor},
           giveni={G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e94d33e7232b0ded5172807b20fa0970}
      \strng{fullhash}{54958f998917b4f43b06cc2a742794f2}
      \strng{bibnamehash}{54958f998917b4f43b06cc2a742794f2}
      \strng{authorbibnamehash}{54958f998917b4f43b06cc2a742794f2}
      \strng{authornamehash}{e94d33e7232b0ded5172807b20fa0970}
      \strng{authorfullhash}{54958f998917b4f43b06cc2a742794f2}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The Common Voice corpus is a massively-multilingual collection of transcribed speech intended for speech technology research and development. Common Voice is designed for Automatic Speech Recognition purposes but can be useful in other domains (e.g. language identification). To achieve scale and sustainability, the Common Voice project employs crowdsourcing for both data collection and data validation. The most recent release includes 29 languages, and as of November 2019 there are a total of 38 languages collecting data. Over 50,000 individuals have participated so far, resulting in 2,500 hours of collected audio. To our knowledge this is the largest audio corpus in the public domain for speech recognition, both in terms of number of hours and number of languages. As an example use case for Common Voice, we present speech recognition experiments using Mozilla’s DeepSpeech Speech-to-Text toolkit. By applying transfer learning from a source English model, we find an average Character Error Rate improvement of 5.99 ± 5.48 for twelve target languages (German, French, Italian, Turkish, Catalan, Slovenian, Welsh, Irish, Breton, Tatar, Chuvash, and Kabyle). For most of these languages, these are the first ever published results on end-to-end Automatic Speech Recognition.}
      \field{day}{5}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{3}
      \field{pubstate}{prepublished}
      \field{shorttitle}{Common {{Voice}}}
      \field{title}{Common {{Voice}}: {{A Massively-Multilingual Speech Corpus}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1912.06670
      \endverb
      \verb{eprint}
      \verb 1912.06670
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/DVASHKJ2/Ardila et al. - 2020 - Common Voice A Massively-Multilingual Speech Corpus.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1912.06670
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1912.06670
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning}
    \endentry
    \entry{arnbjornsdottirIntelligentCALLGranular2022}{book}{}
      \name{editor}{7}{}{%
        {{un=0,uniquepart=base,hash=d9b491cb9ec2bb5ebe7783133813fb53}{%
           family={Arnbjörnsdóttir},
           familyi={A\bibinitperiod},
           given={Birna},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d1d00a431c5a70c6b895bc7b7e9450e}{%
           family={Bédi},
           familyi={B\bibinitperiod},
           given={Branislav},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b2970509b209cf28362cdda7c227463e}{%
           family={Bradley},
           familyi={B\bibinitperiod},
           given={Linda},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7d06ebfcc2d9def12e3833e3a507acac}{%
           family={Friðriksdóttir},
           familyi={F\bibinitperiod},
           given={Kolbrún},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f8f1e5452eac10c58fa21475951c02aa}{%
           family={Garðarsdóttir},
           familyi={G\bibinitperiod},
           given={Hólmfríður},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4f3b4cee0ccaaa4c4ca8bf7c966b071}{%
           family={Thouësny},
           familyi={T\bibinitperiod},
           given={Sylvie},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=22d40d343c412f3e8e11e8b993c43179}{%
           family={Whelpton},
           familyi={W\bibinitperiod},
           given={Matthew\bibnamedelima James},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Research-publishing.net}%
      }
      \strng{namehash}{d992f319a847cb3e11acc4ba41a99aa2}
      \strng{fullhash}{0c7cdabd13752b2b33fb5b46b8d2cc11}
      \strng{bibnamehash}{0c7cdabd13752b2b33fb5b46b8d2cc11}
      \strng{editorbibnamehash}{0c7cdabd13752b2b33fb5b46b8d2cc11}
      \strng{editornamehash}{d992f319a847cb3e11acc4ba41a99aa2}
      \strng{editorfullhash}{0c7cdabd13752b2b33fb5b46b8d2cc11}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{editor}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The 2022 EUROCALL conference was held in Reykjavik on 17-19 August 2022 as a fully online event hosted by the Vigdís Finnbogadóttir Institute for Foreign Languages, the University of Iceland, and the Árni Magnússon Institute for Icelandic Studies. The conference theme was Intelligent CALL, granular systems and learner data. This theme reflects the newest developments in the field of technology for language learning. Subfields such as natural language processing and machine learning not only enable smoother spoken and written communication between human learners and computers, but also offer ways in which language learning can be tailored to the needs of individual learners. By adding components of automatic speech recognition, text-to-speech systems, automatic feedback mechanisms, and tracking systems monitoring learners’ progress and their use of tools, applications are becoming better targeted. All of this is used to optimise the learning experience of individual learners. This volume includes 66 short papers by some of the EUROCALL 2022 presenters and it offers a combination of research studies and theoretical papers reflecting the subthemes of the conference. The articles are ordered alphabetically.}
      \field{day}{12}
      \field{edition}{1}
      \field{isbn}{978-2-38372-015-7}
      \field{langid}{english}
      \field{month}{12}
      \field{shorttitle}{Intelligent {{CALL}}, Granular Systems and Learner Data}
      \field{title}{Intelligent {{CALL}}, Granular Systems and Learner Data: Short Papers from {{EUROCALL}} 2022}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.14705/rpnet.2022.61.9782383720157
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/8PK8IQET/Arnbjörnsdóttir et al. - 2022 - Intelligent CALL, granular systems and learner data short papers from EUROCALL 2022.pdf
      \endverb
      \verb{urlraw}
      \verb https://research-publishing.net/book?10.14705/rpnet.2022.61.9782383720157
      \endverb
      \verb{url}
      \verb https://research-publishing.net/book?10.14705/rpnet.2022.61.9782383720157
      \endverb
    \endentry
    \entry{moseleyAtlasWorldsLanguages2010}{misc}{}
      \name{namea}{2}{}{%
        {{hash=1be4a49be999a9fdbf490c5b34f06e04}{%
           family={Moseley},
           familyi={M\bibinitperiod},
           given={Christopher},
           giveni={C\bibinitperiod}}}%
        {{hash=d5261aa7acd169f78b0cf19a10a6dcfb}{%
           family={Nicolas},
           familyi={N\bibinitperiod},
           given={Alexandre},
           giveni={A\bibinitperiod}}}%
      }
      \list{location}{1}{%
        {Paris}%
      }
      \list{organization}{1}{%
        {UNESCO Publishing}%
      }
      \strng{nameabibnamehash}{ff98648deea816cbe36858c04d841f1c}
      \strng{nameanamehash}{ff98648deea816cbe36858c04d841f1c}
      \strng{nameafullhash}{ff98648deea816cbe36858c04d841f1c}
      \field{sortinit}{A}
      \field{sortinithash}{2f401846e2029bad6b3ecc16d50031e2}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labeltitlesource}{title}
      \field{edition}{3. ed., entirely rev., enlarged and updated}
      \field{isbn}{978-92-3-104096-2 978-92-3-104095-5}
      \field{langid}{english}
      \field{nameatype}{collaborator}
      \field{pagetotal}{62}
      \field{title}{Atlas of the World's Languages in Danger}
      \field{year}{2010}
      \field{dateera}{ce}
    \endentry
    \entry{baevskiEffectivenessSelfsupervisedPretraining2020}{online}{}
      \name{author}{3}{ul=2}{%
        {{un=0,uniquepart=base,hash=e478046d4abc39e9814f6e364a736511}{%
           family={Baevski},
           familyi={B\bibinitperiod},
           given={Alexei},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3ff0eff0a1d1258618c88f2ec57095f}{%
           family={Auli},
           familyi={A\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=838ae213145f7410d963d9727504b2df}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Abdelrahman},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b81d7ae6e69bcb58f969bb3a50905801}
      \strng{fullhash}{57131208bf99f1e9bf17505834567dcf}
      \strng{bibnamehash}{57131208bf99f1e9bf17505834567dcf}
      \strng{authorbibnamehash}{57131208bf99f1e9bf17505834567dcf}
      \strng{authornamehash}{b81d7ae6e69bcb58f969bb3a50905801}
      \strng{authorfullhash}{57131208bf99f1e9bf17505834567dcf}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We compare self-supervised representation learning algorithms which either explicitly quantize the audio data or learn representations without quantization. We find the former to be more accurate since it builds a good vocabulary of the data through vq-wav2vec [1] to enable learning of effective representations in subsequent BERT training. Different to previous work, we directly fine-tune the pre-trained BERT models on transcribed speech using a Connectionist Temporal Classification (CTC) loss instead of feeding the representations into a task-specific model. We also propose a BERT-style model learning directly from the continuous audio data and compare pre-training on raw audio to spectral features. Fine-tuning a BERT model on 10 hour of labeled Librispeech data with a vq-wav2vec vocabulary is almost as good as the best known reported system trained on 100 hours of labeled data on testclean, while achieving a 25\% WER reduction on test-other. When using only 10 minutes of labeled data, WER is 25.2 on test-other and 16.3 on test-clean. This demonstrates that self-supervision can enable speech recognition systems trained on a near-zero amount of transcribed data.}
      \field{day}{18}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{5}
      \field{pubstate}{prepublished}
      \field{title}{Effectiveness of Self-Supervised Pre-Training for Speech Recognition}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1911.03912
      \endverb
      \verb{eprint}
      \verb 1911.03912
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/M9V7A8QV/Baevski et al. - 2020 - Effectiveness of self-supervised pre-training for speech recognition.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1911.03912
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1911.03912
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning}
    \endentry
    \entry{baevskiVqwav2vecSelfSupervisedLearning2020}{online}{}
      \name{author}{3}{ul=2}{%
        {{un=0,uniquepart=base,hash=e478046d4abc39e9814f6e364a736511}{%
           family={Baevski},
           familyi={B\bibinitperiod},
           given={Alexei},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a13c8464f464250a409c78edf90ea235}{%
           family={Schneider},
           familyi={S\bibinitperiod},
           given={Steffen},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3ff0eff0a1d1258618c88f2ec57095f}{%
           family={Auli},
           familyi={A\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3de575d02086b46b3037b42a314f9421}
      \strng{fullhash}{f27b45b9fadd86a4e99bde34a1d2b41f}
      \strng{bibnamehash}{f27b45b9fadd86a4e99bde34a1d2b41f}
      \strng{authorbibnamehash}{f27b45b9fadd86a4e99bde34a1d2b41f}
      \strng{authornamehash}{3de575d02086b46b3037b42a314f9421}
      \strng{authorfullhash}{f27b45b9fadd86a4e99bde34a1d2b41f}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We propose vq-wav2vec to learn discrete representations of audio segments through a wav2vec-style self-supervised context prediction task. The algorithm uses either a gumbel softmax or online k-means clustering to quantize the dense representations. Discretization enables the direct application of algorithms from the NLP community which require discrete inputs. Experiments show that BERT pre-training achieves a new state of the art on TIMIT phoneme classification and WSJ speech recognition.}
      \field{day}{16}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{2}
      \field{pubstate}{prepublished}
      \field{shorttitle}{Vq-Wav2vec}
      \field{title}{Vq-Wav2vec: {{Self-Supervised Learning}} of {{Discrete Speech Representations}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1910.05453
      \endverb
      \verb{eprint}
      \verb 1910.05453
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/VXRQVZIT/Baevski et al. - 2020 - vq-wav2vec Self-Supervised Learning of Discrete Speech Representations.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1910.05453
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1910.05453
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning}
    \endentry
    \entry{baevskiWav2vec20Framework2020}{online}{}
      \name{author}{4}{ul=2}{%
        {{un=0,uniquepart=base,hash=e478046d4abc39e9814f6e364a736511}{%
           family={Baevski},
           familyi={B\bibinitperiod},
           given={Alexei},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5c159723f6448ed6ac38752cc576037}{%
           family={Zhou},
           familyi={Z\bibinitperiod},
           given={Henry},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=838ae213145f7410d963d9727504b2df}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Abdelrahman},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3ff0eff0a1d1258618c88f2ec57095f}{%
           family={Auli},
           familyi={A\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{dc7b23f969a11e51f4e475f7da4939cc}
      \strng{fullhash}{ec8bd239017ce02048aaf9cd2453b4d5}
      \strng{bibnamehash}{ec8bd239017ce02048aaf9cd2453b4d5}
      \strng{authorbibnamehash}{ec8bd239017ce02048aaf9cd2453b4d5}
      \strng{authornamehash}{dc7b23f969a11e51f4e475f7da4939cc}
      \strng{authorfullhash}{ec8bd239017ce02048aaf9cd2453b4d5}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data.}
      \field{day}{22}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{10}
      \field{pubstate}{prepublished}
      \field{shorttitle}{Wav2vec 2.0}
      \field{title}{Wav2vec 2.0: {{A Framework}} for {{Self-Supervised Learning}} of {{Speech Representations}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2006.11477
      \endverb
      \verb{eprint}
      \verb 2006.11477
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/FYBUF8ZV/Baevski et al. - 2020 - wav2vec 2.0 A Framework for Self-Supervised Learning of Speech Representations.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2006.11477
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2006.11477
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{bajorek2017l2}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=8631c19273e5a80e28776391ab19751a}{%
           family={Bajorek},
           familyi={B\bibinitperiod},
           given={Joan\bibnamedelima Palmiter},
           giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8631c19273e5a80e28776391ab19751a}
      \strng{fullhash}{8631c19273e5a80e28776391ab19751a}
      \strng{bibnamehash}{8631c19273e5a80e28776391ab19751a}
      \strng{authorbibnamehash}{8631c19273e5a80e28776391ab19751a}
      \strng{authornamehash}{8631c19273e5a80e28776391ab19751a}
      \strng{authorfullhash}{8631c19273e5a80e28776391ab19751a}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{Issues and Trends in Educational Technology}
      \field{number}{1}
      \field{title}{L2 Pronunciation in {{CALL}}: {{The}} Unrealized Potential of {{Rosetta}} Stone, {{Duolingo}}, {{Babbel}}, and Mango Languages}
      \field{volume}{5}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{pages}{24\bibrangedash 51}
      \range{pages}{28}
      \verb{file}
      \verb /home/pccady/Zotero/storage/IQR5R4FR/Bajorek - 2017 - L2 pronunciation in CALL The unrealized potential of Rosetta stone, Duolingo, Babbel, and mango lan.pdf
      \endverb
    \endentry
    \entry{ballierUsingWhisperLLM}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=946dc77f7c7d94fd705c2eb86d7ebed6}{%
           family={Ballier},
           familyi={B\bibinitperiod},
           given={Nicolas},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ce3579cb6f798a3ce4237b6027cdc2a2}{%
           family={Méli},
           familyi={M\bibinitperiod},
           given={Adrien},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e149b63ebff0b2e873e0c6dbda201bf9}{%
           family={Amand},
           familyi={A\bibinitperiod},
           given={Maelle},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=55f91b99cb3408045f41602dca09bbf2}{%
           family={Yunès},
           familyi={Y\bibinitperiod},
           given={Jean-Baptiste},
           giveni={J\bibinithyphendelim B\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e635ba12e806f63654c31d74b3e44834}
      \strng{fullhash}{1be818d2ea5802dd82e11d3413bd0e26}
      \strng{bibnamehash}{1be818d2ea5802dd82e11d3413bd0e26}
      \strng{authorbibnamehash}{1be818d2ea5802dd82e11d3413bd0e26}
      \strng{authornamehash}{e635ba12e806f63654c31d74b3e44834}
      \strng{authorfullhash}{1be818d2ea5802dd82e11d3413bd0e26}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper reports on a pilot study to use Whisper’s large language model (LLM) as a tool for potential representation of segmental (phone) pronunciation errors. We compared the performance of the transcription outputs for the various models developed by the automatic speech recognition (ASR) system Whisper (Radford et al., 2022) ranging from 39 to 1,550 million parameters. We investigated 38 recordings of two paragraphs from Conrad’s Typhoon. The whisper transcriptions were compared to the original text that was read by these second-year French undergraduates. We used WER (Word Error Rate) and Levenshtein distance to assess the various graphic representations of Conrad’s reference text. We show how the differences can be transformed into operationalised feedback for learners. We used expert phonetic knowledge to check the plausibility of the phonetic interpretation with the signal (in particular the recall of H dropping produced by French learners). Our findings suggest that the transcriptions produced by the medium model converge with what a native speaker understands and that the tiny model produces alternate transcriptions that are plausible candidates for learner errors.}
      \field{langid}{english}
      \field{title}{Using {{Whisper LLM}} for {{Automatic Phonetic Diagnosis}} of {{L2 Speech}}: {{A Case Study}} with {{French Learners}} of {{English}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/Y7D8ILEC/Ballier et al. - Using Whisper LLM for Automatic Phonetic Diagnosis of L2 Speech A Case Study with French Learners o.pdf
      \endverb
    \endentry
    \entry{bannoProficiencyAssessmentL22022}{online}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=89a0d9f3cace3e007138aa699a1e0112}{%
           family={Bannò},
           familyi={B\bibinitperiod},
           given={Stefano},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c481c9fa52dbd24e8ded8dbb342e01d}{%
           family={Matassoni},
           familyi={M\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{86333f40c8f9973bc2649785029be867}
      \strng{fullhash}{86333f40c8f9973bc2649785029be867}
      \strng{bibnamehash}{86333f40c8f9973bc2649785029be867}
      \strng{authorbibnamehash}{86333f40c8f9973bc2649785029be867}
      \strng{authornamehash}{86333f40c8f9973bc2649785029be867}
      \strng{authorfullhash}{86333f40c8f9973bc2649785029be867}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The increasing demand for learning English as a second language has led to a growing interest in methods for automatically assessing spoken language proficiency. Most approaches use hand-crafted features, but their efficacy relies on their particular underlying assumptions and they risk discarding potentially salient information about proficiency. Other approaches rely on transcriptions produced by ASR systems which may not provide a faithful rendition of a learner’s utterance in specific scenarios (e.g., non-native children’s spontaneous speech). Furthermore, transcriptions do not yield any information about relevant aspects such as intonation, rhythm or prosody. In this paper, we investigate the use of wav2vec 2.0 for assessing overall and individual aspects of proficiency on two small datasets, one of which is publicly available. We find that this approach significantly outperforms the BERT-based baseline system trained on ASR and manual transcriptions used for comparison.}
      \field{day}{24}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{10}
      \field{pubstate}{prepublished}
      \field{title}{Proficiency Assessment of {{L2}} Spoken {{English}} Using Wav2vec 2.0}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2210.13168
      \endverb
      \verb{eprint}
      \verb 2210.13168
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/EGUZ3K24/Bannò and Matassoni - 2022 - Proficiency assessment of L2 spoken English using wav2vec 2.0.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2210.13168
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2210.13168
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{barteldsMakingMoreLittle2023}{online}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=07c4453efe601e93fc331d72ed4c5be2}{%
           family={Bartelds},
           familyi={B\bibinitperiod},
           given={Martijn},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=39cbeb7e56afcc2dece256d14248c50a}{%
           family={San},
           familyi={S\bibinitperiod},
           given={Nay},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5cb9a4e25cf34341a4d955c890436cdb}{%
           family={McDonnell},
           familyi={M\bibinitperiod},
           given={Bradley},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3147296c99a3f829087becd1a4eaec08}{%
           family={Jurafsky},
           familyi={J\bibinitperiod},
           given={Dan},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=210957e931f1a0a12afd9b9d7f3e8947}{%
           family={Wieling},
           familyi={W\bibinitperiod},
           given={Martijn},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{13d6acb28fdc132d6453fe76fd2c5f5b}
      \strng{fullhash}{937dd00ea439fbf13238e3a3e948f097}
      \strng{bibnamehash}{937dd00ea439fbf13238e3a3e948f097}
      \strng{authorbibnamehash}{937dd00ea439fbf13238e3a3e948f097}
      \strng{authornamehash}{13d6acb28fdc132d6453fe76fd2c5f5b}
      \strng{authorfullhash}{937dd00ea439fbf13238e3a3e948f097}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{The performance of automatic speech recognition (ASR) systems has advanced substantially in recent years, particularly for languages for which a large amount of transcribed speech is available. Unfortunately, for low-resource languages, such as minority languages, regional languages or dialects, ASR performance generally remains much lower. In this study, we investigate whether data augmentation techniques could help improve low-resource ASR performance, focusing on four typologically diverse minority languages or language variants (West Germanic: Gronings, West-Frisian; Malayo-Polynesian: Besemah, Nasal). For all four languages, we examine the use of self-training, where an ASR system trained with the available human-transcribed data is used to generate transcriptions, which are then combined with the original data to train a new ASR system. For Gronings, for which there was a pre-existing text-to-speech (TTS) system available, we also examined the use of TTS to generate ASR training data from text-only sources. We find that using a self-training approach consistently yields improved performance (a relative WER reduction up to 20.5\% compared to using an ASR system trained on 24 minutes of manually transcribed speech). The performance gain from TTS augmentation for Gronings was even stronger (up to 25.5\% relative reduction in WER compared to a system based on 24 minutes of manually transcribed speech). In sum, our results show the benefit of using self-training or (if possible) TTS-generated data as an efficient solution to overcome the limitations of data availability for resource-scarce languages in order to improve ASR performance.}
      \field{day}{19}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{month}{5}
      \field{pubstate}{prepublished}
      \field{shorttitle}{Making {{More}} of {{Little Data}}}
      \field{title}{Making {{More}} of {{Little Data}}: {{Improving Low-Resource Automatic Speech Recognition Using Data Augmentation}}}
      \field{urlday}{15}
      \field{urlmonth}{7}
      \field{urlyear}{2025}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2305.10951
      \endverb
      \verb{eprint}
      \verb 2305.10951
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/JSBDMVYY/Bartelds et al. - 2023 - Making More of Little Data Improving Low-Resource Automatic Speech Recognition Using Data Augmentat.pdf;/home/pccady/Zotero/storage/UECVQWGQ/2305.html
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2305.10951
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2305.10951
      \endverb
      \keyw{Computer Science - Computation and Language,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{benderAchievingEvaluatingLanguageIndependence2011}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=e579c650beb31c286389278140fadd63}{%
           family={Bender},
           familyi={B\bibinitperiod},
           given={Emily\bibnamedelima M.},
           giveni={E\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e579c650beb31c286389278140fadd63}
      \strng{fullhash}{e579c650beb31c286389278140fadd63}
      \strng{bibnamehash}{e579c650beb31c286389278140fadd63}
      \strng{authorbibnamehash}{e579c650beb31c286389278140fadd63}
      \strng{authornamehash}{e579c650beb31c286389278140fadd63}
      \strng{authorfullhash}{e579c650beb31c286389278140fadd63}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Language independence is commonly presented as one of the advantages of modern, machine-learning approaches to NLP, and it is an important type of scalability. In this position paper, I critically review the widespread approaches to achieving and evaluating language independence in the field of computational linguistics and argue that, on the one hand, we are not truly evaluating language independence with any systematicity and on the other hand, that truly language-independent technology requires more linguistic sophistication than is the norm.}
      \field{day}{1}
      \field{issn}{1945-3604}
      \field{journaltitle}{Linguistic Issues in Language Technology}
      \field{langid}{english}
      \field{month}{10}
      \field{shortjournal}{LiLT}
      \field{title}{On {{Achieving}} and {{Evaluating Language-Independence}} in {{NLP}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{6}
      \field{year}{2011}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.33011/lilt.v6i.1239
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/US6RJ7YH/Bender - 2011 - On Achieving and Evaluating Language-Independence in NLP.pdf
      \endverb
      \verb{urlraw}
      \verb https://journals.colorado.edu/index.php/lilt/article/view/1239
      \endverb
      \verb{url}
      \verb https://journals.colorado.edu/index.php/lilt/article/view/1239
      \endverb
    \endentry
    \entry{besacierAutomaticSpeechRecognition2014}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=393dbf8e1aaa82b3c52ce5fde54751dc}{%
           family={Besacier},
           familyi={B\bibinitperiod},
           given={Laurent},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8d146e62af0ef9c9436022e82a30bb4f}{%
           family={Barnard},
           familyi={B\bibinitperiod},
           given={Etienne},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6404be0e94e9d1e52252cbe343e118e5}{%
           family={Karpov},
           familyi={K\bibinitperiod},
           given={Alexey},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1f89e6d7240f123a6ea1333a02e28990}{%
           family={Schultz},
           familyi={S\bibinitperiod},
           given={Tanja},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Elsevier BV}%
      }
      \strng{namehash}{8b41073f345ca2222582b8b131fdefe4}
      \strng{fullhash}{99f93f6ef361745678aa4494e9d281c9}
      \strng{bibnamehash}{99f93f6ef361745678aa4494e9d281c9}
      \strng{authorbibnamehash}{99f93f6ef361745678aa4494e9d281c9}
      \strng{authornamehash}{8b41073f345ca2222582b8b131fdefe4}
      \strng{authorfullhash}{99f93f6ef361745678aa4494e9d281c9}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Speech processing for under-resourced languages is an active field of research, which has experienced significant progress during the past decade. We propose, in this paper, a survey that focuses on automatic speech recognition (ASR) for these languages. The definition of under-resourced languages and the challenges associated to them are first defined. The main part of the paper is a literature review of the recent (last 8 years) contributions made in ASR for under-resourced languages. Examples of past projects and future trends when dealing with under-resourced languages are also presented. We believe that this paper will be a good starting point for anyone interested to initiate research in (or operational development of) ASR for one or several under-resourced languages. It should be clear, however, that many of the issues and approaches presented here, apply to speech technology in general (text-to-speech synthesis for instance).}
      \field{issn}{0167-6393}
      \field{journaltitle}{Speech Communication}
      \field{langid}{english}
      \field{month}{1}
      \field{shorttitle}{Automatic Speech Recognition for Under-Resourced Languages}
      \field{title}{Automatic Speech Recognition for Under-Resourced Languages: {{A}} Survey}
      \field{urlday}{15}
      \field{urlmonth}{7}
      \field{urlyear}{2025}
      \field{volume}{56}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{85\bibrangedash 100}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1016/j.specom.2013.07.008
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/AKFY7UJQ/Besacier et al. - 2014 - Automatic speech recognition for under-resourced languages A survey.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639313000988
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639313000988
      \endverb
    \endentry
    \entry{bodnarEvaluatingMotivationalImpact2016}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=4fac394c8bf9842cb3c6f368eaac16b5}{%
           family={Bodnar},
           familyi={B\bibinitperiod},
           given={Stephen},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a712139715a50e15afa4f4800444e61}{%
           family={Cucchiarini},
           familyi={C\bibinitperiod},
           given={Catia},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a872bcf73b844088551245ffed26cc56}{%
           family={Strik},
           familyi={S\bibinitperiod},
           given={Helmer},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a86eaf68ee137e436e4fe2bfacd13790}{%
           family={Van\bibnamedelima Hout},
           familyi={V\bibinitperiod\bibinitdelim H\bibinitperiod},
           given={Roeland},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ab4cda25f51c1171c062efa04efdcaab}
      \strng{fullhash}{fbe8b209dd38cb04be991b66aabfdb6c}
      \strng{bibnamehash}{fbe8b209dd38cb04be991b66aabfdb6c}
      \strng{authorbibnamehash}{fbe8b209dd38cb04be991b66aabfdb6c}
      \strng{authornamehash}{ab4cda25f51c1171c062efa04efdcaab}
      \strng{authorfullhash}{fbe8b209dd38cb04be991b66aabfdb6c}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{day}{2}
      \field{issn}{0958-8221, 1744-3210}
      \field{journaltitle}{Computer Assisted Language Learning}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{Computer Assisted Language Learning}
      \field{shorttitle}{Evaluating the Motivational Impact of {{CALL}} Systems}
      \field{title}{Evaluating the Motivational Impact of {{CALL}} Systems: Current Practices and Future Directions}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{29}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{186\bibrangedash 212}
      \range{pages}{27}
      \verb{doi}
      \verb 10.1080/09588221.2014.927365
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/W5NCUPMW/Bodnar et al. - 2016 - Evaluating the motivational impact of CALL systems current practices and future directions.pdf
      \endverb
      \verb{urlraw}
      \verb http://www.tandfonline.com/doi/full/10.1080/09588221.2014.927365
      \endverb
      \verb{url}
      \verb http://www.tandfonline.com/doi/full/10.1080/09588221.2014.927365
      \endverb
    \endentry
    \entry{bouliannePhonemeTranscriptionEndangered2022}{inproceedings}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=4da0ff554d1408c6508f7ae846654700}{%
           family={Boulianne},
           familyi={B\bibinitperiod},
           given={Gilles},
           giveni={G\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Dublin, Ireland}%
      }
      \list{publisher}{1}{%
        {Association for Computational Linguistics}%
      }
      \strng{namehash}{4da0ff554d1408c6508f7ae846654700}
      \strng{fullhash}{4da0ff554d1408c6508f7ae846654700}
      \strng{bibnamehash}{4da0ff554d1408c6508f7ae846654700}
      \strng{authorbibnamehash}{4da0ff554d1408c6508f7ae846654700}
      \strng{authornamehash}{4da0ff554d1408c6508f7ae846654700}
      \strng{authorfullhash}{4da0ff554d1408c6508f7ae846654700}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Transcription is often reported as the bottleneck in endangered language documentation, requiring large efforts from scarce speakers and transcribers. In general, automatic speech recognition (ASR) can be accurate enough to accelerate transcription only if trained on large amounts of transcribed data. However, when a single speaker is involved, several studies have reported encouraging results for phonetic transcription even with small amounts of training. Here we expand this body of work on speaker-dependent transcription by comparing four ASR approaches, notably recent transformer and pretrained multilingual models, on a common dataset of 11 languages. To automate data preparation, training and evaluation steps, we also developed a phoneme recognition setup which handles morphologically complex languages and writing systems for which no pronunciation dictionary exists. We find that fine-tuning a multilingual pretrained model yields an average phoneme error rate (PER) of 15\% for 6 languages with 99 minutes or less of transcribed data for training. For the 5 languages with between 100 and 192 minutes of training, we achieved a PER of 8.4\% or less. These results on a number of varied languages suggest that ASR can now significantly reduce transcription efforts in the speaker-dependent situation common in endangered language work.}
      \field{booktitle}{Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2022}
      \field{eventtitle}{Findings of the {{Association}} for {{Computational Linguistics}}: {{ACL}} 2022}
      \field{langid}{english}
      \field{shorttitle}{Phoneme Transcription of Endangered Languages}
      \field{title}{Phoneme Transcription of Endangered Languages: An Evaluation of Recent {{ASR}} Architectures in the Single Speaker Scenario}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2301\bibrangedash 2308}
      \range{pages}{8}
      \verb{doi}
      \verb 10.18653/v1/2022.findings-acl.180
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/JQZFFRPM/Boulianne - 2022 - Phoneme transcription of endangered languages an evaluation of recent ASR architectures in the sing.pdf
      \endverb
      \verb{urlraw}
      \verb https://aclanthology.org/2022.findings-acl.180
      \endverb
      \verb{url}
      \verb https://aclanthology.org/2022.findings-acl.180
      \endverb
    \endentry
    \entry{broinNewUrbanIrish}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=d27b372d6738704d986062cd20f59d1f}{%
           family={Broin},
           familyi={B\bibinitperiod},
           given={Brian\bibnamedelima Ó},
           giveni={B\bibinitperiod\bibinitdelim Ó\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{d27b372d6738704d986062cd20f59d1f}
      \strng{fullhash}{d27b372d6738704d986062cd20f59d1f}
      \strng{bibnamehash}{d27b372d6738704d986062cd20f59d1f}
      \strng{authorbibnamehash}{d27b372d6738704d986062cd20f59d1f}
      \strng{authornamehash}{d27b372d6738704d986062cd20f59d1f}
      \strng{authorfullhash}{d27b372d6738704d986062cd20f59d1f}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article compares the phonetics and morphology of Irish spoken in the Gaeltacht with that spoken in Irish cities. Informants were identified by randomly selecting newsreaders and chat show hosts on Gaeltacht and urban Irishlanguage radio stations. Recordings of the speakers were transcribed and then analysed for morphological and phonetic accuracy. City speakers demonstrated a move towards simplified morphology and phonology, making fewer than 50\% of expected changes, while Gaeltacht speakers retained the language’s traditional forms, making more than 90\% of expected changes. It was discovered that the city speakers, while apparently speaking stable idiolects, each returned very different rates, suggesting that the cities do not yet have stable Irish dialects. The Gaeltacht speakers all returned very similar rates.}
      \field{langid}{english}
      \field{title}{New {{Urban Irish}}: {{Pidgin}}, {{Creole}}, or {{Bona Fide Dialect}}? {{The Phonetics}} and {{Morphology}} of {{City}} and {{Gaeltacht Speakers Systematically Compared}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/ULMAZYR4/Broin - New Urban Irish Pidgin, Creole, or Bona Fide Dialect The Phonetics and Morphology of City and Gael.pdf
      \endverb
    \endentry
    \entry{chasaideABAIRInitiativeBringing2017}{book}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=dfdef9c4f0b798139ec7baeb9c10b726}{%
           family={Chasaide},
           familyi={C\bibinitperiod},
           given={Ailbhe},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ff6612f89e173ef3f99da3d8e3198ec0}{%
           family={Ní\bibnamedelima Chiaráin},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Neasa},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a09def41ef54cd6582b67d86ae3785c1}{%
           family={Wendler},
           familyi={W\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4ca87a8b7ddfc49d2811ec5f34f86af}{%
           family={Berthelsen},
           familyi={B\bibinitperiod},
           given={Harald},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c18def86d87b42fc64a7f14ad616b8d1}{%
           family={Murphy},
           familyi={M\bibinitperiod},
           given={Andy},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f08b34b12657a55637cced651ec89cc3}{%
           family={Gobl},
           familyi={G\bibinitperiod},
           given={Christer},
           giveni={C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{956fdc8171f999d575de92d489af31ca}
      \strng{fullhash}{a366136d263e53aedd99fa07980855b7}
      \strng{bibnamehash}{a366136d263e53aedd99fa07980855b7}
      \strng{authorbibnamehash}{a366136d263e53aedd99fa07980855b7}
      \strng{authornamehash}{956fdc8171f999d575de92d489af31ca}
      \strng{authorfullhash}{a366136d263e53aedd99fa07980855b7}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{day}{20}
      \field{month}{8}
      \field{shorttitle}{The {{ABAIR}} Initiative}
      \field{title}{The {{ABAIR}} Initiative: {{Bringing Spoken Irish}} into the {{Digital Space}}}
      \field{year}{2017}
      \field{dateera}{ce}
      \verb{doi}
      \verb 10.21437/Interspeech.2017-1407
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/2JKBUKKG/Chasaide et al. - 2017 - The ABAIR initiative Bringing Spoken Irish into the Digital Space.pdf
      \endverb
    \endentry
    \entry{chenEndtoEndNeuralNetwork2018}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=1,uniquepart=given,hash=046842e5933d7131df18c28d8bce94ff}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=0f190860bbbf83baa61c1fc8971da324}{%
           family={Tao},
           familyi={T\bibinitperiod},
           given={Jidong},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a69c9643cad7bfec65176aefc1b39362}{%
           family={Ghaffarzadegan},
           familyi={G\bibinitperiod},
           given={Shabnam},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bd4968147b63f3be255e1c58da6f95f7}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Yao},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Calgary, AB}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{8f6e8ef60e7861f74a658032bfe8d526}
      \strng{fullhash}{c5d78c7cd8284d860dab0bdf7b11ab64}
      \strng{bibnamehash}{c5d78c7cd8284d860dab0bdf7b11ab64}
      \strng{authorbibnamehash}{c5d78c7cd8284d860dab0bdf7b11ab64}
      \strng{authornamehash}{8f6e8ef60e7861f74a658032bfe8d526}
      \strng{authorfullhash}{c5d78c7cd8284d860dab0bdf7b11ab64}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In recent years, machine learning models for automated speech scoring systems were mainly built using data-driven approaches with handcrafted features as one of the main components. However, the remarkable successes of deep learning (DL) technology in a variety of machine learning tasks has demonstrated its effectiveness in extracting features. Although there have been some efforts in utilizing DL technology for the automated speech scoring task, a thorough investigation of learning useful features is still missing. In this paper, we propose an end-to-end solution that consists of using deep neural network models to encode both lexical and acoustical cues to learn predictive features automatically. Experiments also confirm the effectiveness of our proposed solution compared to conventional methods based on handcrafted features.}
      \field{booktitle}{2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})}
      \field{eventtitle}{{{ICASSP}} 2018 - 2018 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})}
      \field{isbn}{978-1-5386-4658-8}
      \field{langid}{english}
      \field{month}{4}
      \field{title}{End-to-{{End Neural Network Based Automated Speech Scoring}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{6234\bibrangedash 6238}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP.2018.8462562
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/53IG6K6Q/Chen et al. - 2018 - End-to-End Neural Network Based Automated Speech Scoring.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/8462562/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/8462562/
      \endverb
    \endentry
    \entry{chenComputerassistedPronunciationTraining2016}{inproceedings}{}
      \name{author}{2}{}{%
        {{un=1,uniquepart=given,hash=268decadec6e9ab3b767d7da9875e4cc}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Nancy\bibnamedelima F.},
           giveni={N\bibinitperiod\bibinitdelim F\bibinitperiod},
           givenun=1}}%
        {{un=1,uniquepart=given,hash=f397ee85433a25b75738faa0b764e496}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Haizhou},
           giveni={H\bibinitperiod},
           givenun=1}}%
      }
      \list{location}{1}{%
        {Jeju, South Korea}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{85af320bcfeef49c09d817ec5ce05fc0}
      \strng{fullhash}{85af320bcfeef49c09d817ec5ce05fc0}
      \strng{bibnamehash}{85af320bcfeef49c09d817ec5ce05fc0}
      \strng{authorbibnamehash}{85af320bcfeef49c09d817ec5ce05fc0}
      \strng{authornamehash}{85af320bcfeef49c09d817ec5ce05fc0}
      \strng{authorfullhash}{85af320bcfeef49c09d817ec5ce05fc0}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper reviews the research approaches used in computer-assisted pronunciation training (CAPT), addresses the existing challenges, and discusses emerging trends and opportunities. To complement existing work, our analysis places more emphasis on pronunciation teaching and learning (as opposed to pronunciation assessment), prosodic error detection (as opposed to phonetic error detection), and research work from the past five years given the recent rapid development in spoken language technology.}
      \field{booktitle}{2016 {{Asia-Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA}})}
      \field{eventtitle}{2016 {{Asia-Pacific Signal}} and {{Information Processing Association Annual Summit}} and {{Conference}} ({{APSIPA}})}
      \field{isbn}{978-988-14768-2-1}
      \field{langid}{english}
      \field{month}{12}
      \field{shorttitle}{Computer-Assisted Pronunciation Training}
      \field{title}{Computer-Assisted Pronunciation Training: {{From}} Pronunciation Scoring towards Spoken Language Learning}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 7}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1109/APSIPA.2016.7820782
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/G5Y3MTKU/Chen and Li - 2016 - Computer-assisted pronunciation training From pronunciation scoring towards spoken language learnin.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7820782/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7820782/
      \endverb
    \endentry
    \entry{collinsSituatedImmersiveGaming2021}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=4fc6b2e7710821d1aec368bb4679778e}{%
           family={Collins},
           familyi={C\bibinitperiod},
           given={Naoise},
           giveni={N\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Technological University Dublin}%
      }
      \strng{namehash}{4fc6b2e7710821d1aec368bb4679778e}
      \strng{fullhash}{4fc6b2e7710821d1aec368bb4679778e}
      \strng{bibnamehash}{4fc6b2e7710821d1aec368bb4679778e}
      \strng{authorbibnamehash}{4fc6b2e7710821d1aec368bb4679778e}
      \strng{authornamehash}{4fc6b2e7710821d1aec368bb4679778e}
      \strng{authorfullhash}{4fc6b2e7710821d1aec368bb4679778e}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this thesis, three cycles of design based research are outlined, implementing a situated immersive virtual reality game for Irish language learning. It was undertaken in order to investigate a potential technological solution to improve the limited number of daily Irish adult speakers in Ireland, 3\%. It examines the intersection between game based learning, Irish language learning and virtual reality technology and the methodological approach undertaken follows a design based research paradigm.}
      \field{langid}{english}
      \field{title}{Situated {{Immersive Gaming Environments}} for {{Irish Language Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.21427/JKMJ-XM34
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/JR69R49N/Collins - 2021 - Situated Immersive Gaming Environments for Irish Language Learning.pdf
      \endverb
      \verb{urlraw}
      \verb https://arrow.tudublin.ie/tourdoc/35
      \endverb
      \verb{url}
      \verb https://arrow.tudublin.ie/tourdoc/35
      \endverb
    \endentry
    \entry{collinsGaeltechVRMeasuringImpact2019}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=4fc6b2e7710821d1aec368bb4679778e}{%
           family={Collins},
           familyi={C\bibinitperiod},
           given={Naoise},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2a9bada010a9e46285b604cd2f483516}{%
           family={Vaughan},
           familyi={V\bibinitperiod},
           given={Dr\bibnamedelima Brian},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8cae66da50eda99ea13e80096b744429}{%
           family={Cullen},
           familyi={C\bibinitperiod},
           given={Dr\bibnamedelima Charlie},
           giveni={D\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e595e9ff5e6da0863aad0368ee7f0137}{%
           family={Gardner},
           familyi={G\bibinitperiod},
           given={Dr\bibnamedelima Keith},
           giveni={D\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4646b2163c344eae34a2f0e9bdb543bf}
      \strng{fullhash}{038af3cf0d2d34224ae361447b08cd84}
      \strng{bibnamehash}{038af3cf0d2d34224ae361447b08cd84}
      \strng{authorbibnamehash}{038af3cf0d2d34224ae361447b08cd84}
      \strng{authornamehash}{4646b2163c344eae34a2f0e9bdb543bf}
      \strng{authorfullhash}{038af3cf0d2d34224ae361447b08cd84}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This study investigates how a design-based research methodology is best suited to measuring the impact of a designed virtual reality experience to improve situated identity in Irish learners focusing on their attitudes, motivation, and confidence as Irish language learners. This paper describes the design of GaeltechVR: an immersive Irish language VR experience designed for the VIVE Pro. It also gives the results of a mixed-methods study to measure the impact in a local adult Irish language learner context. A questionnaire on situated attitudes and motivation to language learning (Ushioda \& Dörnyei, 2009) was adapted for the Irish context to investigate a small scale sample of the local context’s attitudes to Irish language learning. The participant’s gameplay was recorded for analysis along with questionnaires on presence (Witmer \& Singer, 1998), simulator sickness and an adapted questionnaire on their attitudes after the intervention.}
      \field{langid}{english}
      \field{number}{3}
      \field{title}{{{GaeltechVR}}: {{Measuring}} the {{Impact}} of an {{Immersive Virtual Environment}} to {{Promote Situated Identity}} in {{Irish Language Learning}}}
      \field{volume}{12}
      \field{year}{2019}
      \field{dateera}{ce}
      \verb{file}
      \verb /home/pccady/Zotero/storage/DVI524TZ/Collins et al. - 2019 - GaeltechVR Measuring the Impact of an Immersive Virtual Environment to Promote Situated Identity in.pdf
      \endverb
    \endentry
    \entry{conneauUnsupervisedCrosslingualRepresentation2020}{online}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=7cf7ac6a9456559cc67ee138c7f21cec}{%
           family={Conneau},
           familyi={C\bibinitperiod},
           given={Alexis},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e478046d4abc39e9814f6e364a736511}{%
           family={Baevski},
           familyi={B\bibinitperiod},
           given={Alexei},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=133261178beda1dc3991e0e1dfd5a791}{%
           family={Collobert},
           familyi={C\bibinitperiod},
           given={Ronan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=838ae213145f7410d963d9727504b2df}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Abdelrahman},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3ff0eff0a1d1258618c88f2ec57095f}{%
           family={Auli},
           familyi={A\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{2916bb4d39f814823624e9e16627e23a}
      \strng{fullhash}{6e68297063fd6e1f247f0478a67fd8c9}
      \strng{bibnamehash}{6e68297063fd6e1f247f0478a67fd8c9}
      \strng{authorbibnamehash}{6e68297063fd6e1f247f0478a67fd8c9}
      \strng{authornamehash}{2916bb4d39f814823624e9e16627e23a}
      \strng{authorfullhash}{6e68297063fd6e1f247f0478a67fd8c9}
      \field{extraname}{1}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents XLSR which learns cross-lingual speech representations by pretraining a single model from the raw waveform of speech in multiple languages. We build on wav2vec 2.0 which is trained by solving a contrastive task over masked latent speech representations and jointly learns a quantization of the latents shared across languages. The resulting model is fine-tuned on labeled data and experiments show that cross-lingual pretraining significantly outperforms monolingual pretraining. On the CommonVoice benchmark, XLSR shows a relative phoneme error rate reduction of 72\% compared to the best known results. On BABEL, our approach improves word error rate by 16\% relative compared to a comparable system. Our approach enables a single multilingual speech recognition model which is competitive to strong individual models. Analysis shows that the latent discrete speech representations are shared across languages with increased sharing for related languages. We hope to catalyze research in low-resource speech understanding by releasing XLSR-53, a large model pretrained in 53 languages.}
      \field{day}{15}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{12}
      \field{pubstate}{prepublished}
      \field{title}{Unsupervised {{Cross-lingual Representation Learning}} for {{Speech Recognition}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2006.13979
      \endverb
      \verb{eprint}
      \verb 2006.13979
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/KQLZCMY9/Conneau et al. - 2020 - Unsupervised Cross-lingual Representation Learning for Speech Recognition.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2006.13979
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2006.13979
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{conneauFLEURSFewshotLearning2022}{online}{}
      \name{author}{9}{}{%
        {{un=0,uniquepart=base,hash=7cf7ac6a9456559cc67ee138c7f21cec}{%
           family={Conneau},
           familyi={C\bibinitperiod},
           given={Alexis},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=32f2d0efd7ab7988edc0ae637e441a81}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Min},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2d5d4d6610084e1ec6ee51ef32df252e}{%
           family={Khanuja},
           familyi={K\bibinitperiod},
           given={Simran},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9a4f4a1ff661cd600eb26523a5ba8bb4}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=21dc628b949090d920cec3c106ae1019}{%
           family={Axelrod},
           familyi={A\bibinitperiod},
           given={Vera},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e102dda6b0e5bf95c65afe90b9454aa2}{%
           family={Dalmia},
           familyi={D\bibinitperiod},
           given={Siddharth},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b137e608b42835dfb224061b97b8aba4}{%
           family={Riesa},
           familyi={R\bibinitperiod},
           given={Jason},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eb8ed9e3bdc50c922825a6193a311b66}{%
           family={Rivera},
           familyi={R\bibinitperiod},
           given={Clara},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=75d3660c3d4af9c1db2372eee7e68746}{%
           family={Bapna},
           familyi={B\bibinitperiod},
           given={Ankur},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{2916bb4d39f814823624e9e16627e23a}
      \strng{fullhash}{b0faa309f6f6531a62185551e776d769}
      \strng{bibnamehash}{b0faa309f6f6531a62185551e776d769}
      \strng{authorbibnamehash}{b0faa309f6f6531a62185551e776d769}
      \strng{authornamehash}{2916bb4d39f814823624e9e16627e23a}
      \strng{authorfullhash}{b0faa309f6f6531a62185551e776d769}
      \field{extraname}{2}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We introduce FLEURS, the Few-shot Learning Evaluation of Universal Representations of Speech benchmark. FLEURS is an n-way parallel speech dataset in 102 languages built on top of the machine translation FLoRes-101 benchmark, with approximately 12 hours of speech supervision per language. FLEURS can be used for a variety of speech tasks, including Automatic Speech Recognition (ASR), Speech Language Identification (Speech LangID), Translation and Retrieval. In this paper, we provide baselines for the tasks based on multilingual pre-trained models like mSLAM. The goal of FLEURS is to enable speech technology in more languages and catalyze research in low-resource speech understanding.}
      \field{day}{25}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{5}
      \field{pubstate}{prepublished}
      \field{shorttitle}{{{FLEURS}}}
      \field{title}{{{FLEURS}}: {{Few-shot Learning Evaluation}} of {{Universal Representations}} of {{Speech}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2205.12446
      \endverb
      \verb{eprint}
      \verb 2205.12446
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/ETIS2DLG/Conneau et al. - 2022 - FLEURS Few-shot Learning Evaluation of Universal Representations of Speech.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2205.12446
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2205.12446
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{deichlerMMConvMultimodalConversational2024}{online}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=cf5e90fa1ca4f9f3962088f5b009c40e}{%
           family={Deichler},
           familyi={D\bibinitperiod},
           given={Anna},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7fdaca3c38da7961e6ce30f62d5fce54}{%
           family={O'Regan},
           familyi={O\bibinitperiod},
           given={Jim},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=360375b5fce1d04c3e8e15b273de2833}{%
           family={Beskow},
           familyi={B\bibinitperiod},
           given={Jonas},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{73fa768409b15075f4120d59e36f4986}
      \strng{fullhash}{0e3f3768bfcb8f4bdef967b87b1a0dfe}
      \strng{bibnamehash}{0e3f3768bfcb8f4bdef967b87b1a0dfe}
      \strng{authorbibnamehash}{0e3f3768bfcb8f4bdef967b87b1a0dfe}
      \strng{authornamehash}{73fa768409b15075f4120d59e36f4986}
      \strng{authorfullhash}{0e3f3768bfcb8f4bdef967b87b1a0dfe}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, we present a novel dataset captured using a VR headset to record conversations between participants within a physics simulator (AI2-THOR). Our primary objective is to extend the field of co-speech gesture generation by incorporating rich contextual information within referential settings. Participants engaged in various conversational scenarios, all based on referential communication tasks. The dataset provides a rich set of multimodal recordings such as motion capture, speech, gaze, and scene graphs. This comprehensive dataset aims to enhance the understanding and development of gesture generation models in 3D scenes by providing diverse and contextually rich data.}
      \field{day}{30}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{9}
      \field{pubstate}{prepublished}
      \field{shorttitle}{{{MM-Conv}}}
      \field{title}{{{MM-Conv}}: {{A Multi-modal Conversational Dataset}} for {{Virtual Humans}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2410.00253
      \endverb
      \verb{eprint}
      \verb 2410.00253
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/M5EG8TE2/Deichler et al. - 2024 - MM-Conv A Multi-modal Conversational Dataset for Virtual Humans.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2410.00253
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2410.00253
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Human-Computer Interaction}
    \endentry
    \entry{matthewdryerWorldAtlasLanguage2024}{dataset}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=b7e65067ded37e5f6af4a7ca6b2ea9bf}{%
           family={Dryer},
           familyi={D\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6554cfb014a9427af44c63f16722a3dd}{%
           family={Haspelmath},
           familyi={H\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b7e65067ded37e5f6af4a7ca6b2ea9bf}{%
           family={Dryer},
           familyi={D\bibinitperiod},
           given={Matthew},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6554cfb014a9427af44c63f16722a3dd}{%
           family={Haspelmath},
           familyi={H\bibinitperiod},
           given={Martin},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \name{namea}{1}{}{%
        {{hash=951238340aa8b7462747dcf6168e4cd3}{%
           family={Forkel},
           familyi={F\bibinitperiod},
           given={Robert},
           giveni={R\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Zenodo}%
      }
      \strng{namehash}{ab2abf2c1f5d3085340249e71171cdeb}
      \strng{fullhash}{bf6e8fe4075d3f99eb0eea37b449b4dd}
      \strng{bibnamehash}{bf6e8fe4075d3f99eb0eea37b449b4dd}
      \strng{authorbibnamehash}{bf6e8fe4075d3f99eb0eea37b449b4dd}
      \strng{authornamehash}{ab2abf2c1f5d3085340249e71171cdeb}
      \strng{authorfullhash}{bf6e8fe4075d3f99eb0eea37b449b4dd}
      \strng{nameabibnamehash}{951238340aa8b7462747dcf6168e4cd3}
      \strng{nameanamehash}{951238340aa8b7462747dcf6168e4cd3}
      \strng{nameafullhash}{951238340aa8b7462747dcf6168e4cd3}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Cite the source of the dataset as: Dryer, Matthew S. \& Haspelmath, Martin (eds.) 2013. The World Atlas of Language Structures Online. Leipzig: Max Planck Institute for Evolutionary Anthropology. (Available online at https://wals.info)}
      \field{day}{18}
      \field{month}{10}
      \field{nameatype}{collaborator}
      \field{title}{The {{World Atlas}} of {{Language Structures Online}}}
      \field{urlday}{8}
      \field{urlmonth}{7}
      \field{urlyear}{2025}
      \field{version}{v2020.4}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.5281/ZENODO.13950591
      \endverb
      \verb{urlraw}
      \verb https://zenodo.org/doi/10.5281/zenodo.13950591
      \endverb
      \verb{url}
      \verb https://zenodo.org/doi/10.5281/zenodo.13950591
      \endverb
      \keyw{cldf:StructureDataset,linguistics}
    \endentry
    \entry{engstrandFonetikensGrunder2004}{book}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=98db60a4e9dce92a3608e34daf6c50f7}{%
           family={Engstrand},
           familyi={E\bibinitperiod},
           given={Olle},
           giveni={O\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Lund}%
      }
      \list{publisher}{1}{%
        {Studentlitteratur}%
      }
      \strng{namehash}{98db60a4e9dce92a3608e34daf6c50f7}
      \strng{fullhash}{98db60a4e9dce92a3608e34daf6c50f7}
      \strng{bibnamehash}{98db60a4e9dce92a3608e34daf6c50f7}
      \strng{authorbibnamehash}{98db60a4e9dce92a3608e34daf6c50f7}
      \strng{authornamehash}{98db60a4e9dce92a3608e34daf6c50f7}
      \strng{authorfullhash}{98db60a4e9dce92a3608e34daf6c50f7}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{978-91-44-04238-1}
      \field{pagetotal}{355}
      \field{title}{Fonetikens Grunder}
      \field{year}{2004}
      \field{dateera}{ce}
    \endentry
    \entry{eskenaziOverviewSpokenLanguage2009}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=331a3b7829f967e10a2c7f54cc1beb31}{%
           family={Eskenazi},
           familyi={E\bibinitperiod},
           given={Maxine},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{331a3b7829f967e10a2c7f54cc1beb31}
      \strng{fullhash}{331a3b7829f967e10a2c7f54cc1beb31}
      \strng{bibnamehash}{331a3b7829f967e10a2c7f54cc1beb31}
      \strng{authorbibnamehash}{331a3b7829f967e10a2c7f54cc1beb31}
      \strng{authornamehash}{331a3b7829f967e10a2c7f54cc1beb31}
      \strng{authorfullhash}{331a3b7829f967e10a2c7f54cc1beb31}
      \field{sortinit}{E}
      \field{sortinithash}{8da8a182d344d5b9047633dfc0cc9131}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper reviews research in spoken language technology for education and more specifically for language learning. It traces the history of the domain and then groups main issues in the interaction with the student. It addresses the modalities of interaction and their implementation issues and algorithms. Then it discusses one user population – children – and an application for them. Finally it has a discussion of overall systems. It can be used as an introduction to the field and a source of reference materials.}
      \field{issn}{01676393}
      \field{journaltitle}{Speech Communication}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{10}
      \field{shortjournal}{Speech Communication}
      \field{title}{An Overview of Spoken Language Technology for Education}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{51}
      \field{year}{2009}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{832\bibrangedash 844}
      \range{pages}{13}
      \verb{doi}
      \verb 10.1016/j.specom.2009.04.005
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/MEGHYA3U/Eskenazi - 2009 - An overview of spoken language technology for education.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639309000673
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639309000673
      \endverb
    \endentry
    \entry{fiscus1997post}{inproceedings}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=5eb94c7444909f6544dafe84917447f3}{%
           family={Fiscus},
           familyi={F\bibinitperiod},
           given={Jonathan\bibnamedelima G},
           giveni={J\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{5eb94c7444909f6544dafe84917447f3}
      \strng{fullhash}{5eb94c7444909f6544dafe84917447f3}
      \strng{bibnamehash}{5eb94c7444909f6544dafe84917447f3}
      \strng{authorbibnamehash}{5eb94c7444909f6544dafe84917447f3}
      \strng{authornamehash}{5eb94c7444909f6544dafe84917447f3}
      \strng{authorfullhash}{5eb94c7444909f6544dafe84917447f3}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{1997 {{IEEE}} Workshop on Automatic Speech Recognition and Understanding Proceedings}
      \field{title}{A Post-Processing System to Yield Reduced Word Error Rates: {{Recognizer}} Output Voting Error Reduction ({{ROVER}})}
      \field{year}{1997}
      \field{dateera}{ce}
      \field{pages}{347\bibrangedash 354}
      \range{pages}{8}
      \verb{file}
      \verb /home/pccady/Zotero/storage/X9QBVI6H/Fiscus - 1997 - A post-processing system to yield reduced word error rates Recognizer output voting error reduction.pdf
      \endverb
    \endentry
    \entry{fuFullTextDependentEnd2021}{online}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=215351f381b0789cbfa01174d2994890}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Kaiqi},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bbfe25a103dc2284a59673717e70d398}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Jones},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=240852ee544f176c02ca5edaf106318f}{%
           family={Ke},
           familyi={K\bibinitperiod},
           given={Dengfeng},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d5474a5562f892dc1a1f5e572721e21}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Yanlu},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74f3067f20603e85bac325f904c6b552}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jinsong},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=86728d3a00a7b01605eba98ae7c69da3}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Binghuai},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e6b4e8588f9bcdd134d10b0c76c02c82}
      \strng{fullhash}{855c893f1a8ba561febceb2c29c9e001}
      \strng{bibnamehash}{855c893f1a8ba561febceb2c29c9e001}
      \strng{authorbibnamehash}{855c893f1a8ba561febceb2c29c9e001}
      \strng{authornamehash}{e6b4e8588f9bcdd134d10b0c76c02c82}
      \strng{authorfullhash}{855c893f1a8ba561febceb2c29c9e001}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, end-to-end mispronunciation detection and diagnosis (MD\&D) systems has become a popular alternative to greatly simplify the model-building process of conventional hybrid DNN-HMM systems by representing complicated modules with a single deep network architecture. In this paper, in order to utilize the prior text in the end-to-end structure, we present a novel text-dependent model which is difference with sed-mdd, the model achieves a fully end-to-end system by aligning the audio with the phoneme sequences of the prior text inside the model through the attention mechanism. Moreover, the prior text as input will be a problem of imbalance between positive and negative samples in the phoneme sequence. To alleviate this problem, we propose three simple data augmentation methods, which effectively improve the ability of model to capture mispronounced phonemes. We conduct experiments on L2ARCTIC, and our best performance improved from 49.29\% to 56.08\% in F-measure metric compared to the CNN-RNN-CTC model.}
      \field{day}{17}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{4}
      \field{pubstate}{prepublished}
      \field{title}{A {{Full Text-Dependent End}} to {{End Mispronunciation Detection}} and {{Diagnosis}} with {{Easy Data Augmentation Techniques}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2104.08428
      \endverb
      \verb{eprint}
      \verb 2104.08428
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/Q9VYFCIG/Fu et al. - 2021 - A Full Text-Dependent End to End Mispronunciation Detection and Diagnosis with Easy Data Augmentatio.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2104.08428
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2104.08428
      \endverb
      \keyw{Computer Science - Computation and Language}
    \endentry
    \entry{gabrieleEnglishInfluenceL2}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=122d45f92fde0703f6ca31c3f18fe13d}{%
           family={Gabriele},
           familyi={G\bibinitperiod},
           given={Jennifer\bibnamedelima C},
           giveni={J\bibinitperiod\bibinitdelim C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{122d45f92fde0703f6ca31c3f18fe13d}
      \strng{fullhash}{122d45f92fde0703f6ca31c3f18fe13d}
      \strng{bibnamehash}{122d45f92fde0703f6ca31c3f18fe13d}
      \strng{authorbibnamehash}{122d45f92fde0703f6ca31c3f18fe13d}
      \strng{authornamehash}{122d45f92fde0703f6ca31c3f18fe13d}
      \strng{authorfullhash}{122d45f92fde0703f6ca31c3f18fe13d}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{English {{Influence}} on {{L2 Speakers}}’ {{Production}} of {{Palatalization}} and {{Velarization}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/Y3E3RFSQ/Gabriele - English Influence on L2 Speakers’ Production of Palatalization and Velarization.pdf
      \endverb
    \endentry
    \entry{gitmanConfidencebasedEnsemblesEndtoEnd2023}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=3ebf1483613fa32fd2310a1840e1479f}{%
           family={Gitman},
           familyi={G\bibinitperiod},
           given={Igor},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ea50ad27e3aeecaaeee4cf5837a6b13a}{%
           family={Lavrukhin},
           familyi={L\bibinitperiod},
           given={Vitaly},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=be6aebc721bfde5ca511ee8447424b5c}{%
           family={Laptev},
           familyi={L\bibinitperiod},
           given={Aleksandr},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=57b6ee8703cf89267a2d51429a4e61a7}{%
           family={Ginsburg},
           familyi={G\bibinitperiod},
           given={Boris},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{c59710d7b0e517579b6b531306dfd0fc}
      \strng{fullhash}{d22d5cd4941d715b4378ca92343ac846}
      \strng{bibnamehash}{d22d5cd4941d715b4378ca92343ac846}
      \strng{authorbibnamehash}{d22d5cd4941d715b4378ca92343ac846}
      \strng{authornamehash}{c59710d7b0e517579b6b531306dfd0fc}
      \strng{authorfullhash}{d22d5cd4941d715b4378ca92343ac846}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The number of end-to-end speech recognition models grows every year. These models are often adapted to new domains or languages resulting in a proliferation of expert systems that achieve great results on target data, while generally showing inferior performance outside of their domain of expertise. We explore combination of such experts via confidence-based ensembles: ensembles of models where only the output of the most-confident model is used. We assume that models’ target data is not available except for a small validation set. We demonstrate effectiveness of our approach with two applications. First, we show that a confidence-based ensemble of 5 monolingual models outperforms a system where model selection is performed via a dedicated language identification block. Second, we demonstrate that it is possible to combine base and adapted models to achieve strong results on both original and target data. We validate all our results on multiple datasets and model architectures.}
      \field{booktitle}{{{INTERSPEECH}} 2023}
      \field{day}{20}
      \field{eprintclass}{eess}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{8}
      \field{title}{Confidence-Based {{Ensembles}} of {{End-to-End Speech Recognition Models}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1414\bibrangedash 1418}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2023-1281
      \endverb
      \verb{eprint}
      \verb 2306.15824
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/HV8PGS5P/Gitman et al. - 2023 - Confidence-based Ensembles of End-to-End Speech Recognition Models.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2306.15824
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2306.15824
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{gongTransformerBasedMultiAspectMultiGranularity2022}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=001add0b14cdbd927a79bb51b1e48332}{%
           family={Gong},
           familyi={G\bibinitperiod},
           given={Yuan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a9aaa25f3317100dc7167c8c44c5f220}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Ziyi},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=10df0031d0c63dbc8bc3fc10eba5151e}{%
           family={Chu},
           familyi={C\bibinitperiod},
           given={Iek-Heng},
           giveni={I\bibinithyphendelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2a1ab9792be24e1401bdb865de053497}{%
           family={Chang},
           familyi={C\bibinitperiod},
           given={Peng},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=079738ec97fefceec5036d7c3657c667}{%
           family={Glass},
           familyi={G\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{d23ffb125862abcdbb865bea4c794f32}
      \strng{fullhash}{24b8a8dd01f47628bcbe2f1b7172e33a}
      \strng{bibnamehash}{24b8a8dd01f47628bcbe2f1b7172e33a}
      \strng{authorbibnamehash}{24b8a8dd01f47628bcbe2f1b7172e33a}
      \strng{authornamehash}{d23ffb125862abcdbb865bea4c794f32}
      \strng{authorfullhash}{24b8a8dd01f47628bcbe2f1b7172e33a}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Automatic pronunciation assessment is an important technology to help self-directed language learners. While pronunciation quality has multiple aspects including accuracy, fluency, completeness, and prosody, previous efforts typically only model one aspect (e.g., accuracy) at one granularity (e.g., at the phoneme-level). In this work, we explore modeling multi-aspect pronunciation assessment at multiple granularities. Specifically, we train a Goodness Of Pronunciation feature-based Transformer (GOPT) with multi-task learning. Experiments show that GOPT achieves the best results on speechocean762 with a public automatic speech recognition (ASR) acoustic model trained on Librispeech. Code at https://github.com/YuanGongND/gopt.}
      \field{booktitle}{{{ICASSP}} 2022 - 2022 {{IEEE International Conference}} on {{Acoustics}}, {{Speech}} and {{Signal Processing}} ({{ICASSP}})}
      \field{day}{23}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{5}
      \field{title}{Transformer-{{Based Multi-Aspect Multi-Granularity Non-Native English Speaker Pronunciation Assessment}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{7262\bibrangedash 7266}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1109/ICASSP43922.2022.9746743
      \endverb
      \verb{eprint}
      \verb 2205.03432
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/BS9CBM4Q/Gong et al. - 2022 - Transformer-Based Multi-Aspect Multi-Granularity Non-Native English Speaker Pronunciation Assessment.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2205.03432
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2205.03432
      \endverb
      \keyw{Computer Science - Machine Learning,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{gravesConnectionistTemporalClassification}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=dfca94b0427da7f9088af596e23b46c0}{%
           family={Graves},
           familyi={G\bibinitperiod},
           given={Alex},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=299d87a73d184d0f2be5c0710ab298e8}{%
           family={Fernandez},
           familyi={F\bibinitperiod},
           given={Santiago},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6ac505680efa9d3591dd05930a13ccd5}{%
           family={Gomez},
           familyi={G\bibinitperiod},
           given={Faustino},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3a004dc2b8b6fb4dd79c5b8c1469da7}{%
           family={Schmidhuber},
           familyi={S\bibinitperiod},
           given={Jurgen},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8b91c8aa3714ffeda8908af3996aa567}
      \strng{fullhash}{f5e5158a9b0b82b5f8db6483b94f8d53}
      \strng{bibnamehash}{f5e5158a9b0b82b5f8db6483b94f8d53}
      \strng{authorbibnamehash}{f5e5158a9b0b82b5f8db6483b94f8d53}
      \strng{authornamehash}{8b91c8aa3714ffeda8908af3996aa567}
      \strng{authorfullhash}{f5e5158a9b0b82b5f8db6483b94f8d53}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Many real-world sequence learning tasks require the prediction of sequences of labels from noisy, unsegmented input data. In speech recognition, for example, an acoustic signal is transcribed into words or sub-word units. Recurrent neural networks (RNNs) are powerful sequence learners that would seem well suited to such tasks. However, because they require pre-segmented training data, and post-processing to transform their outputs into label sequences, their applicability has so far been limited. This paper presents a novel method for training RNNs to label unsegmented sequences directly, thereby solving both problems. An experiment on the TIMIT speech corpus demonstrates its advantages over both a baseline HMM and a hybrid HMM-RNN.}
      \field{langid}{english}
      \field{title}{Connectionist {{Temporal Classiﬁcation}}: {{Labelling Unsegmented Sequence Data}} with {{Recurrent Neural Networks}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/KY7HCUCD/Graves et al. - Connectionist Temporal Classiﬁcation Labelling Unsegmented Sequence Data with Recurrent Neural Netw.pdf
      \endverb
    \endentry
    \entry{guoCalibrationModernNeural2017}{online}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=e053cf028522c39af65dd862da2d8ed1}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={Chuan},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=373d04718ec0efd3786a0e2b6c0adf00}{%
           family={Pleiss},
           familyi={P\bibinitperiod},
           given={Geoff},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=17b6a43f5598c7efd897f9d254090fdd}{%
           family={Sun},
           familyi={S\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=68a0238356fbd88b34be8886f25938a7}{%
           family={Weinberger},
           familyi={W\bibinitperiod},
           given={Kilian\bibnamedelima Q.},
           giveni={K\bibinitperiod\bibinitdelim Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{203b115999f73097be6ab32411fb1f42}
      \strng{fullhash}{f3833eed8ef776fc6c89f407c7d66c34}
      \strng{bibnamehash}{f3833eed8ef776fc6c89f407c7d66c34}
      \strng{authorbibnamehash}{f3833eed8ef776fc6c89f407c7d66c34}
      \strng{authornamehash}{203b115999f73097be6ab32411fb1f42}
      \strng{authorfullhash}{f3833eed8ef776fc6c89f407c7d66c34}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Confidence calibration – the problem of predicting probability estimates representative of the true correctness likelihood – is important for classification models in many applications. We discover that modern neural networks, unlike those from a decade ago, are poorly calibrated. Through extensive experiments, we observe that depth, width, weight decay, and Batch Normalization are important factors influencing calibration. We evaluate the performance of various post-processing calibration methods on state-ofthe-art architectures with image and document classification datasets. Our analysis and experiments not only offer insights into neural network learning, but also provide a simple and straightforward recipe for practical settings: on most datasets, temperature scaling – a singleparameter variant of Platt Scaling – is surprisingly effective at calibrating predictions.}
      \field{day}{3}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{8}
      \field{pubstate}{prepublished}
      \field{title}{On {{Calibration}} of {{Modern Neural Networks}}}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1706.04599
      \endverb
      \verb{eprint}
      \verb 1706.04599
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/M6YFZKNL/Guo et al. - 2017 - On Calibration of Modern Neural Networks.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1706.04599
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1706.04599
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{hansenedwardsPhonologySecondLanguage2008}{book}{}
      \name{editor}{2}{}{%
        {{un=0,uniquepart=base,hash=3dd16e0f4e8ff8fe60fd34532ae2e0c4}{%
           family={Hansen\bibnamedelima Edwards},
           familyi={H\bibinitperiod\bibinitdelim E\bibinitperiod},
           given={Jette\bibnamedelima G.},
           giveni={J\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5ddd09c391536b11783c74f8541474cb}{%
           family={Zampini},
           familyi={Z\bibinitperiod},
           given={Mary\bibnamedelima L.},
           giveni={M\bibinitperiod\bibinitdelim L\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Amsterdam}%
      }
      \list{publisher}{1}{%
        {John Benjamins Publishing Company}%
      }
      \strng{namehash}{9a2db918370eb5df891cff1d22a59699}
      \strng{fullhash}{9a2db918370eb5df891cff1d22a59699}
      \strng{bibnamehash}{9a2db918370eb5df891cff1d22a59699}
      \strng{editorbibnamehash}{9a2db918370eb5df891cff1d22a59699}
      \strng{editornamehash}{9a2db918370eb5df891cff1d22a59699}
      \strng{editorfullhash}{9a2db918370eb5df891cff1d22a59699}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{editor}
      \field{labeltitlesource}{title}
      \field{abstract}{This volume is a collection of 13 chapters, each devoted to a particular issue that is crucial to our understanding of the way learners acquire, learn, and use an L2 sound system. In addition, it spans both theory and application in L2 phonology. The book is divided into three parts, with each section unified by broad thematic content: Part I, “Theoretical Issues and Frameworks in L2 Phonology,” lays the groundwork for examining L2 phonological acquisition. Part II, “Second Language Speech Perception and Production,” examines these two aspects of L2 speech in more detail. Finally, Part III, “Technology, Training, and Curriculum,” bridges the gap between theory and practice. Each chapter examines theoretical frameworks, major research findings (both classic and recent), methodological issues and choices for conducting research in a particular area of L2 phonology, and major implications of the research findings for more general models of language acquisition and/or pedagogy}
      \field{isbn}{978-90-272-4147-4 978-90-272-9139-4}
      \field{langid}{english}
      \field{pagetotal}{1}
      \field{series}{Studies in {{Bilingualism}}}
      \field{title}{Phonology and {{Second Language Acquisition}}}
      \field{year}{2008}
      \field{dateera}{ce}
      \verb{doi}
      \verb 10.1075/sibil.36
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/3N96SQE6/Hansen Edwards and Zampini - 2008 - Phonology and Second Language Acquisition.pdf
      \endverb
    \endentry
    \entry{hardisonSecondlanguageSpokenWord2005}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=1237a296978ca780cea8d988f1c2e8bc}{%
           family={Hardison},
           familyi={H\bibinitperiod},
           given={Debra\bibnamedelima M.},
           giveni={D\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{1237a296978ca780cea8d988f1c2e8bc}
      \strng{fullhash}{1237a296978ca780cea8d988f1c2e8bc}
      \strng{bibnamehash}{1237a296978ca780cea8d988f1c2e8bc}
      \strng{authorbibnamehash}{1237a296978ca780cea8d988f1c2e8bc}
      \strng{authornamehash}{1237a296978ca780cea8d988f1c2e8bc}
      \strng{authorfullhash}{1237a296978ca780cea8d988f1c2e8bc}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Experiments using the gating paradigm investigated the effects of auditory–visual (AV) and auditoryonly perceptual training on second-language spoken-word identification by Japanese and Korean learners of English. Stimuli were familiar bisyllabic words beginning with /p/, /f/, /ô/, /l/, and /s, t, k/ combined with high, low, and rounded vowels. Results support the priming role of visual cues in AV speech processing. Identification was earlier with visual cues and following training, especially for words beginning with /ô/ and /l/, which also showed significant effects of adjacent vowel. For the Japanese, the AV advantage in identifying /ô/- and /l/-initial words was accentuated following training. Findings are discussed within a multimodal episodic model of learning.}
      \field{issn}{0142-7164, 1469-1817}
      \field{journaltitle}{Applied Psycholinguistics}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{4}
      \field{shortjournal}{Applied Psycholinguistics}
      \field{shorttitle}{Second-Language Spoken Word Identification}
      \field{title}{Second-Language Spoken Word Identification: {{Effects}} of Perceptual Training, Visual Cues, and Phonetic Environment}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{26}
      \field{year}{2005}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{579\bibrangedash 596}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1017/S0142716405050319
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/294NNY9V/Hardison - 2005 - Second-language spoken word identification Effects of perceptual training, visual cues, and phoneti.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.cambridge.org/core/product/identifier/S0142716405050319/type/journal_article
      \endverb
      \verb{url}
      \verb https://www.cambridge.org/core/product/identifier/S0142716405050319/type/journal_article
      \endverb
    \endentry
    \entry{hedderichSurveyRecentApproaches2021}{online}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=91d8659efb45fc4b4497af15ad3d09e1}{%
           family={Hedderich},
           familyi={H\bibinitperiod},
           given={Michael\bibnamedelima A.},
           giveni={M\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8da45ea26125cf5fa6868b62f46040e8}{%
           family={Lange},
           familyi={L\bibinitperiod},
           given={Lukas},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8c9a8dad2ae2739191d1554f7597bcdb}{%
           family={Adel},
           familyi={A\bibinitperiod},
           given={Heike},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=647b33fa6024aba71fae94c0b0914c80}{%
           family={Strötgen},
           familyi={S\bibinitperiod},
           given={Jannik},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f440856a11ae15184a2f1802e005ea47}{%
           family={Klakow},
           familyi={K\bibinitperiod},
           given={Dietrich},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4be00ab1a9fdc726558b68fd2ceecdc4}
      \strng{fullhash}{89df11acc283a7c1b578f9dd1a191893}
      \strng{bibnamehash}{89df11acc283a7c1b578f9dd1a191893}
      \strng{authorbibnamehash}{89df11acc283a7c1b578f9dd1a191893}
      \strng{authornamehash}{4be00ab1a9fdc726558b68fd2ceecdc4}
      \strng{authorfullhash}{89df11acc283a7c1b578f9dd1a191893}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep neural networks and huge language models are becoming omnipresent in natural language applications. As they are known for requiring large amounts of training data, there is a growing body of work to improve the performance in low-resource settings. Motivated by the recent fundamental changes towards neural models and the popular pre-train and fine-tune paradigm, we survey promising approaches for low-resource natural language processing. After a discussion about the different dimensions of data availability, we give a structured overview of methods that enable learning when training data is sparse. This includes mechanisms to create additional labeled data like data augmentation and distant supervision as well as transfer learning settings that reduce the need for target supervision. A goal of our survey is to explain how these methods differ in their requirements as understanding them is essential for choosing a technique suited for a specific low-resource setting. Further key aspects of this work are to highlight open issues and to outline promising directions for future research.}
      \field{day}{9}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{4}
      \field{pubstate}{prepublished}
      \field{title}{A {{Survey}} on {{Recent Approaches}} for {{Natural Language Processing}} in {{Low-Resource Scenarios}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2010.12309
      \endverb
      \verb{eprint}
      \verb 2010.12309
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/Q5GCKUZY/Hedderich et al. - 2021 - A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2010.12309
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2010.12309
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Machine Learning}
    \endentry
    \entry{holmbergDesigningAddedPedagogical}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=6583aad132658485530aa56fdfb58564}{%
           family={Holmberg},
           familyi={H\bibinitperiod},
           given={Jörgen},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6583aad132658485530aa56fdfb58564}
      \strng{fullhash}{6583aad132658485530aa56fdfb58564}
      \strng{bibnamehash}{6583aad132658485530aa56fdfb58564}
      \strng{authorbibnamehash}{6583aad132658485530aa56fdfb58564}
      \strng{authornamehash}{6583aad132658485530aa56fdfb58564}
      \strng{authorfullhash}{6583aad132658485530aa56fdfb58564}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In an increasingly digitized world teachers are expected to take on the role of educational designers and use ICT to design in ways that add pedagogical value to teaching and learning. This thesis adopts a design-based research (DBR) approach to: (a) explore and contribute to the educational design processes of teachers of English as a foreign language in their efforts to use ICT for added pedagogical value, (b) examine how ICT is used in educational designs to create/contribute to what the teachers and students describe as added value and (c) explore, problematize and refine DBR as a research approach.}
      \field{langid}{english}
      \field{title}{Designing for Added Pedagogical Value}
      \verb{file}
      \verb /home/pccady/Zotero/storage/EEJTFJTW/Holmberg - Designing for added pedagogical value.pdf
      \endverb
    \endentry
    \entry{homaRoleFeedbackCategory}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=952f4614294187a17cfb180a48c1864e}{%
           family={Homa},
           familyi={H\bibinitperiod},
           given={Donald},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b7339547b5f9965efcf39a1d627a7556}{%
           family={Cultice},
           familyi={C\bibinitperiod},
           given={Joan},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{862b9b6c8d1c70386050a0c47c08b191}
      \strng{fullhash}{862b9b6c8d1c70386050a0c47c08b191}
      \strng{bibnamehash}{862b9b6c8d1c70386050a0c47c08b191}
      \strng{authorbibnamehash}{862b9b6c8d1c70386050a0c47c08b191}
      \strng{authornamehash}{862b9b6c8d1c70386050a0c47c08b191}
      \strng{authorfullhash}{862b9b6c8d1c70386050a0c47c08b191}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{Role of {{Feedback}}, {{Category Size}}, and {{Stimulus Distortion}} on the {{Acquisition}} and {{Utilization}} of {{Ill-Defined Categories}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/C5I8E6D7/Homa and Cultice - Role of Feedback, Category Size, and Stimulus Distortion on the Acquisition and Utilization of Ill-D.pdf
      \endverb
    \endentry
    \entry{hosseini-kivananiExperimentsASRbasedMispronunciation2021}{online}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=ac27c61f8989e5bbaa9cccee1ef8d16d}{%
           family={Hosseini-Kivanani},
           familyi={H\bibinithyphendelim K\bibinitperiod},
           given={Nina},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=58d790cbe184ff4775b871b9de7c3ea8}{%
           family={Gretter},
           familyi={G\bibinitperiod},
           given={Roberto},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c481c9fa52dbd24e8ded8dbb342e01d}{%
           family={Matassoni},
           familyi={M\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9da6b08608132a8cded2a3143992ae7b}{%
           family={Falavigna},
           familyi={F\bibinitperiod},
           given={Giuseppe\bibnamedelima Daniele},
           giveni={G\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eb7f049609e7be33fae4b9c721296d03}
      \strng{fullhash}{21d20f95559d8a62ac7044ff48690d73}
      \strng{bibnamehash}{21d20f95559d8a62ac7044ff48690d73}
      \strng{authorbibnamehash}{21d20f95559d8a62ac7044ff48690d73}
      \strng{authornamehash}{eb7f049609e7be33fae4b9c721296d03}
      \strng{authorfullhash}{21d20f95559d8a62ac7044ff48690d73}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Pronunciation is one of the fundamentals of language learning, and it is considered a primary factor of spoken language when it comes to an understanding and being understood by others. The persistent presence of high error rates in speech recognition domains resulting from mispronunciations motivates us to find alternative techniques for handling mispronunciations. In this study, we develop a mispronunciation assessment system that checks the pronunciation of non-native English speakers, identifies the commonly mispronounced phonemes of Italian learners of English, and presents an evaluation of the non-native pronunciation observed in phonetically annotated speech corpora. In this work, to detect mispronunciations, we used a phonebased ASR implemented using Kaldi. We used two non-native English labeled corpora; (i) a corpus of Italian adults contains 5,867 utterances from 46 speakers, and (ii) a corpus of Italian children consists of 5,268 utterances from 78 children. Our results show that the selected error model can discriminate correct sounds from incorrect sounds in both native and nonnative speech, and therefore can be used to detect pronunciation errors in non-native speech. The phone error rates show improvement in using the error language model. The ASR system shows better accuracy after applying the error model on our selected corpora.}
      \field{day}{13}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{4}
      \field{pubstate}{prepublished}
      \field{title}{Experiments of {{ASR-based}} Mispronunciation Detection for Children and Adult {{English}} Learners}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2104.05980
      \endverb
      \verb{eprint}
      \verb 2104.05980
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/53ZL62HN/Hosseini-Kivanani et al. - 2021 - Experiments of ASR-based mispronunciation detection for children and adult English learners.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2104.05980
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2104.05980
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{hsuHuBERTSelfSupervisedSpeech2021}{online}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=caee6b3fa31c9aa140f1d90048cd989f}{%
           family={Hsu},
           familyi={H\bibinitperiod},
           given={Wei-Ning},
           giveni={W\bibinithyphendelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8e0d00886ab46e79f17cbbd99093776a}{%
           family={Bolte},
           familyi={B\bibinitperiod},
           given={Benjamin},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f9e97a0bc44d64b5d4fc88fedad3d436}{%
           family={Tsai},
           familyi={T\bibinitperiod},
           given={Yao-Hung\bibnamedelima Hubert},
           giveni={Y\bibinithyphendelim H\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=90da1abde84b45ee8f620c681a9f2088}{%
           family={Lakhotia},
           familyi={L\bibinitperiod},
           given={Kushal},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bd2be300d445e9f6db7808f9533e66cb}{%
           family={Salakhutdinov},
           familyi={S\bibinitperiod},
           given={Ruslan},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=838ae213145f7410d963d9727504b2df}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Abdelrahman},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4e8ebcacf4e5cfddb426ee437ac5b2dd}
      \strng{fullhash}{292191d3de884a85de06f22ef470da19}
      \strng{bibnamehash}{292191d3de884a85de06f22ef470da19}
      \strng{authorbibnamehash}{292191d3de884a85de06f22ef470da19}
      \strng{authornamehash}{4e8ebcacf4e5cfddb426ee437ac5b2dd}
      \strng{authorfullhash}{292191d3de884a85de06f22ef470da19}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Self-supervised approaches for speech representation learning are challenged by three unique problems: (1) there are multiple sound units in each input utterance, (2) there is no lexicon of input sound units during the pre-training phase, and (3) sound units have variable lengths with no explicit segmentation. To deal with these three problems, we propose the Hidden-Unit BERT (HuBERT) approach for self-supervised speech representation learning, which utilizes an offline clustering step to provide aligned target labels for a BERT-like prediction loss. A key ingredient of our approach is applying the prediction loss over the masked regions only, which forces the model to learn a combined acoustic and language model over the continuous inputs. HuBERT relies primarily on the consistency of the unsupervised clustering step rather than the intrinsic quality of the assigned cluster labels. Starting with a simple k-means teacher of 100 clusters, and using two iterations of clustering, the HuBERT model either matches or improves upon the state-of-the-art wav2vec 2.0 performance on the Librispeech (960h) and Libri-light (60,000h) benchmarks with 10min, 1h, 10h, 100h, and 960h fine-tuning subsets. Using a 1B parameter model, HuBERT shows up to 19\% and 13\% relative WER reduction on the more challenging dev-other and test-other evaluation subsets.}
      \field{day}{14}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{6}
      \field{pubstate}{prepublished}
      \field{shorttitle}{{{HuBERT}}}
      \field{title}{{{HuBERT}}: {{Self-Supervised Speech Representation Learning}} by {{Masked Prediction}} of {{Hidden Units}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2106.07447
      \endverb
      \verb{eprint}
      \verb 2106.07447
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/M6Q5JU52/Hsu et al. - 2021 - HuBERT Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2106.07447
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2106.07447
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{islamExploringSpeechRepresentations2023}{inproceedings}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=ee7a17ae0947f6263297313c2e978f78}{%
           family={Islam},
           familyi={I\bibinitperiod},
           given={Elaf},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8e3c30f7f193c73c0ce4a7e46cc9728a}{%
           family={Park},
           familyi={P\bibinitperiod},
           given={Chanho},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d2c122385cc21071982b3bbc486387f}{%
           family={Hain},
           familyi={H\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{cd56d1175bed4470e0fcd9633851a67c}
      \strng{fullhash}{033e85041f6c3d0c8216cb5ab8e7327d}
      \strng{bibnamehash}{033e85041f6c3d0c8216cb5ab8e7327d}
      \strng{authorbibnamehash}{033e85041f6c3d0c8216cb5ab8e7327d}
      \strng{authornamehash}{cd56d1175bed4470e0fcd9633851a67c}
      \strng{authorfullhash}{033e85041f6c3d0c8216cb5ab8e7327d}
      \field{sortinit}{I}
      \field{sortinithash}{8d291c51ee89b6cd86bf5379f0b151d8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Automatic proficiency assessment can be a useful tool in language learning, for self-evaluation of language skills and to enable educators to tailor instruction effectively. Often assessment methods use categorisation approaches. In this paper an exemplar based approach is chosen, and comparisons between utterances are made using different speech encodings. Such an approach has the advantage to avoid formal categorisation of errors by experts. Aside from a standard spectral representation pretrained model embeddings are investigated for the usefulness for this task. Experiments are conducted using speechocean762 database, which provides 3 levels of proficiency. Data was clustered and performance of different representations is assessed in terms of cluster purity as well as categorisation correctness. Cosine distance with Whisper representations yielded better clustering performance.}
      \field{booktitle}{9th {{Workshop}} on {{Speech}} and {{Language Technology}} in {{Education}} ({{SLaTE}})}
      \field{day}{18}
      \field{eventtitle}{9th {{Workshop}} on {{Speech}} and {{Language Technology}} in {{Education}} ({{SLaTE}})}
      \field{langid}{english}
      \field{month}{8}
      \field{title}{Exploring {{Speech Representations}} for {{Proficiency Assessment}} in {{Language Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{151\bibrangedash 155}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/SLaTE.2023-29
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/5SWSP8ZI/Islam et al. - 2023 - Exploring Speech Representations for Proficiency Assessment in Language Learning.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/slate_2023/islam23_slate.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/slate_2023/islam23_slate.html
      \endverb
    \endentry
    \entry{jalalvandAutomaticQualityEstimation2018}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=d2b3ec13bd980b44ffda8a0923293676}{%
           family={Jalalvand},
           familyi={J\bibinitperiod},
           given={Shahab},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0f16b299409e285e906d16569d6b44af}{%
           family={Negri},
           familyi={N\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=121cc06517329fdc64d0d73a86f9d3f0}{%
           family={Falavigna},
           familyi={F\bibinitperiod},
           given={Daniele},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7c481c9fa52dbd24e8ded8dbb342e01d}{%
           family={Matassoni},
           familyi={M\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=abebe32f4d5b1a29c5f5dddab4544482}{%
           family={Turchi},
           familyi={T\bibinitperiod},
           given={Marco},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{9493c99e83ed487c697da85f480eb289}
      \strng{fullhash}{cd99c8ab182e8289998d87d6bf73f631}
      \strng{bibnamehash}{cd99c8ab182e8289998d87d6bf73f631}
      \strng{authorbibnamehash}{cd99c8ab182e8289998d87d6bf73f631}
      \strng{authornamehash}{9493c99e83ed487c697da85f480eb289}
      \strng{authorfullhash}{cd99c8ab182e8289998d87d6bf73f631}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recognizer Output Voting Error Reduction (ROVER) has been widely used for system combination in automatic speech recognition (ASR). In order to select the most appropriate words to insert at each position in the output transcriptions, some ROVER extensions rely on critical information such as confidence scores and other ASR decoder features. This information, which is not always available, highly depends on the decoding process and sometimes tends to overestimate the real quality of the recognized words. In this paper we propose a novel variant of ROVER that takes advantage of ASR quality estimation (QE) for ranking the transcriptions at “segment level” instead of: i) relying on confidence scores, or ii) feeding ROVER with randomly ordered hypotheses. We first introduce an effective set of features to compensate for the absence of ASR decoder information. Then, we apply QE techniques to perform accurate hypothesis ranking at segment-level before starting the fusion process. The evaluation is carried out on two different tasks, in which we respectively combine hypotheses coming from independent ASR systems and multi-microphone recordings. In both tasks, it is assumed that the ASR decoder information is not available. The proposed approach significantly outperforms standard ROVER and it is competitive with two strong oracles that exploit prior knowledge about the real quality of the hypotheses to be combined. Compared to standard ROVER, the absolute WER improvements in the two evaluation scenarios range from 0.5\% to 7.3\%.}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{issn}{08852308}
      \field{journaltitle}{Computer Speech \& Language}
      \field{langid}{english}
      \field{month}{1}
      \field{shortjournal}{Computer Speech \& Language}
      \field{title}{Automatic {{Quality Estimation}} for {{ASR System Combination}}}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{volume}{47}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{214\bibrangedash 239}
      \range{pages}{26}
      \verb{doi}
      \verb 10.1016/j.csl.2017.06.003
      \endverb
      \verb{eprint}
      \verb 1706.07238
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/T4J62QNS/Jalalvand et al. - 2018 - Automatic Quality Estimation for ASR System Combination.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1706.07238
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1706.07238
      \endverb
      \keyw{Computer Science - Computation and Language}
    \endentry
    \entry{joshiStateFateLinguistic2021}{online}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=a71c462a03a7d6e462146be99aa2198b}{%
           family={Joshi},
           familyi={J\bibinitperiod},
           given={Pratik},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d360ddafdeee83df8cf1fd9284e3b834}{%
           family={Santy},
           familyi={S\bibinitperiod},
           given={Sebastin},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1d88603e0d71dfb04a604b7a2c8fdf1c}{%
           family={Budhiraja},
           familyi={B\bibinitperiod},
           given={Amar},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4e7a16b33b42e17420a922fd0fca193b}{%
           family={Bali},
           familyi={B\bibinitperiod},
           given={Kalika},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7a7a17fc7626c6be3b71a694952301e6}{%
           family={Choudhury},
           familyi={C\bibinitperiod},
           given={Monojit},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{f5e11edfa5aa66430b2f7eda7b4fdb00}
      \strng{fullhash}{1a8cf437fd3c8babf4a66fe90d7e24b0}
      \strng{bibnamehash}{1a8cf437fd3c8babf4a66fe90d7e24b0}
      \strng{authorbibnamehash}{1a8cf437fd3c8babf4a66fe90d7e24b0}
      \strng{authornamehash}{f5e11edfa5aa66430b2f7eda7b4fdb00}
      \strng{authorfullhash}{1a8cf437fd3c8babf4a66fe90d7e24b0}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Language technologies contribute to promoting multilingualism and linguistic diversity around the world. However, only a very small number of the over 7000 languages of the world are represented in the rapidly evolving language technologies and applications. In this paper we look at the relation between the types of languages, resources, and their representation in NLP conferences to understand the trajectory that different languages have followed over time. Our quantitative investigation underlines the disparity between languages, especially in terms of their resources, and calls into question the “language agnostic” status of current models and systems. Through this paper, we attempt to convince the ACL community to prioritise the resolution of the predicaments highlighted here, so that no language is left behind.}
      \field{day}{27}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{1}
      \field{pubstate}{prepublished}
      \field{title}{The {{State}} and {{Fate}} of {{Linguistic Diversity}} and {{Inclusion}} in the {{NLP World}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2004.09095
      \endverb
      \verb{eprint}
      \verb 2004.09095
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/LSSBQHM5/Joshi et al. - 2021 - The State and Fate of Linguistic Diversity and Inclusion in the NLP World.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2004.09095
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2004.09095
      \endverb
      \keyw{Computer Science - Computation and Language}
    \endentry
    \entry{kheirMispronunciationDetectionSpeechBlender}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=4cb51d7a0e9fedd9d43f0e738aedbdcb}{%
           family={Kheir},
           familyi={K\bibinitperiod},
           given={Yassine\bibnamedelima EL},
           giveni={Y\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4cb51d7a0e9fedd9d43f0e738aedbdcb}
      \strng{fullhash}{4cb51d7a0e9fedd9d43f0e738aedbdcb}
      \strng{bibnamehash}{4cb51d7a0e9fedd9d43f0e738aedbdcb}
      \strng{authorbibnamehash}{4cb51d7a0e9fedd9d43f0e738aedbdcb}
      \strng{authornamehash}{4cb51d7a0e9fedd9d43f0e738aedbdcb}
      \strng{authorfullhash}{4cb51d7a0e9fedd9d43f0e738aedbdcb}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{Mispronunciation {{Detection}} with {{SpeechBlender Data Augmentation Pipeline}}.}
      \verb{file}
      \verb /home/pccady/Zotero/storage/AERWL4YF/Kheir - Mispronunciation Detection with SpeechBlender Data Augmentation Pipeline..pdf
      \endverb
    \endentry
    \entry{kheirAutomaticPronunciationAssessment2023}{online}{}
      \name{author}{3}{ul=2}{%
        {{un=0,uniquepart=base,hash=a6f9b8f7fe4d6b1a66162ee44f2f18bc}{%
           family={Kheir},
           familyi={K\bibinitperiod},
           given={Yassine\bibnamedelima El},
           giveni={Y\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fc6b779fd58dd748836db7347acb08d6}{%
           family={Ali},
           familyi={A\bibinitperiod},
           given={Ahmed},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b4bface8fc882cc6891c3e6e6b84f1f5}{%
           family={Chowdhury},
           familyi={C\bibinitperiod},
           given={Shammur\bibnamedelima Absar},
           giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6cb08b2639438992435ed85b96605304}
      \strng{fullhash}{751b2acd09a98d6b04bf6ec1a7867d8d}
      \strng{bibnamehash}{751b2acd09a98d6b04bf6ec1a7867d8d}
      \strng{authorbibnamehash}{751b2acd09a98d6b04bf6ec1a7867d8d}
      \strng{authornamehash}{6cb08b2639438992435ed85b96605304}
      \strng{authorfullhash}{751b2acd09a98d6b04bf6ec1a7867d8d}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Pronunciation assessment and its application in computer-aided pronunciation training (CAPT) have seen impressive progress in recent years. With the rapid growth in language processing and deep learning over the past few years, there is a need for an updated review. In this paper, we review methods employed in pronunciation assessment for both phonemic and prosodic. We categorize the main challenges observed in prominent research trends, and highlight existing limitations, and available resources. This is followed by a discussion of the remaining challenges and possible directions for future work.}
      \field{day}{21}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{10}
      \field{pubstate}{prepublished}
      \field{title}{Automatic {{Pronunciation Assessment}} -- {{A Review}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2310.13974
      \endverb
      \verb{eprint}
      \verb 2310.13974
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/8VY2N9BF/Kheir et al. - 2023 - Automatic Pronunciation Assessment -- A Review.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2310.13974
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2310.13974
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{kheirL1awareMultilingualMispronunciation2023}{online}{}
      \name{author}{3}{ul=2}{%
        {{un=0,uniquepart=base,hash=a6f9b8f7fe4d6b1a66162ee44f2f18bc}{%
           family={Kheir},
           familyi={K\bibinitperiod},
           given={Yassine\bibnamedelima El},
           giveni={Y\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b4bface8fc882cc6891c3e6e6b84f1f5}{%
           family={Chowdhury},
           familyi={C\bibinitperiod},
           given={Shammur\bibnamedelima Absar},
           giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fc6b779fd58dd748836db7347acb08d6}{%
           family={Ali},
           familyi={A\bibinitperiod},
           given={Ahmed},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3f413ce86c20e6dd585556f8a69774fb}
      \strng{fullhash}{852fba2d0ab9ceed3c2f1f4d52171a44}
      \strng{bibnamehash}{852fba2d0ab9ceed3c2f1f4d52171a44}
      \strng{authorbibnamehash}{852fba2d0ab9ceed3c2f1f4d52171a44}
      \strng{authornamehash}{3f413ce86c20e6dd585556f8a69774fb}
      \strng{authorfullhash}{852fba2d0ab9ceed3c2f1f4d52171a44}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The phonological discrepancies between a speaker’s native (L1) and the non-native language (L2) serves as a major factor for mispronunciation. This paper introduces a novel multilingual MDD architecture, L1-MultiMDD, enriched with L1aware speech representation. An end-to-end speech encoder is trained on the input signal and its corresponding reference phoneme sequence. First, an attention mechanism is deployed to align the input audio with the reference phoneme sequence. Afterwards, the L1-L2-speech embedding are extracted from an auxiliary model, pretrained in a multi-task setup identifying L1 and L2 language, and are infused with the primary network. Finally, the L1-MultiMDD is then optimized for a unified multilingual phoneme recognition task using connectionist temporal classification (CTC) loss for the target languages: English, Arabic, and Mandarin. Our experiments demonstrate the effectiveness of the proposed L1-MultiMDD framework on both seen – L2-ARTIC, LATIC, and AraVoiceL2v2; and unseen – EpaDB and Speechocean762 datasets. The consistent gains in PER, and false rejection rate (FRR) across all target languages confirm our approach’s robustness, efficacy, and generalizability.}
      \field{day}{21}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{9}
      \field{pubstate}{prepublished}
      \field{title}{L1-Aware {{Multilingual Mispronunciation Detection Framework}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2309.07719
      \endverb
      \verb{eprint}
      \verb 2309.07719
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/JYTSEG3W/Kheir et al. - 2023 - L1-aware Multilingual Mispronunciation Detection Framework.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2309.07719
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2309.07719
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{kimAutomaticPronunciationAssessment2022}{online}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=d21296dd6c908a3b237293b211d496a0}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Eesung},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5384447d74ce42f82b7afadb759b9753}{%
           family={Jeon},
           familyi={J\bibinitperiod},
           given={Jae-Jin},
           giveni={J\bibinithyphendelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=633e9ada45dde6fa66fe3ad40c04fc00}{%
           family={Seo},
           familyi={S\bibinitperiod},
           given={Hyeji},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b87a4c1df5dd642082f7c8794a6f755f}{%
           family={Kim},
           familyi={K\bibinitperiod},
           given={Hoon},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ab672ad643eedfde144be2803f9ce80f}
      \strng{fullhash}{3ffb15545496a763b1d587a4f65c76b3}
      \strng{bibnamehash}{3ffb15545496a763b1d587a4f65c76b3}
      \strng{authorbibnamehash}{3ffb15545496a763b1d587a4f65c76b3}
      \strng{authornamehash}{ab672ad643eedfde144be2803f9ce80f}
      \strng{authorfullhash}{3ffb15545496a763b1d587a4f65c76b3}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Self-supervised learning (SSL) approaches such as wav2vec 2.0 and HuBERT models have shown promising results in various downstream tasks in the speech community. In particular, speech representations learned by SSL models have been shown to be effective for encoding various speech-related characteristics. In this context, we propose a novel automatic pronunciation assessment method based on SSL models. First, the proposed method fine-tunes the pre-trained SSL models with connectionist temporal classification to adapt the English pronunciation of English-as-a-second-language (ESL) learners in a data environment. Then, the layer-wise contextual representations are extracted from all across the transformer layers of the SSL models. Finally, the automatic pronunciation score is estimated using bidirectional long short-term memory with the layer-wise contextual representations and the corresponding text. We show that the proposed SSL model-based methods outperform the baselines, in terms of the Pearson correlation coefficient, on datasets of Korean ESL learner children and Speechocean762. Furthermore, we analyze how different representations of transformer layers in the SSL model affect the performance of the pronunciation assessment task.}
      \field{day}{8}
      \field{eprintclass}{eess}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{4}
      \field{pubstate}{prepublished}
      \field{title}{Automatic {{Pronunciation Assessment}} Using {{Self-Supervised Speech Representation Learning}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2204.03863
      \endverb
      \verb{eprint}
      \verb 2204.03863
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/BMDC8LPB/Kim et al. - 2022 - Automatic Pronunciation Assessment using Self-Supervised Speech Representation Learning.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2204.03863
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2204.03863
      \endverb
      \keyw{Computer Science - Computation and Language,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{korzekwaComputerassistedPronunciationTraining2022}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=d6f2d5b085340bf4faa87e419694bf1f}{%
           family={Korzekwa},
           familyi={K\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=487dee4d02326569c9a3d5dfb62c6c98}{%
           family={Lorenzo-Trueba},
           familyi={L\bibinithyphendelim T\bibinitperiod},
           given={Jaime},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cc1e00c8800b9aa1412d2b25783a3844}{%
           family={Drugman},
           familyi={D\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8b9471c61598bbd36a32ca75fcec3d10}{%
           family={Kostek},
           familyi={K\bibinitperiod},
           given={Bozena},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Elsevier BV}%
      }
      \strng{namehash}{61bf961fdab359db9c94d8ba6aa2a305}
      \strng{fullhash}{db2716b7a9e4575980bf8d8a5e9b899c}
      \strng{bibnamehash}{db2716b7a9e4575980bf8d8a5e9b899c}
      \strng{authorbibnamehash}{db2716b7a9e4575980bf8d8a5e9b899c}
      \strng{authornamehash}{61bf961fdab359db9c94d8ba6aa2a305}
      \strng{authorfullhash}{db2716b7a9e4575980bf8d8a5e9b899c}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0167-6393}
      \field{journaltitle}{Speech Communication}
      \field{langid}{english}
      \field{month}{7}
      \field{title}{Computer-Assisted Pronunciation Training—{{Speech}} Synthesis Is Almost All You Need}
      \field{urlday}{18}
      \field{urlmonth}{7}
      \field{urlyear}{2025}
      \field{volume}{142}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{22\bibrangedash 33}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1016/j.specom.2022.06.003
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/QCIRJ73S/Korzekwa et al. - 2022 - Computer-assisted pronunciation training—Speech synthesis is almost all you need.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639322000863
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639322000863
      \endverb
    \endentry
    \entry{krishenbaumRepresentingIPAPhonetics}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=f107db57a1c2a2c1c7eb35f51fa0bf81}{%
           family={Krishenbaum},
           familyi={K\bibinitperiod},
           given={Evan},
           giveni={E\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{f107db57a1c2a2c1c7eb35f51fa0bf81}
      \strng{fullhash}{f107db57a1c2a2c1c7eb35f51fa0bf81}
      \strng{bibnamehash}{f107db57a1c2a2c1c7eb35f51fa0bf81}
      \strng{authorbibnamehash}{f107db57a1c2a2c1c7eb35f51fa0bf81}
      \strng{authornamehash}{f107db57a1c2a2c1c7eb35f51fa0bf81}
      \strng{authorfullhash}{f107db57a1c2a2c1c7eb35f51fa0bf81}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{Representing {{IPA Phonetics}} in {{ASCII}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/D8A9W6JI/Krishenbaum - Representing IPA Phonetics in ASCII.pdf
      \endverb
    \endentry
    \entry{kurzingerCTCSegmentationLargeCorpora2020}{incollection}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=52ff54aeb792c96bdcd0b0f11c659470}{%
           family={Kürzinger},
           familyi={K\bibinitperiod},
           given={Ludwig},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7930df42e2a02b65ff17fd97475eb7dc}{%
           family={Winkelbauer},
           familyi={W\bibinitperiod},
           given={Dominik},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2c3a631af7f3bf630f6f920c8798901f}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Lujun},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=984f7218784a616fbd2673d27be32625}{%
           family={Watzel},
           familyi={W\bibinitperiod},
           given={Tobias},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a412590ea8e1a24b3b627f33dce92dc1}{%
           family={Rigoll},
           familyi={R\bibinitperiod},
           given={Gerhard},
           giveni={G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{2d09ee0d421b102f591039749f14b5b2}
      \strng{fullhash}{01e813e9dc7fd1000eff27e98be6813f}
      \strng{bibnamehash}{01e813e9dc7fd1000eff27e98be6813f}
      \strng{authorbibnamehash}{01e813e9dc7fd1000eff27e98be6813f}
      \strng{authornamehash}{2d09ee0d421b102f591039749f14b5b2}
      \strng{authorfullhash}{01e813e9dc7fd1000eff27e98be6813f}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent end-to-end Automatic Speech Recognition (ASR) systems demonstrated the ability to outperform conventional hybrid DNN/ HMM ASR. Aside from architectural improvements in those systems, those models grew in terms of depth, parameters and model capacity. However, these models also require more training data to achieve comparable performance.}
      \field{eprintclass}{eess}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{title}{{{CTC-Segmentation}} of {{Large Corpora}} for {{German End-to-end Speech Recognition}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{12335}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{267\bibrangedash 278}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1007/978-3-030-60276-5_27
      \endverb
      \verb{eprint}
      \verb 2007.09127
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/RGBGBXLM/Kürzinger et al. - 2020 - CTC-Segmentation of Large Corpora for German End-to-end Speech Recognition.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2007.09127
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2007.09127
      \endverb
      \keyw{Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{kyriakopoulosDeepLearningApproach2018}{inproceedings}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=f7905855e7c2a7c134a48366b0b23126}{%
           family={Kyriakopoulos},
           familyi={K\bibinitperiod},
           given={Konstantinos},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bdb7e082d3678df5470cdf666725c108}{%
           family={Knill},
           familyi={K\bibinitperiod},
           given={Kate},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=54986a9bb01d4bd90e3a54428665980f}{%
           family={Gales},
           familyi={G\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{c8eaaf94516ba10b3233e6c5c898dab7}
      \strng{fullhash}{e00d5293cfbc0c4ef25283fa45c5b960}
      \strng{bibnamehash}{e00d5293cfbc0c4ef25283fa45c5b960}
      \strng{authorbibnamehash}{e00d5293cfbc0c4ef25283fa45c5b960}
      \strng{authornamehash}{c8eaaf94516ba10b3233e6c5c898dab7}
      \strng{authorfullhash}{e00d5293cfbc0c4ef25283fa45c5b960}
      \field{sortinit}{K}
      \field{sortinithash}{c02bf6bff1c488450c352b40f5d853ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The way a non-native speaker pronounces the phones of a language is an important predictor of their proficiency. In grading spontaneous speech, the pairwise distances between generative statistical models trained on each phone have been shown to be powerful features. This paper presents a deep learning alternative to model-based phone distances in the form of a tunable Siamese network feature extractor to extract distance metrics directly from the audio frame sequence. Features are extracted at the phone instance level and combined to phone-level representations using an attention mechanism. Pair-wise distances between phone features are then projected through a feed-forward layer to predict score. The extraction stage is initialised on either a binary phone instance-pair classification task, or to mimic the model-based features, then the whole system is fine-tuned end-to-end, optimising the learning of the distance metric to the score prediction task. This method is therefore more adaptable and more sensitive to phone instance level phenomena. Its performance is compared against a DNN trained on Gaussian phone model distance features.}
      \field{booktitle}{Interspeech 2018}
      \field{day}{2}
      \field{eventtitle}{Interspeech 2018}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{A {{Deep Learning Approach}} to {{Assessing Non-native Pronunciation}} of {{English Using Phone Distances}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1626\bibrangedash 1630}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2018-1087
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/8835LD4X/Kyriakopoulos et al. - 2018 - A Deep Learning Approach to Assessing Non-native Pronunciation of English Using Phone Distances.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2018/kyriakopoulos18_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2018/kyriakopoulos18_interspeech.html
      \endverb
    \endentry
    \entry{leeMassivelyMultilingualPronunciation}{article}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=5748c2b892be1d82413c87f22fc1ca6a}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Jackson\bibnamedelima L},
           giveni={J\bibinitperiod\bibinitdelim L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d7e4ef8024316ea3b6b4dbf372bf07bd}{%
           family={Ashby},
           familyi={A\bibinitperiod},
           given={Lucas\bibnamedelimb F\bibnamedelima E},
           giveni={L\bibinitperiod\bibinitdelim F\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b3c00e4fb3d470ebb763c0a8960d84e8}{%
           family={Garza},
           familyi={G\bibinitperiod},
           given={M\bibnamedelima Elizabeth},
           giveni={M\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5f05b63a39ed7d702e7ab066835c1018}{%
           family={Lee-Sikka},
           familyi={L\bibinithyphendelim S\bibinitperiod},
           given={Yeonju},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9cf3c55965c2ebbe8630bf89dfb072e6}{%
           family={Miller},
           familyi={M\bibinitperiod},
           given={Sean},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f6c96f7512f062c016f4319a5d30ef02}{%
           family={Wong},
           familyi={W\bibinitperiod},
           given={Alan},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=264375f1d2aa510997e3012558f9fb6d}{%
           family={McCarthy},
           familyi={M\bibinitperiod},
           given={Arya\bibnamedelima D},
           giveni={A\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0f46b782a9c4717a7bd161c47f4e57a4}{%
           family={Gorman},
           familyi={G\bibinitperiod},
           given={Kyle},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{63341672a062cb05e50c91b60b0faf28}
      \strng{fullhash}{45582dcb56e8a934576879eb550c20e5}
      \strng{bibnamehash}{45582dcb56e8a934576879eb550c20e5}
      \strng{authorbibnamehash}{45582dcb56e8a934576879eb550c20e5}
      \strng{authornamehash}{63341672a062cb05e50c91b60b0faf28}
      \strng{authorfullhash}{45582dcb56e8a934576879eb550c20e5}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce WikiPron, an open-source command-line tool for extracting pronunciation data from Wiktionary, a collaborative multilingual online dictionary. We first describe the design and use of WikiPron. We then discuss the challenges faced scaling this tool to create an automatically-generated database of 1.7 million pronunciations from 165 languages. Finally, we validate the pronunciation database by using it to train and evaluating a collection of generic grapheme-to-phoneme models. The software, pronunciation data, and models are all made available under permissive open-source licenses.}
      \field{langid}{english}
      \field{title}{Massively {{Multilingual Pronunciation Mining}} with {{WikiPron}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/H79IA2SE/Lee et al. - Massively Multilingual Pronunciation Mining with WikiPron.pdf
      \endverb
    \endentry
    \entry{levisCOMPUTERTECHNOLOGYTEACHING2007}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=224bb0e557cdfc275a192894f9c32603}{%
           family={Levis},
           familyi={L\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{224bb0e557cdfc275a192894f9c32603}
      \strng{fullhash}{224bb0e557cdfc275a192894f9c32603}
      \strng{bibnamehash}{224bb0e557cdfc275a192894f9c32603}
      \strng{authorbibnamehash}{224bb0e557cdfc275a192894f9c32603}
      \strng{authornamehash}{224bb0e557cdfc275a192894f9c32603}
      \strng{authorfullhash}{224bb0e557cdfc275a192894f9c32603}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0267-1905, 1471-6356}
      \field{journaltitle}{Annual Review of Applied Linguistics}
      \field{langid}{english}
      \field{month}{3}
      \field{shortjournal}{APL}
      \field{title}{{{COMPUTER TECHNOLOGY IN TEACHING AND RESEARCHING PRONUNCIATION}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{27}
      \field{year}{2007}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.1017/S0267190508070098
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/BDRESYKU/Levis - 2007 - COMPUTER TECHNOLOGY IN TEACHING AND RESEARCHING PRONUNCIATION.pdf
      \endverb
      \verb{urlraw}
      \verb http://www.journals.cambridge.org/abstract_S0267190508070098
      \endverb
      \verb{url}
      \verb http://www.journals.cambridge.org/abstract_S0267190508070098
      \endverb
    \endentry
    \entry{levisTeachingIntonationDiscourse2004}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=224bb0e557cdfc275a192894f9c32603}{%
           family={Levis},
           familyi={L\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3b828b93bea47b2da4535db14b9c928a}{%
           family={Pickering},
           familyi={P\bibinitperiod},
           given={Lucy},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{c9223a19f134a9d5107c9955a3189901}
      \strng{fullhash}{c9223a19f134a9d5107c9955a3189901}
      \strng{bibnamehash}{c9223a19f134a9d5107c9955a3189901}
      \strng{authorbibnamehash}{c9223a19f134a9d5107c9955a3189901}
      \strng{authornamehash}{c9223a19f134a9d5107c9955a3189901}
      \strng{authorfullhash}{c9223a19f134a9d5107c9955a3189901}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Intonation, long thought to be a key to effectiveness in spoken language, is more and more commonly addressed in English language teaching through the use of speech visualization technology. While the use of visualization technology is a crucial advance in the teaching of intonation, such teaching can be further enhanced by connecting technology to an understanding of how intonation functions in discourse. This study examines the intonation of four readers reading out-of-context sentences and then the same sentences as part of coherent discourse-level texts. Two discourse-level uses of intonation, the use of intonational paragraph markers (paratones) and the distribution of tonal patterns, are discussed and implications for teaching intonation are addressed.}
      \field{issn}{0346251X}
      \field{journaltitle}{System}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{4}
      \field{shortjournal}{System}
      \field{title}{Teaching Intonation in Discourse Using Speech Visualization Technology}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{32}
      \field{year}{2004}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{505\bibrangedash 524}
      \range{pages}{20}
      \verb{doi}
      \verb 10.1016/j.system.2004.09.009
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/YYWGVD4Q/Levis and Pickering - 2004 - Teaching intonation in discourse using speech visualization technology.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0346251X04000752
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0346251X04000752
      \endverb
    \endentry
    \entry{liMispronunciationDetectionDiagnosis2017}{article}{}
      \name{author}{3}{}{%
        {{un=1,uniquepart=given,hash=7112bd5b38def4a55168243f6bc5e41b}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Kun},
           giveni={K\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=8ae5c7d5f0553c19ea134c04ab784e22}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Xiaojun},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8659b27d7c10074faa44f75f234ade20}{%
           family={Meng},
           familyi={M\bibinitperiod},
           given={Helen},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{1b8768dc4dd21611a4f99e8bfcc4f32c}
      \strng{fullhash}{ab323aa466db0390ae45223207e617a2}
      \strng{bibnamehash}{ab323aa466db0390ae45223207e617a2}
      \strng{authorbibnamehash}{ab323aa466db0390ae45223207e617a2}
      \strng{authornamehash}{1b8768dc4dd21611a4f99e8bfcc4f32c}
      \strng{authorfullhash}{ab323aa466db0390ae45223207e617a2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper investigates the use of multidistribution deep neural networks (DNNs) for mispronunciation detection and diagnosis (MDD), to circumvent the difficulties encountered in an existing approach based on extended recognition networks (ERNs). The ERNs leverage existing automatic speech recognition technology by constraining the search space via including the likely phonetic error patterns of the target words in addition to the canonical transcriptions. MDDs are achieved by comparing the recognized transcriptions with the canonical ones. Although this approach performs reasonably well, it has the following issues: 1) Learning the error patterns of the target words to generate the ERNs remains a challenging task. Phones or phone errors missing from the ERNs cannot be recognized even if we have well-trained acoustic models; and 2) acoustic models and phonological rules are trained independently, and hence, contextual information is lost. To address these issues, we propose an acoustic-graphemicphonemic model (AGPM) using a multidistribution DNN, whose input features include acoustic features, as well as corresponding graphemes and canonical transcriptions (encoded as binary vectors). The AGPM can implicitly model both grapheme-to-likelypronunciation and phoneme-to-likely-pronunciation conversions, which are integrated into acoustic modeling. With the AGPM, we develop a unified MDD framework, which works much like freephone recognition. Experiments show that our method achieves a phone error rate (PER) of 11.1\%. The false rejection rate (FRR), false acceptance rate (FAR), and diagnostic error rate (DER) for MDD are 4.6\%, 30.5\%, and 13.5\%, respectively. It outperforms the ERN approach using DNNs as acoustic models, whose PER, FRR, FAR, and DER are 16.8\%, 11.0\%, 43.6\%, and 32.3\%, respectively.}
      \field{issn}{2329-9290, 2329-9304}
      \field{journaltitle}{IEEE/ACM Transactions on Audio, Speech, and Language Processing}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{IEEE/ACM Trans. Audio Speech Lang. Process.}
      \field{title}{Mispronunciation {{Detection}} and {{Diagnosis}} in {{L2 English Speech Using Multidistribution Deep Neural Networks}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{25}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{193\bibrangedash 207}
      \range{pages}{15}
      \verb{doi}
      \verb 10.1109/TASLP.2016.2621675
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/C4PALEVG/Li et al. - 2017 - Mispronunciation Detection and Diagnosis in L2 English Speech Using Multidistribution Deep Neural Ne.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/7752846/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/7752846/
      \endverb
    \endentry
    \entry{liPhonemeLevelArticulatorDynamics2011}{inproceedings}{}
      \name{author}{3}{}{%
        {{un=1,uniquepart=given,hash=d8125976d0f2f0c4fddc5c4adeda313d}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Sheng},
           giveni={S\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=4c32e16577a4c04e689db3ccdde1d2ea}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Lan},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c3f3e61d77580bc96cc28588a623d5ac}{%
           family={Qi},
           familyi={Q\bibinitperiod},
           given={En},
           giveni={E\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Penang, Malaysia}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{9b2a89345055108bf86a394e0a0530ea}
      \strng{fullhash}{4f855e223bb7e400181d96708d2ac17e}
      \strng{bibnamehash}{4f855e223bb7e400181d96708d2ac17e}
      \strng{authorbibnamehash}{4f855e223bb7e400181d96708d2ac17e}
      \strng{authornamehash}{9b2a89345055108bf86a394e0a0530ea}
      \strng{authorfullhash}{4f855e223bb7e400181d96708d2ac17e}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Speech visualization can be extended to a task of pronunciation animation for language learners. In this paper, a three dimensional English articulation database is recorded using Carstens Electro-Magnetic Articulograph (EMA AG500). A HMM-based visual synthesis method for continuous speech is implemented to recover some important articulatory information. The synthesized articulations are then compared to the EMA recordings for objective evaluation. With a data-driven 3D talking head, the distinctions between the confusable phonemes can be depicted through both external and internal articulatory movements. The experiments demonstrated that an EMA data driven 3D talking head, incorporated with HMMbased visual synthesis technique, is quite practical for computer-assisted second language pronunciation training.}
      \field{booktitle}{2011 {{International Conference}} on {{Asian Language Processing}}}
      \field{eventtitle}{2011 {{International Conference}} on {{Asian Language Processing}} ({{IALP}})}
      \field{isbn}{978-1-4577-1733-8}
      \field{langid}{english}
      \field{month}{11}
      \field{title}{The {{Phoneme-Level Articulator Dynamics}} for {{Pronunciation Animation}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2011}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{283\bibrangedash 286}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1109/IALP.2011.13
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/B86KFAGB/Li et al. - 2011 - The Phoneme-Level Articulator Dynamics for Pronunciation Animation.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/6121521/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/6121521/
      \endverb
    \endentry
    \entry{liuEndtoEndUnsupervisedSpeech2023}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=f6dd48342cba0f6385fb3e4ac6d66b33}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Alexander\bibnamedelima H.},
           giveni={A\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=caee6b3fa31c9aa140f1d90048cd989f}{%
           family={Hsu},
           familyi={H\bibinitperiod},
           given={Wei-Ning},
           giveni={W\bibinithyphendelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3ff0eff0a1d1258618c88f2ec57095f}{%
           family={Auli},
           familyi={A\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e478046d4abc39e9814f6e364a736511}{%
           family={Baevski},
           familyi={B\bibinitperiod},
           given={Alexei},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Doha, Qatar}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{fc540f72dcefc288dabdb01697a71a7d}
      \strng{fullhash}{f1a6737a3b74eee4763172b2d6c3d2d6}
      \strng{bibnamehash}{f1a6737a3b74eee4763172b2d6c3d2d6}
      \strng{authorbibnamehash}{f1a6737a3b74eee4763172b2d6c3d2d6}
      \strng{authornamehash}{fc540f72dcefc288dabdb01697a71a7d}
      \strng{authorfullhash}{f1a6737a3b74eee4763172b2d6c3d2d6}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Unsupervised speech recognition has shown great potential to make Automatic Speech Recognition (ASR) systems accessible to every language. However, existing methods still heavily rely on hand-crafted pre-processing. Similar to the trend of making supervised speech recognition end-to-end, we introduce wav2vec-U 2.0 which does away with all audio-side preprocessing and improves accuracy through better architecture. In addition, we introduce an auxiliary self-supervised objective that ties model predictions back to the input. Experiments show that wav2vec-U 2.0 improves unsupervised recognition results across different languages while being conceptually simpler.}
      \field{booktitle}{2022 {{IEEE Spoken Language Technology Workshop}} ({{SLT}})}
      \field{day}{9}
      \field{eventtitle}{2022 {{IEEE Spoken Language Technology Workshop}} ({{SLT}})}
      \field{isbn}{979-8-3503-9690-4}
      \field{langid}{english}
      \field{month}{1}
      \field{title}{Towards {{End-to-End Unsupervised Speech Recognition}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{221\bibrangedash 228}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1109/SLT54892.2023.10023187
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/L94ZBXD8/Liu et al. - 2023 - Towards End-to-End Unsupervised Speech Recognition.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/10023187/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/10023187/
      \endverb
    \endentry
    \entry{lonerganAutomaticSpeechRecognition}{article}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=9db4af13432a594613e8efe0ea532287}{%
           family={Lonergan},
           familyi={L\bibinitperiod},
           given={Liam},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9c58381cb863012cd1df917bb20d39ee}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Mengjie},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4ca87a8b7ddfc49d2811ec5f34f86af}{%
           family={Berthelsen},
           familyi={B\bibinitperiod},
           given={Harald},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c18def86d87b42fc64a7f14ad616b8d1}{%
           family={Murphy},
           familyi={M\bibinitperiod},
           given={Andy},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a09def41ef54cd6582b67d86ae3785c1}{%
           family={Wendler},
           familyi={W\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f0032cd1cf7c14995537d7ee5b8edc21}{%
           family={Chiaráin},
           familyi={C\bibinitperiod},
           given={Neasa\bibnamedelima Ní},
           giveni={N\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f08b34b12657a55637cced651ec89cc3}{%
           family={Gobl},
           familyi={G\bibinitperiod},
           given={Christer},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f2c38cf0d08aca358e56773170a2fe9d}{%
           family={Chasaide},
           familyi={C\bibinitperiod},
           given={Ailbhe\bibnamedelima Ní},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4d34d0315f0b2cb31a08817721dbcd48}
      \strng{fullhash}{c0c6f8a622e8bfe0ad0545ef01b54198}
      \strng{bibnamehash}{c0c6f8a622e8bfe0ad0545ef01b54198}
      \strng{authorbibnamehash}{c0c6f8a622e8bfe0ad0545ef01b54198}
      \strng{authornamehash}{4d34d0315f0b2cb31a08817721dbcd48}
      \strng{authorfullhash}{c0c6f8a622e8bfe0ad0545ef01b54198}
      \field{extraname}{1}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes ÉIST, automatic speech recogniser for Irish, developed as part of the ongoing ABAIR initiative, combining (1) acoustic models, (2) pronunciation lexicons and (3) language models into a hybrid system. A priority for now is a system that can deal with the multiple diverse native-speaker dialects. Consequently, (1) was built using predominately native-speaker speech, which included earlier recordings used for synthesis development as well as more diverse recordings obtained using the MíleGlór platform. The pronunciation variation across the dialects is a particular challenge in the development of (2) and is explored by testing both Transdialect and Multi-dialect letter-to-sound rules. Two approaches to language modelling (3) are used in the hybrid system, a simple n-gram model and recurrent neural network lattice rescoring, the latter garnering impressive performance improvements. The system is evaluated using a test set that is comprised of both native and non-native speakers, which allows for some inferences to be made on the performance of the system on both cohorts.}
      \field{langid}{english}
      \field{title}{Automatic {{Speech Recognition}} for {{Irish}}: The {{ABAIR-ÉIST System}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/R2PXEAQD/Lonergan et al. - Automatic Speech Recognition for Irish the ABAIR-ÉIST System.pdf
      \endverb
    \endentry
    \entry{lonerganLowresourceSpeechRecognition2024}{online}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=9db4af13432a594613e8efe0ea532287}{%
           family={Lonergan},
           familyi={L\bibinitperiod},
           given={Liam},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9c58381cb863012cd1df917bb20d39ee}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Mengjie},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f0032cd1cf7c14995537d7ee5b8edc21}{%
           family={Chiaráin},
           familyi={C\bibinitperiod},
           given={Neasa\bibnamedelima Ní},
           giveni={N\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f08b34b12657a55637cced651ec89cc3}{%
           family={Gobl},
           familyi={G\bibinitperiod},
           given={Christer},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f2c38cf0d08aca358e56773170a2fe9d}{%
           family={Chasaide},
           familyi={C\bibinitperiod},
           given={Ailbhe\bibnamedelima Ní},
           giveni={A\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4d34d0315f0b2cb31a08817721dbcd48}
      \strng{fullhash}{1e12ac34c1c167c26b012a569832ae68}
      \strng{bibnamehash}{1e12ac34c1c167c26b012a569832ae68}
      \strng{authorbibnamehash}{1e12ac34c1c167c26b012a569832ae68}
      \strng{authornamehash}{4d34d0315f0b2cb31a08817721dbcd48}
      \strng{authorfullhash}{1e12ac34c1c167c26b012a569832ae68}
      \field{extraname}{2}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper explores the use of Hybrid CTC/Attention encoderdecoder models trained with Intermediate CTC (InterCTC) for Irish (Gaelic) low-resource speech recognition (ASR) and dialect identification (DID). Results are compared to the current best performing models trained for ASR (TDNN-HMM) and DID (ECAPA-TDNN). An optimal InterCTC setting is initially established using a Conformer encoder. This setting is then used to train a model with an E-branchformer encoder and the performance of both architectures are compared. A multi-task fine-tuning approach is adopted for language model (LM) shallow fusion. The experiments yielded an improvement in DID accuracy of 10.8\% relative to a baseline ECAPA-TDNN, and WER performance approaching the TDNN-HMM model. This multi-task approach emerges as a promising strategy for Irish low-resource ASR and DID.}
      \field{day}{2}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{5}
      \field{pubstate}{prepublished}
      \field{title}{Low-Resource Speech Recognition and Dialect Identification of {{Irish}} in a Multi-Task Framework}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2405.01293
      \endverb
      \verb{eprint}
      \verb 2405.01293
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/7DGRSRXD/Lonergan et al. - 2024 - Low-resource speech recognition and dialect identification of Irish in a multi-task framework.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2405.01293
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2405.01293
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{lysterOralCorrectiveFeedback2013}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=da787ade100437d70e07df7fd7452248}{%
           family={Lyster},
           familyi={L\bibinitperiod},
           given={Roy},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7096616a27b3c2eb708fe1e6ed731268}{%
           family={Saito},
           familyi={S\bibinitperiod},
           given={Kazuya},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=226e1696f5c6e1223240485037177cf9}{%
           family={Sato},
           familyi={S\bibinitperiod},
           given={Masatoshi},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{9b3fa87fa8b66fc48a4f6b1e7a8a9c3e}
      \strng{fullhash}{8f2b8716f260b5c0384caeaafa7a3c8b}
      \strng{bibnamehash}{8f2b8716f260b5c0384caeaafa7a3c8b}
      \strng{authorbibnamehash}{8f2b8716f260b5c0384caeaafa7a3c8b}
      \strng{authornamehash}{9b3fa87fa8b66fc48a4f6b1e7a8a9c3e}
      \strng{authorfullhash}{8f2b8716f260b5c0384caeaafa7a3c8b}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This article reviews research on oral corrective feedback (CF) in second language (L2) classrooms. Various types of oral CF are first identified, and the results of research revealing CF frequency across instructional contexts are presented. Research on CF preferences is then reviewed, revealing a tendency for learners to prefer receiving CF more than teachers feel they should provide it. Next, theoretical perspectives in support of CF are presented and some contentious issues addressed related to the role of learner uptake, the role of instruction, and the overall purpose of CF: to initiate the acquisition of new knowledge or to consolidate already acquired knowledge. A brief review of laboratory studies assessing the effects of recasts is then presented before we focus on classroom studies assessing the effects of different types of CF. Many variables mediate CF effectiveness: of these, we discuss linguistic targets and learners' age in terms of both previous and prospective research. Finally, CF provided by learners and the potential benefits of strategy training for strengthening the role of CF during peer interaction are highlighted.}
      \field{issn}{0261-4448, 1475-3049}
      \field{journaltitle}{Language Teaching}
      \field{langid}{english}
      \field{month}{1}
      \field{number}{1}
      \field{shortjournal}{Lang. Teach.}
      \field{title}{Oral Corrective Feedback in Second Language Classrooms}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{46}
      \field{year}{2013}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 40}
      \range{pages}{40}
      \verb{doi}
      \verb 10.1017/S0261444812000365
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/7PVZ2Q5Z/Lyster et al. - 2013 - Oral corrective feedback in second language classrooms.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.cambridge.org/core/product/identifier/S0261444812000365/type/journal_article
      \endverb
      \verb{url}
      \verb https://www.cambridge.org/core/product/identifier/S0261444812000365/type/journal_article
      \endverb
    \endentry
    \entry{mac2023learning}{thesis}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=d71f89f7068109d7758867e84ba1676c}{%
           family={Mac\bibnamedelima Lochlainn},
           familyi={M\bibinitperiod\bibinitdelim L\bibinitperiod},
           given={Conchúr},
           giveni={C\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {Dublin City University}%
      }
      \strng{namehash}{d71f89f7068109d7758867e84ba1676c}
      \strng{fullhash}{d71f89f7068109d7758867e84ba1676c}
      \strng{bibnamehash}{d71f89f7068109d7758867e84ba1676c}
      \strng{authorbibnamehash}{d71f89f7068109d7758867e84ba1676c}
      \strng{authornamehash}{d71f89f7068109d7758867e84ba1676c}
      \strng{authorfullhash}{d71f89f7068109d7758867e84ba1676c}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Learning to Express, Learning as Self-Expression: A Multimethod Investigation of the {{L2}} Selves of Distance Adult {{Irish L2}} Learners}
      \field{type}{phdthesis}
      \field{year}{2023}
      \field{dateera}{ce}
      \verb{file}
      \verb /home/pccady/Zotero/storage/LMHK7Y9J/Mac Lochlainn - 2023 - Learning to express, learning as self-expression a multimethod investigation of the L2 selves of di.pdf
      \endverb
    \endentry
    \entry{maclochlainnClickingConnectingL22021}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=d71f89f7068109d7758867e84ba1676c}{%
           family={Mac\bibnamedelima Lochlainn},
           familyi={M\bibinitperiod\bibinitdelim L\bibinitperiod},
           given={Conchúr},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4b361f06daa0ed650bb6884de59d3d07}{%
           family={Nic\bibnamedelimb Giolla\bibnamedelima Mhichíl},
           familyi={N\bibinitperiod\bibinitdelim G\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={Mairéad},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=11762e2a52be3c8843ebfd60a2fa13f8}{%
           family={Beirne},
           familyi={B\bibinitperiod},
           given={Elaine},
           giveni={E\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{9eabbe852a9859b5e17f8c16432120dc}
      \strng{fullhash}{eed5c389dc4e8792218ab1f0e62ce2a1}
      \strng{bibnamehash}{eed5c389dc4e8792218ab1f0e62ce2a1}
      \strng{authorbibnamehash}{eed5c389dc4e8792218ab1f0e62ce2a1}
      \strng{authornamehash}{9eabbe852a9859b5e17f8c16432120dc}
      \strng{authorfullhash}{eed5c389dc4e8792218ab1f0e62ce2a1}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Language massive open online courses (LMOOCs) represent an exciting prospect for language teachers and instructors around the globe (Bárcena \& Martín-Monje, 2014). In this paper, we report on the dynamics of participation and learner behaviour in an ab initio Irish language course. The course, Irish 101, ran during March 2019, and we used a mixed-methods approach to analyse both typical patterns of behaviour among course participants and learner reflections upon their reasons for doing so. Findings suggest that most learners use the course resources in an assessing and exploratory manner and are far less likely to produce, or to examine, second language (L2) output, either written or spoken. Learners were found to be selective and to demonstrate significant metacognitive awareness (Wenden, 1998) in their interactions and learning methods, displaying agency and exploiting affordances beyond the design of the course itself. Implications for LMOOC design, including the need to question whether courses should emphasise L2 production or resource provision, are considered, in addition to a general need for more granular, dynamic research, so as to better understand the types of learners who engage in LMOOCs and to better cater to diverse learning needs.}
      \field{issn}{0958-3440, 1474-0109}
      \field{journaltitle}{ReCALL}
      \field{langid}{english}
      \field{month}{5}
      \field{number}{2}
      \field{shortjournal}{ReCALL}
      \field{shorttitle}{Clicking, but Connecting?}
      \field{title}{Clicking, but Connecting? {{L2}} Learning Engagement on an Ab Initio {{Irish}} Language {{LMOOC}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{33}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{111\bibrangedash 127}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1017/S0958344021000100
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/RL4XRZHD/Mac Lochlainn et al. - 2021 - Clicking, but connecting L2 learning engagement on an ab initio Irish language LMOOC.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.cambridge.org/core/product/identifier/S0958344021000100/type/journal_article
      \endverb
      \verb{url}
      \verb https://www.cambridge.org/core/product/identifier/S0958344021000100/type/journal_article
      \endverb
    \endentry
    \entry{magueresseLowresourceLanguagesReview2020}{online}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=547d6e06081308be36083db96b8edb76}{%
           family={Magueresse},
           familyi={M\bibinitperiod},
           given={Alexandre},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=450e744798cbc184fb1059a5477ff238}{%
           family={Carles},
           familyi={C\bibinitperiod},
           given={Vincent},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6bde934679345b5af7be71ea444087eb}{%
           family={Heetderks},
           familyi={H\bibinitperiod},
           given={Evan},
           giveni={E\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{644116805dc710844d9d4236aaea88df}
      \strng{fullhash}{95e06356a259e31da21ef118d7bab191}
      \strng{bibnamehash}{95e06356a259e31da21ef118d7bab191}
      \strng{authorbibnamehash}{95e06356a259e31da21ef118d7bab191}
      \strng{authornamehash}{644116805dc710844d9d4236aaea88df}
      \strng{authorfullhash}{95e06356a259e31da21ef118d7bab191}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{A current problem in NLP is massaging and processing low-resource languages which lack useful training attributes such as supervised data, number of native speakers or experts, etc. This review paper concisely summarizes previous groundbreaking achievements made towards resolving this problem, and analyzes potential improvements in the context of the overall future research direction.}
      \field{day}{12}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{6}
      \field{pubstate}{prepublished}
      \field{shorttitle}{Low-Resource {{Languages}}}
      \field{title}{Low-Resource {{Languages}}: {{A Review}} of {{Past Work}} and {{Future Challenges}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2006.07264
      \endverb
      \verb{eprint}
      \verb 2006.07264
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/CY6KQTVS/Magueresse et al. - 2020 - Low-resource Languages A Review of Past Work and Future Challenges.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2006.07264
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2006.07264
      \endverb
      \keyw{Computer Science - Computation and Language}
    \endentry
    \entry{manoharWhatLostNormalization2024}{online}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=01978b854dda6430b0963152ed52eff6}{%
           family={Manohar},
           familyi={M\bibinitperiod},
           given={Kavya},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=522e1ee735e84a0e6187db7174b35f39}{%
           family={Pillai},
           familyi={P\bibinitperiod},
           given={Leena\bibnamedelima G.},
           giveni={L\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fbcfddf7f0cb93f767bb6f92f54c5c07}{%
           family={Sherly},
           familyi={S\bibinitperiod},
           given={Elizabeth},
           giveni={E\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{c6b7f884446b0a506f305253635cf6f4}
      \strng{fullhash}{8692a505ee960ce3d83b5f137a60bb57}
      \strng{bibnamehash}{8692a505ee960ce3d83b5f137a60bb57}
      \strng{authorbibnamehash}{8692a505ee960ce3d83b5f137a60bb57}
      \strng{authornamehash}{c6b7f884446b0a506f305253635cf6f4}
      \strng{authorfullhash}{8692a505ee960ce3d83b5f137a60bb57}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper explores the pitfalls in evaluating multilingual automatic speech recognition (ASR) models, with a particular focus on Indic language scripts. We investigate the text normalization routine employed by leading ASR models, including OpenAI Whisper, Meta’s MMS, Seamless, and Assembly AI’s Conformer, and their unintended consequences on performance metrics. Our research reveals that current text normalization practices, while aiming to standardize ASR outputs for fair comparison, by removing inconsistencies such as variations in spelling, punctuation, and special characters, are fundamentally flawed when applied to Indic scripts. Through empirical analysis using text similarity scores and in-depth linguistic examination, we demonstrate that these flaws lead to artificially improved performance metrics for Indic languages. We conclude by proposing a shift towards developing text normalization routines that leverage native linguistic expertise, ensuring more robust and accurate evaluations of multilingual ASR models.}
      \field{day}{9}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{11}
      \field{pubstate}{prepublished}
      \field{shorttitle}{What Is Lost in {{Normalization}}?}
      \field{title}{What Is Lost in {{Normalization}}? {{Exploring Pitfalls}} in {{Multilingual ASR Model Evaluations}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2409.02449
      \endverb
      \verb{eprint}
      \verb 2409.02449
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/KB2Q7RZQ/Manohar et al. - 2024 - What is lost in Normalization Exploring Pitfalls in Multilingual ASR Model Evaluations.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2409.02449
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2409.02449
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Human-Computer Interaction}
    \endentry
    \entry{mechuraIntroductionGramadanIrish}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=aecec86c01f11c26b57516f859b2731d}{%
           family={Měchura},
           familyi={M\bibinitperiod},
           given={Michal\bibnamedelima Boleslav},
           giveni={M\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{aecec86c01f11c26b57516f859b2731d}
      \strng{fullhash}{aecec86c01f11c26b57516f859b2731d}
      \strng{bibnamehash}{aecec86c01f11c26b57516f859b2731d}
      \strng{authorbibnamehash}{aecec86c01f11c26b57516f859b2731d}
      \strng{authornamehash}{aecec86c01f11c26b57516f859b2731d}
      \strng{authorfullhash}{aecec86c01f11c26b57516f859b2731d}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{Introduction to {{Gramadán}} and the {{Irish National Morphology Database}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/G68B8EGJ/Měchura - Introduction to Gramadán and the Irish National Morphology Database.pdf
      \endverb
    \endentry
    \entry{mihalicekLanguageFilesMaterials2012}{book}{}
      \name{editor}{2}{}{%
        {{un=0,uniquepart=base,hash=65dcd205cf2cb065b82397bb522026c2}{%
           family={Mihalicek},
           familyi={M\bibinitperiod},
           given={Vedrana},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=317216f5bcf1299ee11f3547ce9dfc1b}{%
           family={Wilson},
           familyi={W\bibinitperiod},
           given={Christin},
           giveni={C\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Taipei}%
      }
      \list{publisher}{1}{%
        {Bookman Books}%
      }
      \strng{namehash}{ce8213ff907458fe8bcf48efeca5ae2f}
      \strng{fullhash}{ce8213ff907458fe8bcf48efeca5ae2f}
      \strng{bibnamehash}{ce8213ff907458fe8bcf48efeca5ae2f}
      \strng{editorbibnamehash}{ce8213ff907458fe8bcf48efeca5ae2f}
      \strng{editornamehash}{ce8213ff907458fe8bcf48efeca5ae2f}
      \strng{editorfullhash}{ce8213ff907458fe8bcf48efeca5ae2f}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{editor}
      \field{labeltitlesource}{shorttitle}
      \field{annotation}{OCLC: 897284575}
      \field{edition}{11th edition}
      \field{isbn}{978-957-445-461-7}
      \field{langid}{english}
      \field{shorttitle}{Language Files}
      \field{title}{Language Files: Materials for an Introduction to Language and Linguistics}
      \field{year}{2012}
      \field{dateera}{ce}
    \endentry
    \entry{mortensenPanPhonResourceMapping}{article}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=cfcb6ba1595b0f5110004216d07213ef}{%
           family={Mortensen},
           familyi={M\bibinitperiod},
           given={David\bibnamedelima R},
           giveni={D\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d8b3ccfeee2656a6a880b39b2e82da8d}{%
           family={Littell},
           familyi={L\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=bcce6929cc46f034e5d0081f0cf3a4e9}{%
           family={Bharadwaj},
           familyi={B\bibinitperiod},
           given={Akash},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1a7a3857a2c57825329a92a115a0c7c9}{%
           family={Goyal},
           familyi={G\bibinitperiod},
           given={Kartik},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dc0d6b065a6566cde5d6b93214be1b55}{%
           family={Dyer},
           familyi={D\bibinitperiod},
           given={Chris},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8c7cf93c3f39a697d31a692e7b289399}{%
           family={Levin},
           familyi={L\bibinitperiod},
           given={Lori},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{297c54b4ae4eadf3bde5b95429c73043}
      \strng{fullhash}{854aa5eb043b3b7787dedb3334efbe3d}
      \strng{bibnamehash}{854aa5eb043b3b7787dedb3334efbe3d}
      \strng{authorbibnamehash}{854aa5eb043b3b7787dedb3334efbe3d}
      \strng{authornamehash}{297c54b4ae4eadf3bde5b95429c73043}
      \strng{authorfullhash}{854aa5eb043b3b7787dedb3334efbe3d}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper contributes to a growing body of evidence that—when coupled with appropriate machine-learning techniques—linguistically motivated, information-rich representations can outperform one-hot encodings of linguistic data. In particular, we show that phonological features outperform character-based models using the PanPhon resource. PanPhon is a database relating over 5,000 IPA segments to 21 subsegmental articulatory features. We show that this database boosts performance in various NER-related tasks. Phonologically aware, neural CRF models built on PanPhon features are able to perform comparably to character-based models on monolingual Spanish and Turkish NER tasks. On transfer models (as between Uzbek and Turkish) they have been shown to perform better. Furthermore, PanPhon features also contribute measurably to Orthography-to-IPA conversion tasks.}
      \field{langid}{english}
      \field{title}{{{PanPhon}}: {{A Resource}} for {{Mapping IPA Segments}} to {{Articulatory Feature Vectors}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/CZLCJ9BG/Mortensen et al. - PanPhon A Resource for Mapping IPA Segments to Articulatory Feature Vectors.pdf
      \endverb
    \endentry
    \entry{neriEffectivenessComputerAssisted2008}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=b195770cf95016dea6d62eb2e6481271}{%
           family={Neri},
           familyi={N\bibinitperiod},
           given={Ambra},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c714d19c66ed5817bbb3624e884c2701}{%
           family={Mich},
           familyi={M\bibinitperiod},
           given={Ornella},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4ae276102dfc13c2ba79c60718c9d364}{%
           family={Gerosa},
           familyi={G\bibinitperiod},
           given={Matteo},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1771e6958f569e27cb59e5495c44fe4c}{%
           family={Giuliani},
           familyi={G\bibinitperiod},
           given={Diego},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{d31cc3a690039757180cbfba76f9a356}
      \strng{fullhash}{3a9763a127841339468336a93ab5f4f6}
      \strng{bibnamehash}{3a9763a127841339468336a93ab5f4f6}
      \strng{authorbibnamehash}{3a9763a127841339468336a93ab5f4f6}
      \strng{authornamehash}{d31cc3a690039757180cbfba76f9a356}
      \strng{authorfullhash}{3a9763a127841339468336a93ab5f4f6}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0958-8221, 1744-3210}
      \field{journaltitle}{Computer Assisted Language Learning}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{5}
      \field{shortjournal}{Computer Assisted Language Learning}
      \field{title}{The Effectiveness of Computer Assisted Pronunciation Training for Foreign Language Learning by Children}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{21}
      \field{year}{2008}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{393\bibrangedash 408}
      \range{pages}{16}
      \verb{doi}
      \verb 10.1080/09588220802447651
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/6QN6VKGQ/Neri et al. - 2008 - The effectiveness of computer assisted pronunciation training for foreign language learning by child.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.tandfonline.com/doi/full/10.1080/09588220802447651
      \endverb
      \verb{url}
      \verb https://www.tandfonline.com/doi/full/10.1080/09588220802447651
      \endverb
    \endentry
    \entry{nichasaideSPEECHTECHNOLOGYDOCUMENTATION}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=df42ebb5984d809e2c235d3381017d65}{%
           family={Ní\bibnamedelima Chasaide},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Ailbhe},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ff6612f89e173ef3f99da3d8e3198ec0}{%
           family={Ní\bibnamedelima Chiaráin},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Neasa},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4ca87a8b7ddfc49d2811ec5f34f86af}{%
           family={Berthelsen},
           familyi={B\bibinitperiod},
           given={Harald},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a09def41ef54cd6582b67d86ae3785c1}{%
           family={Wendler},
           familyi={W\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e1aebdbcb0261db75d2b0ad47acfc629}{%
           family={Murphy},
           familyi={M\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8e831393bc76f0bb7a19553b5cdebb39}
      \strng{fullhash}{ab5d536e3e8a311c11a0ab85aef59c85}
      \strng{bibnamehash}{ab5d536e3e8a311c11a0ab85aef59c85}
      \strng{authorbibnamehash}{ab5d536e3e8a311c11a0ab85aef59c85}
      \strng{authornamehash}{8e831393bc76f0bb7a19553b5cdebb39}
      \strng{authorfullhash}{ab5d536e3e8a311c11a0ab85aef59c85}
      \field{extraname}{1}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Developing speech technology such as text-tospeech (TTS), requiring as it does a raft of phonetic and linguistic resources, can provide a powerful way to document endangered languages. Drawing on the experience of the ABAIR initiative, developing such resources for Irish [1], we illustrate how both the technology and the underpinning resources can be exploited in a variety of ways that can contribute to the preservation and revitalisation of these languages. By enabling new avenues of application, they can further help address the particular challenges that face the language users and learners. To maximise the immediate and downstream impact, resource development should ideally involve linguistically transparent, rule-based approaches, rather than the machine learning approaches typical of the commercially driven TTS systems for major world languages.}
      \field{langid}{english}
      \field{title}{{{SPEECH TECHNOLOGY AS DOCUMENTATION FOR ENDANGERED LANGUAGE PRESERVATION}}: {{THE CASE OF IRISH}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/FUC4REGR/Chasaide et al. - SPEECH TECHNOLOGY AS DOCUMENTATION FOR ENDANGERED LANGUAGE PRESERVATION THE CASE OF IRISH.pdf
      \endverb
    \endentry
    \entry{nichasaideCanWeDefuse2019}{inproceedings}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=df42ebb5984d809e2c235d3381017d65}{%
           family={Ní\bibnamedelima Chasaide},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Ailbhe},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ff6612f89e173ef3f99da3d8e3198ec0}{%
           family={Ní\bibnamedelima Chiaráin},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Neasa},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4ca87a8b7ddfc49d2811ec5f34f86af}{%
           family={Berthelsen},
           familyi={B\bibinitperiod},
           given={Harald},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a09def41ef54cd6582b67d86ae3785c1}{%
           family={Wendler},
           familyi={W\bibinitperiod},
           given={Christoph},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e1aebdbcb0261db75d2b0ad47acfc629}{%
           family={Murphy},
           familyi={M\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=18bd2dc72c7073b77bf1974652a08a0b}{%
           family={Barnes},
           familyi={B\bibinitperiod},
           given={Emily},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f08b34b12657a55637cced651ec89cc3}{%
           family={Gobl},
           familyi={G\bibinitperiod},
           given={Christer},
           giveni={C\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {European Language Resources Association (ELRA)}%
      }
      \strng{namehash}{8e831393bc76f0bb7a19553b5cdebb39}
      \strng{fullhash}{a8de1c9e393d47859bb1c41fdc1df924}
      \strng{bibnamehash}{a8de1c9e393d47859bb1c41fdc1df924}
      \strng{authorbibnamehash}{a8de1c9e393d47859bb1c41fdc1df924}
      \strng{authornamehash}{8e831393bc76f0bb7a19553b5cdebb39}
      \strng{authorfullhash}{a8de1c9e393d47859bb1c41fdc1df924}
      \field{extraname}{2}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Does speech/language technology represent a 'digital timebomb' - or an unprecedented opportunity - for minority and indigenous languages? For successful outcomes, technology development must address linguistic challenges, answer to the needs of the local language communities, enlisting them as a central partner in development. The Irish language ABAIR initiative is building (i) linguistic resources, (ii) core technologies, and (iii) applications for public, educational and access/disability use. The Government’s Digital Plan for Irish Speech and Language Technology provides a model of the support needed by minority languages in the digital age, if the language is to feature in everyday community activities.}
      \field{booktitle}{Proceedings of the {{Language Technologies}} for {{All}} ({{LT4All}})}
      \field{eventtitle}{Proceedings of the {{Language Technologies}} for {{All}} ({{LT4All}})}
      \field{langid}{english}
      \field{title}{Can We Defuse the Digital Timebomb? Linguistics, Speech Technology and the Irish Language Community}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{177\bibrangedash 181}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/SpeechProsody.2016-73
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/HEZYJ5BN/O'Reilly and Ní Chasaide - 2016 - Modelling the timing and scaling of nuclear pitch accents of Connaught and Ulster Irish with the Fuj.pdf
      \endverb
      \verb{urlraw}
      \verb https://lt4all.elra.info/media/papers/O8/97.pdf
      \endverb
      \verb{url}
      \verb https://lt4all.elra.info/media/papers/O8/97.pdf
      \endverb
    \endentry
    \entry{nichiarainCorpasClisteCreating2022}{incollection}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=ff6612f89e173ef3f99da3d8e3198ec0}{%
           family={Ní\bibnamedelima Chiaráin},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Neasa},
           giveni={N\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{7}{}{%
        {{hash=d9b491cb9ec2bb5ebe7783133813fb53}{%
           family={Arnbjörnsdóttir},
           familyi={A\bibinitperiod},
           given={Birna},
           giveni={B\bibinitperiod}}}%
        {{hash=5d1d00a431c5a70c6b895bc7b7e9450e}{%
           family={Bédi},
           familyi={B\bibinitperiod},
           given={Branislav},
           giveni={B\bibinitperiod}}}%
        {{hash=b2970509b209cf28362cdda7c227463e}{%
           family={Bradley},
           familyi={B\bibinitperiod},
           given={Linda},
           giveni={L\bibinitperiod}}}%
        {{hash=7d06ebfcc2d9def12e3833e3a507acac}{%
           family={Friðriksdóttir},
           familyi={F\bibinitperiod},
           given={Kolbrún},
           giveni={K\bibinitperiod}}}%
        {{hash=f8f1e5452eac10c58fa21475951c02aa}{%
           family={Garðarsdóttir},
           familyi={G\bibinitperiod},
           given={Hólmfríður},
           giveni={H\bibinitperiod}}}%
        {{hash=f4f3b4cee0ccaaa4c4ca8bf7c966b071}{%
           family={Thouësny},
           familyi={T\bibinitperiod},
           given={Sylvie},
           giveni={S\bibinitperiod}}}%
        {{hash=22d40d343c412f3e8e11e8b993c43179}{%
           family={Whelpton},
           familyi={W\bibinitperiod},
           given={Matthew\bibnamedelima James},
           giveni={M\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Research-publishing.net}%
      }
      \strng{namehash}{ff6612f89e173ef3f99da3d8e3198ec0}
      \strng{fullhash}{ff6612f89e173ef3f99da3d8e3198ec0}
      \strng{bibnamehash}{ff6612f89e173ef3f99da3d8e3198ec0}
      \strng{authorbibnamehash}{ff6612f89e173ef3f99da3d8e3198ec0}
      \strng{authornamehash}{ff6612f89e173ef3f99da3d8e3198ec0}
      \strng{authorfullhash}{ff6612f89e173ef3f99da3d8e3198ec0}
      \strng{editorbibnamehash}{0c7cdabd13752b2b33fb5b46b8d2cc11}
      \strng{editornamehash}{d992f319a847cb3e11acc4ba41a99aa2}
      \strng{editorfullhash}{0c7cdabd13752b2b33fb5b46b8d2cc11}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{An Corpas Cliste (‘Clever Corpus’) is an Irish language learner corpus. The corpus data comes from a purpose-built intelligent Computer Assisted Language Learning (iCALL) platform called An Scéalaí (‘the Storyteller’) and comprises both audio and text, produced by second and third level learners of Irish. Metadata (e.g. L1, level of Irish, dialect preference, age) is saved with every learner account, along with data on platform engagement (e.g. speech/language technologies employed, time spent on task). This paper illustrates how An Corpas Cliste is structured and is being prepared for analysis and the methodologies and resources that are being used to exploit it with a view to enhancing the learning experience.}
      \field{booktitle}{Intelligent {{CALL}}, Granular Systems and Learner Data: Short Papers from {{EUROCALL}} 2022}
      \field{day}{12}
      \field{edition}{1}
      \field{isbn}{978-2-38372-015-7}
      \field{langid}{english}
      \field{month}{12}
      \field{shorttitle}{An {{Corpas Cliste}}}
      \field{title}{An {{Corpas Cliste}}: Creating a Learner Corpus for {{Irish}} from a New, Purpose-Built {{iCALL}} Platform}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{297\bibrangedash 301}
      \range{pages}{5}
      \verb{doi}
      \verb 10.14705/rpnet.2022.61.1474
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/A9BP3SY7/Ní Chiaráin - 2022 - An Corpas Cliste creating a learner corpus for Irish from a new, purpose-built iCALL platform.pdf
      \endverb
      \verb{urlraw}
      \verb https://research-publishing.net/manuscript?10.14705/rpnet.2022.61.1474
      \endverb
      \verb{url}
      \verb https://research-publishing.net/manuscript?10.14705/rpnet.2022.61.1474
      \endverb
    \endentry
    \entry{nichiarainDigichaintInteractiveGame2016}{incollection}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=ff6612f89e173ef3f99da3d8e3198ec0}{%
           family={Ní\bibnamedelima Chiaráin},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Neasa},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=df42ebb5984d809e2c235d3381017d65}{%
           family={Ní\bibnamedelima Chasaide},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Ailbhe},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{3}{}{%
        {{hash=197690b8c382c1972a323d6aaf6c04a2}{%
           family={Papadima-Sophocleous},
           familyi={P\bibinithyphendelim S\bibinitperiod},
           given={Salomi},
           giveni={S\bibinitperiod}}}%
        {{hash=b2970509b209cf28362cdda7c227463e}{%
           family={Bradley},
           familyi={B\bibinitperiod},
           given={Linda},
           giveni={L\bibinitperiod}}}%
        {{hash=f4f3b4cee0ccaaa4c4ca8bf7c966b071}{%
           family={Thouësny},
           familyi={T\bibinitperiod},
           given={Sylvie},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Research-publishing.net}%
      }
      \strng{namehash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{fullhash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{bibnamehash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{authorbibnamehash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{authornamehash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{authorfullhash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{editorbibnamehash}{ad6df2f7d2b50e65505e282743d0981b}
      \strng{editornamehash}{7fef5a3a43db4abffef5af0e3f8c3046}
      \strng{editorfullhash}{ad6df2f7d2b50e65505e282743d0981b}
      \field{extraname}{1}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Although Text-To-Speech (TTS) synthesis has been little used in Computer-Assisted Language Learning (CALL), it is ripe for deployment, particularly for minority and endangered languages, where learners have little access to native speaker models and where few genuinely interactive and engaging teaching/learning materials are available. These considerations lie behind the development of Digichaint, an interactive language learning game which uses ABAIR Irish TTS voices. It provides a language-rich learning environment for Irish language pedagogy and is also used as a testbed to evaluate the intelligibility, quality and attractiveness of the ABAIR synthetic voices.}
      \field{booktitle}{{{CALL}} Communities and Culture – Short Papers from {{EUROCALL}} 2016}
      \field{day}{18}
      \field{isbn}{978-1-908416-44-5}
      \field{langid}{english}
      \field{month}{12}
      \field{title}{The {{Digichaint}} Interactive Game as a Virtual Learning Environment for {{Irish}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{330\bibrangedash 336}
      \range{pages}{7}
      \verb{doi}
      \verb 10.14705/rpnet.2016.eurocall2016.584
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/9A7YSCBP/Ní Chiaráin and Ní Chasaide - 2016 - The Digichaint interactive game as a virtual learning environment for Irish.pdf
      \endverb
      \verb{urlraw}
      \verb https://research-publishing.net/manuscript?10.14705/rpnet.2016.eurocall2016.584
      \endverb
      \verb{url}
      \verb https://research-publishing.net/manuscript?10.14705/rpnet.2016.eurocall2016.584
      \endverb
    \endentry
    \entry{nichiarainScealaiSyntheticVoices2018}{inbook}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=ff6612f89e173ef3f99da3d8e3198ec0}{%
           family={Ní\bibnamedelima Chiaráin},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Neasa},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=df42ebb5984d809e2c235d3381017d65}{%
           family={Ní\bibnamedelima Chasaide},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Ailbhe},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \name{bookauthor}{4}{}{%
        {{hash=e88809c908cfa2902708131cc535485d}{%
           family={Taalas},
           familyi={T\bibinitperiod},
           given={Peppi},
           giveni={P\bibinitperiod}}}%
        {{hash=f638f94f9ef54e5b0cf4265fa38eccef}{%
           family={Jalkanen},
           familyi={J\bibinitperiod},
           given={Juha},
           giveni={J\bibinitperiod}}}%
        {{hash=b2970509b209cf28362cdda7c227463e}{%
           family={Bradley},
           familyi={B\bibinitperiod},
           given={Linda},
           giveni={L\bibinitperiod}}}%
        {{hash=f4f3b4cee0ccaaa4c4ca8bf7c966b071}{%
           family={Thouësny},
           familyi={T\bibinitperiod},
           given={Sylvie},
           giveni={S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Research-publishing.net}%
      }
      \strng{namehash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{fullhash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{bibnamehash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{authorbibnamehash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{authornamehash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{authorfullhash}{e3777d5d93e1321190c4ff02f4d7dd01}
      \strng{bookauthorbibnamehash}{f7976599c1dbb0dd358c931750df81eb}
      \strng{bookauthornamehash}{e8d1a35ded65d09ca790ccde42fe74e5}
      \strng{bookauthorfullhash}{f7976599c1dbb0dd358c931750df81eb}
      \field{extraname}{2}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper details the motivation for and the main characteristics of An Scéalaí (‘The Storyteller’), an intelligent Computer Assisted Language Learning (iCALL) platform for autonomous learning that integrates the four skills; writing, listening, speaking, and reading. A key feature is the incorporation of speech technology. Speech synthesis provides aural feedback which draws the learners’ attention to errors in the text. Natural language prompts focus on common spelling and grammatical errors, further guiding the learners’ ability to revise and self-correct written materials. While An Scéalaí is still in early stages of development, results of a feasibility study are positive and point towards directions for further development.}
      \field{booktitle}{Future-Proof {{CALL}}: Language Learning as Exploration and Encounters – Short Papers from {{EUROCALL}} 2018}
      \field{day}{8}
      \field{isbn}{978-2-490057-22-1}
      \field{langid}{english}
      \field{month}{12}
      \field{shorttitle}{An {{Scéalaí}}}
      \field{title}{An {{Scéalaí}}: Synthetic Voices for Autonomous Learning}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{230\bibrangedash 235}
      \range{pages}{6}
      \verb{doi}
      \verb 10.14705/rpnet.2018.26.842
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/EZ85DTLC/Ní Chiaráin and Ní Chasaide - 2018 - An Scéalaí synthetic voices for autonomous learning.pdf
      \endverb
      \verb{urlraw}
      \verb https://research-publishing.net/manuscript?10.14705/rpnet.2018.26.842
      \endverb
      \verb{url}
      \verb https://research-publishing.net/manuscript?10.14705/rpnet.2018.26.842
      \endverb
    \endentry
    \entry{nichiarainUsingSpeechNLP2022}{inproceedings}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=ff6612f89e173ef3f99da3d8e3198ec0}{%
           family={Ní\bibnamedelima Chiaráin},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Neasa},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=07c1b8ee53a7fa2d1243da54ab419d6b}{%
           family={Nolan},
           familyi={N\bibinitperiod},
           given={Oisín},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=17b4d16cee0b82c98aa39eab1502e648}{%
           family={Comtois},
           familyi={C\bibinitperiod},
           given={Madeleine},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=19c7f89672a4f684ec0ca8b5f7dd8ca2}{%
           family={Robinson\bibnamedelima Gunning},
           familyi={R\bibinitperiod\bibinitdelim G\bibinitperiod},
           given={Neimhin},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4ca87a8b7ddfc49d2811ec5f34f86af}{%
           family={Berthelsen},
           familyi={B\bibinitperiod},
           given={Harald},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b8bdb8d71c67fb20d6a082af2a756341}{%
           family={Ni\bibnamedelima Chasaide},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Ailbhe},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Dublin, Ireland}%
      }
      \list{publisher}{1}{%
        {Association for Computational Linguistics}%
      }
      \strng{namehash}{f3b878b6c29ee3e82683a7b8d87cae01}
      \strng{fullhash}{60d665949fe26ac1660167b34fbfa4c3}
      \strng{bibnamehash}{60d665949fe26ac1660167b34fbfa4c3}
      \strng{authorbibnamehash}{60d665949fe26ac1660167b34fbfa4c3}
      \strng{authornamehash}{f3b878b6c29ee3e82683a7b8d87cae01}
      \strng{authorfullhash}{60d665949fe26ac1660167b34fbfa4c3}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes how emerging linguistic resources and technologies can be used to build a language learning platform for Irish, an endangered language. This platform, An Scéalaí, harvests learner corpora – a vital resource both to study the stages of learners’ language acquisition and to guide future platform development. A technical description of the platform is provided, including details of how different speech technologies and linguistic resources are fused to provide a holistic learner experience. The active continuous participation of the community, and platform evaluations by learners and teachers, are discussed.}
      \field{booktitle}{Proceedings of the {{Fifth Workshop}} on the {{Use}} of {{Computational Methods}} in the {{Study}} of {{Endangered Languages}}}
      \field{eventtitle}{Proceedings of the {{Fifth Workshop}} on the {{Use}} of {{Computational Methods}} in the {{Study}} of {{Endangered Languages}}}
      \field{langid}{english}
      \field{title}{Using {{Speech}} and {{NLP Resources}} to Build an {{iCALL}} Platform for a Minority Language, the Story of {{An Scéalaí}}, the {{Irish}} Experience to Date}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{109\bibrangedash 118}
      \range{pages}{10}
      \verb{doi}
      \verb 10.18653/v1/2022.computel-1.14
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/5J9PL7H6/Ní Chiaráin et al. - 2022 - Using Speech and NLP Resources to build an iCALL platform for a minority language, the story of An S.pdf
      \endverb
      \verb{urlraw}
      \verb https://aclanthology.org/2022.computel-1.14
      \endverb
      \verb{url}
      \verb https://aclanthology.org/2022.computel-1.14
      \endverb
    \endentry
    \entry{niehuesModelingConfidenceSequencetoSequence2019}{online}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=fc7be2e5c38739e7e2193e9914dcf687}{%
           family={Niehues},
           familyi={N\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1f0f32a331520c55ce998e84d0cc876f}{%
           family={Pham},
           familyi={P\bibinitperiod},
           given={Ngoc-Quan},
           giveni={N\bibinithyphendelim Q\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4581985def52a566f4b97816ae2b2114}
      \strng{fullhash}{4581985def52a566f4b97816ae2b2114}
      \strng{bibnamehash}{4581985def52a566f4b97816ae2b2114}
      \strng{authorbibnamehash}{4581985def52a566f4b97816ae2b2114}
      \strng{authornamehash}{4581985def52a566f4b97816ae2b2114}
      \strng{authorfullhash}{4581985def52a566f4b97816ae2b2114}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recently, significant improvements have been achieved in various natural language processing tasks using neural sequence-to-sequence models. While aiming for the best generation quality is important, ultimately it is also necessary to develop models that can assess the quality of their output.}
      \field{day}{4}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{10}
      \field{pubstate}{prepublished}
      \field{title}{Modeling {{Confidence}} in {{Sequence-to-Sequence Models}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1910.01859
      \endverb
      \verb{eprint}
      \verb 1910.01859
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/G7NFKM7V/Niehues and Pham - 2019 - Modeling Confidence in Sequence-to-Sequence Models.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1910.01859
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1910.01859
      \endverb
      \keyw{Computer Science - Computation and Language}
    \endentry
    \entry{papadopoulosConfidenceEstimationMethods2001}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=9b2d737bc5f1b52cf5c3c8e2aa38dc24}{%
           family={Papadopoulos},
           familyi={P\bibinitperiod},
           given={G.},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2210d266481278c94fe97920021ad0d3}{%
           family={Edwards},
           familyi={E\bibinitperiod},
           given={P.J.},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d8509939f0fd7733a2d5b4366483fc0}{%
           family={Murray},
           familyi={M\bibinitperiod},
           given={A.F.},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ef90f8808baccba2d4be71ab4e654ed9}
      \strng{fullhash}{ae82c171de0f672330b78808e3d444f5}
      \strng{bibnamehash}{ae82c171de0f672330b78808e3d444f5}
      \strng{authorbibnamehash}{ae82c171de0f672330b78808e3d444f5}
      \strng{authornamehash}{ef90f8808baccba2d4be71ab4e654ed9}
      \strng{authorfullhash}{ae82c171de0f672330b78808e3d444f5}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Feedforward neural networks, particularly multilayer perceptrons, are widely used in regression and classification tasks. A reliable and practical measure of prediction confidence is essential. In this work three alternative approaches to prediction confidence estimation are presented and compared. The three methods are the maximum likelihood, approximate Bayesian, and the bootstrap technique. We consider prediction uncertainty owing to both data noise and model parameter misspecification. The methods are tested on a number of controlled artificial problems and a real, industrial regression application, the prediction of paper “curl.” Confidence estimation performance is assessed by calculating the mean and standard deviation of the prediction interval coverage probability. We show that treating data noise variance as a function of the inputs is appropriate for the curl prediction task. Moreover, we show that the mean coverage probability can only gauge confidence estimation performance as an average over the input space, i.e., global performance and that the standard deviation of the coverage is unreliable as a measure of local performance. The approximate Bayesian approach is found to perform better in terms of global performance.}
      \field{issn}{10459227}
      \field{journaltitle}{IEEE Transactions on Neural Networks}
      \field{langid}{english}
      \field{month}{11}
      \field{number}{6}
      \field{shortjournal}{IEEE Trans. Neural Netw.}
      \field{shorttitle}{Confidence Estimation Methods for Neural Networks}
      \field{title}{Confidence Estimation Methods for Neural Networks: A Practical Comparison}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{12}
      \field{year}{2001}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1278\bibrangedash 1287}
      \range{pages}{10}
      \verb{doi}
      \verb 10.1109/72.963764
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/DJHQC45P/Papadopoulos et al. - 2001 - Confidence estimation methods for neural networks a practical comparison.pdf
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/963764/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/963764/
      \endverb
    \endentry
    \entry{pengStudyFineTuningWav2vec202021}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=f737eec8f3f2fb0e9d3b00c5f5aab5ba}{%
           family={Peng},
           familyi={P\bibinitperiod},
           given={Linkai},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=215351f381b0789cbfa01174d2994890}{%
           family={Fu},
           familyi={F\bibinitperiod},
           given={Kaiqi},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=86728d3a00a7b01605eba98ae7c69da3}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Binghuai},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=240852ee544f176c02ca5edaf106318f}{%
           family={Ke},
           familyi={K\bibinitperiod},
           given={Dengfeng},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a3c2910886a48ae317b98f66582d9c00}{%
           family={Zhan},
           familyi={Z\bibinitperiod},
           given={Jinsong},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{342e9ade5815c9036dbd5d60ff7c8d22}
      \strng{fullhash}{f08c52824649848cad0a343077d417f9}
      \strng{bibnamehash}{f08c52824649848cad0a343077d417f9}
      \strng{authorbibnamehash}{f08c52824649848cad0a343077d417f9}
      \strng{authornamehash}{342e9ade5815c9036dbd5d60ff7c8d22}
      \strng{authorfullhash}{f08c52824649848cad0a343077d417f9}
      \field{extraname}{1}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Mispronunciation detection and diagnosis (MDD) technology is a key component of computer-assisted pronunciation training system (CAPT). The mainstream method is based on deep neural network automatic speech recognition. Unfortunately, the technique requires massive human-annotated speech recordings for training. Due to the huge variations in mother tongue, age, and proficiency level among second language learners, it is difficult to gather a large amount of matching data for acoustic model training, which greatly limits the model performance. In this paper, we explore the use of Self-Supervised Pretraining (SSP) model wav2vec2.0 for MDD tasks. SSP utilizes a large unlabelled dataset to learn general representation and can be applied in downstream tasks. We conduct experiments using two publicly available datasets (TIMIT, L2-arctic) and our best system achieves 60.44\% f1-score. Moreover, our method is able to achieve 55.52\% f1-score with 3 times less data, which demonstrates the effectiveness of SSP on MDD1.}
      \field{booktitle}{Interspeech 2021}
      \field{day}{30}
      \field{eventtitle}{Interspeech 2021}
      \field{langid}{english}
      \field{month}{8}
      \field{title}{A {{Study}} on {{Fine-Tuning}} Wav2vec2.0 {{Model}} for the {{Task}} of {{Mispronunciation Detection}} and {{Diagnosis}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4448\bibrangedash 4452}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2021-1344
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/4VWGN4LM/Peng et al. - 2021 - A Study on Fine-Tuning wav2vec2.0 Model for the Task of Mispronunciation Detection and Diagnosis.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2021/peng21e_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2021/peng21e_interspeech.html
      \endverb
    \endentry
    \entry{pengEndtoEndMispronunciationDetection2023}{article}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=f737eec8f3f2fb0e9d3b00c5f5aab5ba}{%
           family={Peng},
           familyi={P\bibinitperiod},
           given={Linkai},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a535a6e206309a4dfa99e76d4fa57128}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Yingming},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1fb99a9f00d4bc94ba579e6709c254ec}{%
           family={Bao},
           familyi={B\bibinitperiod},
           given={Rian},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c15dca1dd47bb240c99f7cf6481272a5}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Ya},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74f3067f20603e85bac325f904c6b552}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jinsong},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{342e9ade5815c9036dbd5d60ff7c8d22}
      \strng{fullhash}{fef3b9b57845bde63efa428d7f936bad}
      \strng{bibnamehash}{fef3b9b57845bde63efa428d7f936bad}
      \strng{authorbibnamehash}{fef3b9b57845bde63efa428d7f936bad}
      \strng{authornamehash}{342e9ade5815c9036dbd5d60ff7c8d22}
      \strng{authorfullhash}{fef3b9b57845bde63efa428d7f936bad}
      \field{extraname}{2}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{As an indispensable module of computer-aided pronunciation training (CAPT) systems, mispronunciation detection and diagnosis (MDD) techniques have attracted a lot of attention from academia and industry over the past decade. To train robust MDD models, this technique requires massive human-annotated speech recordings which are usually expensive and even hard to acquire. In this study, we propose to use transfer learning to tackle the problem of data scarcity from two aspects. First, from audio modality, we explore the use of the pretrained model wav2vec2.0 for MDD tasks by learning robust general acoustic representation. Second, from text modality, we explore transferring prior texts into MDD by learning associations between acoustic and textual modalities. We propose textual modulation gates that assign more importance to the relevant text information while suppressing irrelevant text information. Moreover, given the transcriptions, we propose an extra contrastive loss to reduce the difference of learning objectives between the phoneme recognition and MDD tasks. Conducting experiments on the L2-Arctic dataset showed that our wav2vec2.0 based models outperformed the conventional methods. The proposed textual modulation gate and contrastive loss further improved the F1-score by more than 2.88\% and our best model achieved an F1-score of 61.75\%.}
      \field{day}{2}
      \field{issn}{2076-3417}
      \field{journaltitle}{Applied Sciences}
      \field{langid}{english}
      \field{month}{6}
      \field{number}{11}
      \field{shortjournal}{Applied Sciences}
      \field{title}{End-to-{{End Mispronunciation Detection}} and {{Diagnosis Using Transfer Learning}}}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{volume}{13}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{6793}
      \range{pages}{1}
      \verb{doi}
      \verb 10.3390/app13116793
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/D2YW35F7/Peng et al. - 2023 - End-to-End Mispronunciation Detection and Diagnosis Using Transfer Learning.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.mdpi.com/2076-3417/13/11/6793
      \endverb
      \verb{url}
      \verb https://www.mdpi.com/2076-3417/13/11/6793
      \endverb
    \endentry
    \entry{pengTextAwareEndtoendMispronunciation2022}{online}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=f737eec8f3f2fb0e9d3b00c5f5aab5ba}{%
           family={Peng},
           familyi={P\bibinitperiod},
           given={Linkai},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a535a6e206309a4dfa99e76d4fa57128}{%
           family={Gao},
           familyi={G\bibinitperiod},
           given={Yingming},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=86728d3a00a7b01605eba98ae7c69da3}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Binghuai},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=240852ee544f176c02ca5edaf106318f}{%
           family={Ke},
           familyi={K\bibinitperiod},
           given={Dengfeng},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9d5474a5562f892dc1a1f5e572721e21}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Yanlu},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=74f3067f20603e85bac325f904c6b552}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Jinsong},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{342e9ade5815c9036dbd5d60ff7c8d22}
      \strng{fullhash}{a6f969cc710cef57b53d623f0030f0ac}
      \strng{bibnamehash}{a6f969cc710cef57b53d623f0030f0ac}
      \strng{authorbibnamehash}{a6f969cc710cef57b53d623f0030f0ac}
      \strng{authornamehash}{342e9ade5815c9036dbd5d60ff7c8d22}
      \strng{authorfullhash}{a6f969cc710cef57b53d623f0030f0ac}
      \field{extraname}{3}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Mispronunciation detection and diagnosis (MDD) technology is a key component of computer-assisted pronunciation training system (CAPT). In the field of assessing the pronunciation quality of constrained speech, the given transcriptions can play the role of a teacher. Conventional methods have fully utilized the prior texts for the model construction or improving the system performance, e.g. forced-alignment and extended recognition networks. Recently, some end-to-end based methods attempt to incorporate the prior texts into model training and preliminarily show the effectiveness. However, previous studies mostly consider applying raw attention mechanism to fuse audio representations with text representations, without taking possible text-pronunciation mismatch into account. In this paper, we present a gating strategy that assigns more importance to the relevant audio features while suppressing irrelevant text information. Moreover, given the transcriptions, we design an extra contrastive loss to reduce the gap between the learning objective of phoneme recognition and MDD. We conducted experiments using two publicly available datasets (TIMIT and L2Arctic) and our best model improved the F1 score from 57.51\% to 61.75\% compared to the baselines. Besides, we provide a detailed analysis to shed light on the effectiveness of gating mechanism and contrastive learning on MDD1.}
      \field{day}{15}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{6}
      \field{pubstate}{prepublished}
      \field{title}{Text-{{Aware End-to-end Mispronunciation Detection}} and {{Diagnosis}}}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2206.07289
      \endverb
      \verb{eprint}
      \verb 2206.07289
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/BPCSWBTP/Peng et al. - 2022 - Text-Aware End-to-end Mispronunciation Detection and Diagnosis.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2206.07289
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2206.07289
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{pisoniHandbookSpeechPerception}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=462209d75312cb8f556d740963d93ea3}{%
           family={Pisoni},
           familyi={P\bibinitperiod},
           given={David\bibnamedelima B},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=26f5e7ac270c2b3ba160353dc9088356}{%
           family={Remez},
           familyi={R\bibinitperiod},
           given={Robert\bibnamedelima E},
           giveni={R\bibinitperiod\bibinitdelim E\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{9cd028a8cf8336e82a9f890f4e53100b}
      \strng{fullhash}{9cd028a8cf8336e82a9f890f4e53100b}
      \strng{bibnamehash}{9cd028a8cf8336e82a9f890f4e53100b}
      \strng{authorbibnamehash}{9cd028a8cf8336e82a9f890f4e53100b}
      \strng{authornamehash}{9cd028a8cf8336e82a9f890f4e53100b}
      \strng{authorfullhash}{9cd028a8cf8336e82a9f890f4e53100b}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{langid}{english}
      \field{title}{The {{Handbook}} of {{Speech Perception}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/7HRR2MGX/Pisoni and Remez - The Handbook of Speech Perception.pdf
      \endverb
    \endentry
    \entry{poveyKaldiSpeechRecognition}{article}{}
      \name{author}{13}{}{%
        {{un=0,uniquepart=base,hash=e37bd3eba929f71a8a0351899f3870d5}{%
           family={Povey},
           familyi={P\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7317e829771fcdb6bffb1ce8c3b6c02f}{%
           family={Ghoshal},
           familyi={G\bibinitperiod},
           given={Arnab},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4da0ff554d1408c6508f7ae846654700}{%
           family={Boulianne},
           familyi={B\bibinitperiod},
           given={Gilles},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b54fb746be9f1030d1c6dc43c46b9345}{%
           family={Burget},
           familyi={B\bibinitperiod},
           given={Lukaˇs},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d219f381488e5233bb991b9a13f89856}{%
           family={Glembek},
           familyi={G\bibinitperiod},
           given={Ondˇrej},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=84224cceb127111325bf34d5bf6126bf}{%
           family={Goel},
           familyi={G\bibinitperiod},
           given={Nagendra},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=40eaa8a12b21dce5ba6c013910d5cc4a}{%
           family={Hannemann},
           familyi={H\bibinitperiod},
           given={Mirko},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3445ac8d82122c5ab55819eb219eb35a}{%
           family={Motlıˇcek},
           familyi={M\bibinitperiod},
           given={Petr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8945f0f8c84f5bfcb4ba5f31e3b49586}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Yanmin},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4d5da0ee0f4359168b596b8ad93969d}{%
           family={Schwarz},
           familyi={S\bibinitperiod},
           given={Petr},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=dc8ceaecfbd95ac33eeb8dd33a7e04a1}{%
           family={Silovsky},
           familyi={S\bibinitperiod},
           given={Jan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c45a4751946223d635ac92a2ae9189ed}{%
           family={Stemmer},
           familyi={S\bibinitperiod},
           given={Georg},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7170093a97980c23772ad16a6a04d0c1}{%
           family={Vesely},
           familyi={V\bibinitperiod},
           given={Karel},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{58ab821c54bf7cddd915674ad5dd9f5a}
      \strng{fullhash}{d6b1adb09af2d899a3a8f5067c0eedb2}
      \strng{bibnamehash}{d6b1adb09af2d899a3a8f5067c0eedb2}
      \strng{authorbibnamehash}{d6b1adb09af2d899a3a8f5067c0eedb2}
      \strng{authornamehash}{58ab821c54bf7cddd915674ad5dd9f5a}
      \strng{authorfullhash}{d6b1adb09af2d899a3a8f5067c0eedb2}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We describe the design of Kaldi, a free, open-source toolkit for speech recognition research. Kaldi provides a speech recognition system based on finite-state transducers (using the freely available OpenFst), together with detailed documentation and scripts for building complete recognition systems. Kaldi is written is C++, and the core library supports modeling of arbitrary phonetic-context sizes, acoustic modeling with subspace Gaussian mixture models (SGMM) as well as standard Gaussian mixture models, together with all commonly used linear and affine transforms. Kaldi is released under the Apache License v2.0, which is highly nonrestrictive, making it suitable for a wide community of users.}
      \field{langid}{english}
      \field{title}{The {{Kaldi Speech Recognition Toolkit}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/MAC6UCHS/Povey et al. - The Kaldi Speech Recognition Toolkit.pdf
      \endverb
    \endentry
    \entry{prabhavalkarMinimumWordError2017}{online}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=93bb6027d9d5e18776d8d859c9da7e5e}{%
           family={Prabhavalkar},
           familyi={P\bibinitperiod},
           given={Rohit},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=28a3d000e5cd60656250014708db8ec1}{%
           family={Sainath},
           familyi={S\bibinitperiod},
           given={Tara\bibnamedelima N.},
           giveni={T\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1fc7a40d6072b1bb1d4e56d14ef88e2f}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Yonghui},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=842040ccc784c0e00e9b177a7271883a}{%
           family={Nguyen},
           familyi={N\bibinitperiod},
           given={Patrick},
           giveni={P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0d10aaf985cebf8d0497e1828f9313f}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Zhifeng},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a16597f6d78144232241757f5d6e401c}{%
           family={Chiu},
           familyi={C\bibinitperiod},
           given={Chung-Cheng},
           giveni={C\bibinithyphendelim C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e6e0baf52b06f58dfd24c76abe0b0495}{%
           family={Kannan},
           familyi={K\bibinitperiod},
           given={Anjuli},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{af7d5e642586b4bf247dee7652a2749d}
      \strng{fullhash}{2a0d6dadc50a46a7c7a4f56ce2293245}
      \strng{bibnamehash}{2a0d6dadc50a46a7c7a4f56ce2293245}
      \strng{authorbibnamehash}{2a0d6dadc50a46a7c7a4f56ce2293245}
      \strng{authornamehash}{af7d5e642586b4bf247dee7652a2749d}
      \strng{authorfullhash}{2a0d6dadc50a46a7c7a4f56ce2293245}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Sequence-to-sequence models, such as attention-based models in automatic speech recognition (ASR), are typically trained to optimize the cross-entropy criterion which corresponds to improving the loglikelihood of the data. However, system performance is usually measured in terms of word error rate (WER), not log-likelihood. Traditional ASR systems benefit from discriminative sequence training which optimizes criteria such as the state-level minimum Bayes risk (sMBR) which are more closely related to WER.}
      \field{day}{5}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{12}
      \field{pubstate}{prepublished}
      \field{title}{Minimum {{Word Error Rate Training}} for {{Attention-based Sequence-to-Sequence Models}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2017}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1712.01818
      \endverb
      \verb{eprint}
      \verb 1712.01818
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/56J9L4X6/Prabhavalkar et al. - 2017 - Minimum Word Error Rate Training for Attention-based Sequence-to-Sequence Models.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1712.01818
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1712.01818
      \endverb
      \keyw{Computer Science - Computation and Language,Electrical Engineering and Systems Science - Audio and Speech Processing,Statistics - Machine Learning}
    \endentry
    \entry{pratapScalingSpeechTechnology}{article}{}
      \name{author}{15}{}{%
        {{un=0,uniquepart=base,hash=2f6e561c99309a827c3bdec1c0ae8a91}{%
           family={Pratap},
           familyi={P\bibinitperiod},
           given={Vineel},
           giveni={V\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=66dd2c90abd0bf676a14e5c1df8927d9}{%
           family={Tjandra},
           familyi={T\bibinitperiod},
           given={Andros},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=105be1020b1f6157f60ea46dab6be9f4}{%
           family={Shi},
           familyi={S\bibinitperiod},
           given={Bowen},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d27435fede55c71e4e4c81b921d28609}{%
           family={Babu},
           familyi={B\bibinitperiod},
           given={Paden\bibnamedelimb Tomasello\bibnamedelima Arun},
           giveni={P\bibinitperiod\bibinitdelim T\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f84fb4b923ba1f6382a9a29b91e620a1}{%
           family={Kundu},
           familyi={K\bibinitperiod},
           given={Sayani},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=81e75b7bf72c04dc581587d8932bcd44}{%
           family={Elkahky},
           familyi={E\bibinitperiod},
           given={Ali},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9eb9202410623e793ef53a09a198a9e5}{%
           family={Ni},
           familyi={N\bibinitperiod},
           given={Zhaoheng},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=57928887b6801b20de490f4d2e4b90ad}{%
           family={Vyas},
           familyi={V\bibinitperiod},
           given={Apoorv},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=3574995111995617f1b94c9b2646d290}{%
           family={Fazel-Zarandi},
           familyi={F\bibinithyphendelim Z\bibinitperiod},
           given={Maryam},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e478046d4abc39e9814f6e364a736511}{%
           family={Baevski},
           familyi={B\bibinitperiod},
           given={Alexei},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b524686c039bdbe0e8cca661fca6b56c}{%
           family={Adi},
           familyi={A\bibinitperiod},
           given={Yossi},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=76c4ac342426fb82f4a004c0cdbadd6d}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Xiaohui},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=caee6b3fa31c9aa140f1d90048cd989f}{%
           family={Hsu},
           familyi={H\bibinitperiod},
           given={Wei-Ning},
           giveni={W\bibinithyphendelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7cf7ac6a9456559cc67ee138c7f21cec}{%
           family={Conneau},
           familyi={C\bibinitperiod},
           given={Alexis},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d3ff0eff0a1d1258618c88f2ec57095f}{%
           family={Auli},
           familyi={A\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{3300c27a1df7d0239f8316a0e179c5e9}
      \strng{fullhash}{e38f29d27d60f7ba7c2c50ef44642ad1}
      \strng{bibnamehash}{e38f29d27d60f7ba7c2c50ef44642ad1}
      \strng{authorbibnamehash}{e38f29d27d60f7ba7c2c50ef44642ad1}
      \strng{authornamehash}{3300c27a1df7d0239f8316a0e179c5e9}
      \strng{authorfullhash}{e38f29d27d60f7ba7c2c50ef44642ad1}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Expanding the language coverage of speech technology has the potential to improve access to information for many more people. However, current speech technology is restricted to about one hundred languages which is a small fraction of the over 7,000 languages spoken around the world. The Massively Multilingual Speech (MMS) project increases the number of supported languages by 10-40x, depending on the task. The main ingredients are a new dataset based on readings of publicly available religious texts and effectively leveraging self-supervised learning. We built pre-trained wav2vec 2.0 models covering 1,406 languages, a single multilingual automatic speech recognition model for 1,107 languages, speech synthesis models for the same number of languages, as well as a language identification model for 4,017 languages. Experiments show that our multilingual speech recognition model more than halves the word error rate of Whisper on 54 languages of the FLEURS benchmark while being trained on a small fraction of the labeled data. The MMS models are available at https://github.com/pytorch/fairseq/tree/master/examples/mms.}
      \field{langid}{english}
      \field{title}{Scaling {{Speech Technology}} to 1,000+ {{Languages}}}
      \verb{file}
      \verb /home/pccady/Zotero/storage/5Z9XSBY6/Pratap et al. - Scaling Speech Technology to 1,000+ Languages.pdf
      \endverb
    \endentry
    \entry{punjabiLanguageModelBootstrapping2019}{inproceedings}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=32d105a4eafe9206dbcf0ba9335e12d8}{%
           family={Punjabi},
           familyi={P\bibinitperiod},
           given={Surabhi},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=85bf51d525abc7817d3d7bc793f67291}{%
           family={Arsikere},
           familyi={A\bibinitperiod},
           given={Harish},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=25a969074e32d100b2658596cf2ac90d}{%
           family={Garimella},
           familyi={G\bibinitperiod},
           given={Sri},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {SG, Singapore}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{ec2cfb2a2cb4f9a413c4bee064a8a10b}
      \strng{fullhash}{fa53e6ceffbf8b895141a520dfc18f10}
      \strng{bibnamehash}{fa53e6ceffbf8b895141a520dfc18f10}
      \strng{authorbibnamehash}{fa53e6ceffbf8b895141a520dfc18f10}
      \strng{authornamehash}{ec2cfb2a2cb4f9a413c4bee064a8a10b}
      \strng{authorfullhash}{fa53e6ceffbf8b895141a520dfc18f10}
      \field{sortinit}{P}
      \field{sortinithash}{ff3bcf24f47321b42cb156c2cc8a8422}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Building conversational speech recognition systems for new languages is constrained by the availability of utterances capturing user-device interactions. Data collection is expensive and limited by speed of manual transcription. In order to address this, we advocate the use of neural machine translation as a data augmentation technique for bootstrapping language models. Machine translation (MT) offers a systematic way of incorporating collections from mature, resource-rich conversational systems that may be available for a different language. However, ingesting raw translations from a general purpose MT system may not be effective owing to the presence of named entities, intra sentential code-switching and the domain mismatch between the conversational data being translated and the parallel text used for MT training. To circumvent this, we explore following domain adaptation techniques: (a) sentence embedding based data selection for MT training, (b) model finetuning, and (c) rescoring and filtering translated hypotheses. Using Hindi language as the experimental testbed, we supplement transcribed collections with translated US English utterances. We observe a relative word error rate reduction of 7.8-15.6\%, depending on the bootstrapping phase. Fine grained analysis reveals that translation particularly aids the interaction scenarios underrepresented in the transcribed data.}
      \field{booktitle}{2019 {{IEEE Automatic Speech Recognition}} and {{Understanding Workshop}} ({{ASRU}})}
      \field{eventtitle}{2019 {{IEEE Automatic Speech Recognition}} and {{Understanding Workshop}} ({{ASRU}})}
      \field{isbn}{978-1-7281-0306-8}
      \field{langid}{english}
      \field{month}{12}
      \field{title}{Language {{Model Bootstrapping Using Neural Machine Translation}} for {{Conversational Speech Recognition}}}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{487\bibrangedash 493}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1109/ASRU46091.2019.9003982
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/CPJQZQLD/Punjabi et al. - 2019 - Language Model Bootstrapping Using Neural Machine Translation for Conversational Speech Recognition.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9003982/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9003982/
      \endverb
    \endentry
    \entry{qianAutomaticSpeechRecognition2022}{inproceedings}{}
      \name{author}{8}{}{%
        {{un=0,uniquepart=base,hash=9c58381cb863012cd1df917bb20d39ee}{%
           family={Qian},
           familyi={Q\bibinitperiod},
           given={Mengjie},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f4ca87a8b7ddfc49d2811ec5f34f86af}{%
           family={Berthelsen},
           familyi={B\bibinitperiod},
           given={Harald},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9db4af13432a594613e8efe0ea532287}{%
           family={Lonergan},
           familyi={L\bibinitperiod},
           given={Liam},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c18def86d87b42fc64a7f14ad616b8d1}{%
           family={Murphy},
           familyi={M\bibinitperiod},
           given={Andy},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a07538345876c54ba2426d3f56f2cfbc}{%
           family={O'Neill},
           familyi={O\bibinitperiod},
           given={Claire},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=4832403ab21dc1506ada3840a69dc45b}{%
           family={Ni\bibnamedelima Chiarain},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Neasa},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f08b34b12657a55637cced651ec89cc3}{%
           family={Gobl},
           familyi={G\bibinitperiod},
           given={Christer},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b8bdb8d71c67fb20d6a082af2a756341}{%
           family={Ni\bibnamedelima Chasaide},
           familyi={N\bibinitperiod\bibinitdelim C\bibinitperiod},
           given={Ailbhe},
           giveni={A\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {Cork, Ireland}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{906297d8c6ac2de604b6bf8bba41be88}
      \strng{fullhash}{dedfebca4c1e67f2373a2e30cc2a49b9}
      \strng{bibnamehash}{dedfebca4c1e67f2373a2e30cc2a49b9}
      \strng{authorbibnamehash}{dedfebca4c1e67f2373a2e30cc2a49b9}
      \strng{authornamehash}{906297d8c6ac2de604b6bf8bba41be88}
      \strng{authorfullhash}{dedfebca4c1e67f2373a2e30cc2a49b9}
      \field{sortinit}{Q}
      \field{sortinithash}{ce69a400a872ddd02ee7fdb3b38c6abd}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{A range of lexicons and language models were tested in the development of ASR for Irish. One problem, common among minority languages, is the multiplicity of dialects, with no one spoken standard. To address this challenge, in a hybrid ASR system two alternative cross-dialect lexicons are tested, which draw on research in dialect phonology. First, individual lexicons were built for the three main dialects of Ulster (Ul), Connaught (Co) and Munster (Mu). With these, a Multi-dialect lexicon incorporated all dialect-varying word forms. An alternative Global lexicon, essentially a trans-dialect lexicon, used abstract representations of dialect-varying forms (phoneme or morpheme sized units). These two cross-dialect lexicons were tested along with the three dialect-specific lexicons. Several different language models were also tested. Results for the Global and Multi-dialect lexicons were found to yield the highest performance, with the lowest overall WER for the latter. There were considerable differences in results for the individual dialect lexicons: this may reflect a bias in the datasets used or could be indicators of the linguistic distance between the dialects — competing hypotheses that will need more rigorous testing. Results showed a strong effect of the language model used. Error patterns show frequent substitutions involving inflected forms.}
      \field{booktitle}{2022 33rd {{Irish Signals}} and {{Systems Conference}} ({{ISSC}})}
      \field{day}{9}
      \field{eventtitle}{2022 33rd {{Irish Signals}} and {{Systems Conference}} ({{ISSC}})}
      \field{isbn}{978-1-6654-5227-4}
      \field{langid}{english}
      \field{month}{6}
      \field{shorttitle}{Automatic {{Speech Recognition}} for {{Irish}}}
      \field{title}{Automatic {{Speech Recognition}} for {{Irish}}: Testing Lexicons and Language Models}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 6}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1109/ISSC55427.2022.9826201
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/ETGTXC54/Qian et al. - 2022 - Automatic Speech Recognition for Irish testing lexicons and language models.pdf
      \endverb
      \verb{urlraw}
      \verb https://ieeexplore.ieee.org/document/9826201/
      \endverb
      \verb{url}
      \verb https://ieeexplore.ieee.org/document/9826201/
      \endverb
    \endentry
    \entry{ranathungaNeuralMachineTranslation2021}{online}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=9e443800457acf0658615783189b864c}{%
           family={Ranathunga},
           familyi={R\bibinitperiod},
           given={Surangika},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1d73302bddcfccef41c5feb7798fe180}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={En-Shiun\bibnamedelima Annie},
           giveni={E\bibinithyphendelim S\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e5907034a5337158db442887961f849b}{%
           family={Skenduli},
           familyi={S\bibinitperiod},
           given={Marjana\bibnamedelima Prifti},
           giveni={M\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0a2a3d4aa43f3a2dabd0a64882f9216b}{%
           family={Shekhar},
           familyi={S\bibinitperiod},
           given={Ravi},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d5ea65cd3bf1c7bf17a424c061512ca1}{%
           family={Alam},
           familyi={A\bibinitperiod},
           given={Mehreen},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a4fd7990bba4ac998dc66c8dc521c96d}{%
           family={Kaur},
           familyi={K\bibinitperiod},
           given={Rishemjit},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{0f65f7ca78551fb3c96114466b4a0c35}
      \strng{fullhash}{eb200f6f49fec9f5c8d03ae83c008f14}
      \strng{bibnamehash}{eb200f6f49fec9f5c8d03ae83c008f14}
      \strng{authorbibnamehash}{eb200f6f49fec9f5c8d03ae83c008f14}
      \strng{authornamehash}{0f65f7ca78551fb3c96114466b4a0c35}
      \strng{authorfullhash}{eb200f6f49fec9f5c8d03ae83c008f14}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Neural Machine Translation (NMT) has seen a tremendous spurt of growth in less than ten years, and has already entered a mature phase. While considered as the most widely used solution for Machine Translation, its performance on low-resource language pairs still remains sub-optimal compared to the high-resource counterparts, due to the unavailability of large parallel corpora. Therefore, the implementation of NMT techniques for low-resource language pairs has been receiving the spotlight in the recent NMT research arena, thus leading to a substantial amount of research reported on this topic. This paper presents a detailed survey of research advancements in low-resource language NMT (LRL-NMT), along with a quantitative analysis aimed at identifying the most popular solutions. Based on our findings from reviewing previous work, this survey paper provides a set of guidelines to select the possible NMT technique for a given LRL data setting. It also presents a holistic view of the LRL-NMT research landscape and provides a list of recommendations to further enhance the research efforts on LRL-NMT. CCS Concepts: • Computing methodologies → Natural language processing; Neural networks; Machine translation; Language resources; Machine learning.}
      \field{day}{29}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{6}
      \field{pubstate}{prepublished}
      \field{shorttitle}{Neural {{Machine Translation}} for {{Low-Resource Languages}}}
      \field{title}{Neural {{Machine Translation}} for {{Low-Resource Languages}}: {{A Survey}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2106.15115
      \endverb
      \verb{eprint}
      \verb 2106.15115
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/SC639869/Ranathunga et al. - 2021 - Neural Machine Translation for Low-Resource Languages A Survey.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2106.15115
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2106.15115
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computation and Language}
    \endentry
    \entry{rogerson-revellComputerAssistedPronunciationTraining2021}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=6116c522bb60bdf6648fee04dee72adc}{%
           family={Rogerson-Revell},
           familyi={R\bibinithyphendelim R\bibinitperiod},
           given={Pamela\bibnamedelima M},
           giveni={P\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6116c522bb60bdf6648fee04dee72adc}
      \strng{fullhash}{6116c522bb60bdf6648fee04dee72adc}
      \strng{bibnamehash}{6116c522bb60bdf6648fee04dee72adc}
      \strng{authorbibnamehash}{6116c522bb60bdf6648fee04dee72adc}
      \strng{authornamehash}{6116c522bb60bdf6648fee04dee72adc}
      \strng{authorfullhash}{6116c522bb60bdf6648fee04dee72adc}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This viewpoint essay considers the current status of computer-assisted pronunciation training (CAPT) before examining some of the current issues and future directions in the field. The underlying premise is the pedagogic potential of CAPT systems and resources for teaching and learning, and the need for greater synergy between technological design and functionality on the one hand, and pedagogic purpose on the other. Some of the key issues examined include providing accurate and individualised automated feedback for pronunciation, for both learning and assessment, and evaluating the effectiveness of CAPT tools and systems. When considering future directions, the discussion focuses on what aspects of pedagogy are likely to be at the forefront of developments, including ubiquitous learning; intelligent tutoring and authentic interaction; and goal-oriented, task-based learning.}
      \field{issn}{0033-6882, 1745-526X}
      \field{journaltitle}{RELC Journal}
      \field{langid}{english}
      \field{month}{4}
      \field{number}{1}
      \field{shortjournal}{RELC Journal}
      \field{shorttitle}{Computer-{{Assisted Pronunciation Training}} ({{CAPT}})}
      \field{title}{Computer-{{Assisted Pronunciation Training}} ({{CAPT}}): {{Current Issues}} and {{Future Directions}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{52}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{189\bibrangedash 205}
      \range{pages}{17}
      \verb{doi}
      \verb 10.1177/0033688220977406
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/EJLED84K/Rogerson-Revell - 2021 - Computer-Assisted Pronunciation Training (CAPT) Current Issues and Future Directions.pdf
      \endverb
      \verb{urlraw}
      \verb https://journals.sagepub.com/doi/10.1177/0033688220977406
      \endverb
      \verb{url}
      \verb https://journals.sagepub.com/doi/10.1177/0033688220977406
      \endverb
    \endentry
    \entry{rosenblumSpeechPerceptionMultimodal2008}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=6990b24deadc93e1bf527ae1841c8926}{%
           family={Rosenblum},
           familyi={R\bibinitperiod},
           given={Lawrence\bibnamedelima D.},
           giveni={L\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{6990b24deadc93e1bf527ae1841c8926}
      \strng{fullhash}{6990b24deadc93e1bf527ae1841c8926}
      \strng{bibnamehash}{6990b24deadc93e1bf527ae1841c8926}
      \strng{authorbibnamehash}{6990b24deadc93e1bf527ae1841c8926}
      \strng{authornamehash}{6990b24deadc93e1bf527ae1841c8926}
      \strng{authorfullhash}{6990b24deadc93e1bf527ae1841c8926}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Speech perception is inherently multimodal. Visual speech (lip-reading) information is used by all perceivers and readily integrates with auditory speech. Imaging research suggests that the brain treats auditory and visual speech similarly. These findings have led some researchers to consider that speech perception works by extracting amodal information that takes the same form across modalities. From this perspective, speech integration is a property of the input information itself. Amodal speech information could explain the reported automaticity, immediacy, and completeness of audiovisual speech integration. However, recent findings suggest that speech integration can be influenced by higher cognitive properties such as lexical status and semantic context. Proponents of amodal accounts will need to explain these results.}
      \field{issn}{0963-7214, 1467-8721}
      \field{journaltitle}{Current Directions in Psychological Science}
      \field{langid}{english}
      \field{month}{12}
      \field{number}{6}
      \field{shortjournal}{Curr Dir Psychol Sci}
      \field{title}{Speech {{Perception}} as a {{Multimodal Phenomenon}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{17}
      \field{year}{2008}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{405\bibrangedash 409}
      \range{pages}{5}
      \verb{doi}
      \verb 10.1111/j.1467-8721.2008.00615.x
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/HA5WE24Z/Rosenblum - 2008 - Speech Perception as a Multimodal Phenomenon.pdf
      \endverb
      \verb{urlraw}
      \verb https://journals.sagepub.com/doi/10.1111/j.1467-8721.2008.00615.x
      \endverb
      \verb{url}
      \verb https://journals.sagepub.com/doi/10.1111/j.1467-8721.2008.00615.x
      \endverb
    \endentry
    \entry{rouditchenkoComparisonMultilingualSelfSupervised2023}{inproceedings}{}
      \name{author}{9}{}{%
        {{un=0,uniquepart=base,hash=4061fbecb11a224923e0caad26faf56d}{%
           family={Rouditchenko},
           familyi={R\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7ed1ec7bfbb89b56b1e64e1b48efdaa6}{%
           family={Khurana},
           familyi={K\bibinitperiod},
           given={Sameer},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0a327007a0b097a2d8bfa1b4eb2086d1}{%
           family={Thomas},
           familyi={T\bibinitperiod},
           given={Samuel},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b28550979e1f46d5c67bcd9212bab845}{%
           family={Feris},
           familyi={F\bibinitperiod},
           given={Rogerio},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f946c74905bbd1310ba1609f93e47413}{%
           family={Karlinsky},
           familyi={K\bibinitperiod},
           given={Leonid},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=abbb2b3478036776ebfd1dec522c0091}{%
           family={Kuehne},
           familyi={K\bibinitperiod},
           given={Hilde},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0bd189af57105df4f4e2d749c815bf13}{%
           family={Harwath},
           familyi={H\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8f101126b3acf3a5a0f51d86f0fe89b8}{%
           family={Kingsbury},
           familyi={K\bibinitperiod},
           given={Brian},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=079738ec97fefceec5036d7c3657c667}{%
           family={Glass},
           familyi={G\bibinitperiod},
           given={James},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{b9405e31b90fba6482be163bac61d85d}
      \strng{fullhash}{77888588c7a00e13891af165ac8c3e88}
      \strng{bibnamehash}{77888588c7a00e13891af165ac8c3e88}
      \strng{authorbibnamehash}{77888588c7a00e13891af165ac8c3e88}
      \strng{authornamehash}{b9405e31b90fba6482be163bac61d85d}
      \strng{authorfullhash}{77888588c7a00e13891af165ac8c3e88}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recent models such as XLS-R and Whisper have made multilingual speech technologies more accessible by pre-training on audio from around 100 spoken languages each. However, there are thousands of spoken languages worldwide, and adapting to new languages is an important problem. In this work, we aim to understand which model adapts better to languages unseen during pre-training. We fine-tune both models on 13 unseen languages and 18 seen languages. Our results show that the number of hours seen per language and language family during pre-training is predictive of how the models compare, despite the significant differences in the pre-training methods.}
      \field{booktitle}{{{INTERSPEECH}} 2023}
      \field{day}{20}
      \field{eventtitle}{{{INTERSPEECH}} 2023}
      \field{langid}{english}
      \field{month}{8}
      \field{title}{Comparison of {{Multilingual Self-Supervised}} and {{Weakly-Supervised Speech Pre-Training}} for {{Adaptation}} to {{Unseen Languages}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2023}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2268\bibrangedash 2272}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2023-1061
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/SYX7C589/Rouditchenko et al. - 2023 - Comparison of Multilingual Self-Supervised and Weakly-Supervised Speech Pre-Training for Adaptation.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2023/rouditchenko23_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2023/rouditchenko23_interspeech.html
      \endverb
    \endentry
    \entry{saitoEffectsSecondLanguage2019}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=7096616a27b3c2eb708fe1e6ed731268}{%
           family={Saito},
           familyi={S\bibinitperiod},
           given={Kazuya},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d1610f0d8ba2325db96b39b1d7cc8fe5}{%
           family={Plonsky},
           familyi={P\bibinitperiod},
           given={Luke},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8281c1265039d85b3b51f9ba45225fdf}
      \strng{fullhash}{8281c1265039d85b3b51f9ba45225fdf}
      \strng{bibnamehash}{8281c1265039d85b3b51f9ba45225fdf}
      \strng{authorbibnamehash}{8281c1265039d85b3b51f9ba45225fdf}
      \strng{authornamehash}{8281c1265039d85b3b51f9ba45225fdf}
      \strng{authorfullhash}{8281c1265039d85b3b51f9ba45225fdf}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{We propose a new framework for conceptualizing measures of instructed L2 pronunciation proficiency according to three sets of parameters: (a) the constructs being focused on (global vs. specific), (b) the scoring method (human raters vs. acoustic analyses), and (c) the type of knowledge being elicited (controlled vs. spontaneous). Adopting the model (i.e., Framework for L2 Pronunciation Measurement) as a synthetic tool, we code the instruments found in 77 studies of L2 pronunciation teaching published between 1982 and 2017. We calculate the frequency of each measurement type and re-examine the interaction of instructional effectiveness and measurement within the sample. According to the results, instruction is most effective when it targets learners’ monitored production of specific segmental/suprasegmental features. The efficacy of instruction remains relatively unclear when gains are measured globally via subjective/human judgements especially at a spontaneous level. The findings are discussed to improve the designs in L2 pronunciation research and, more generally, strengthen the interface between pronunciation teaching, measurement and SLA.}
      \field{issn}{0023-8333, 1467-9922}
      \field{journaltitle}{Language Learning}
      \field{langid}{english}
      \field{month}{9}
      \field{number}{3}
      \field{shortjournal}{Language Learning}
      \field{shorttitle}{Effects of {{Second Language Pronunciation Teaching Revisited}}}
      \field{title}{Effects of {{Second Language Pronunciation Teaching Revisited}}: {{A Proposed Measurement Framework}} and {{Meta}}‐{{Analysis}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{69}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{652\bibrangedash 708}
      \range{pages}{57}
      \verb{doi}
      \verb 10.1111/lang.12345
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/WZS99UEJ/Saito and Plonsky - 2019 - Effects of Second Language Pronunciation Teaching Revisited A Proposed Measurement Framework and Me.pdf
      \endverb
      \verb{urlraw}
      \verb https://onlinelibrary.wiley.com/doi/10.1111/lang.12345
      \endverb
      \verb{url}
      \verb https://onlinelibrary.wiley.com/doi/10.1111/lang.12345
      \endverb
    \endentry
    \entry{schmidtChapter2Attention2012}{incollection}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=cd7c519acadcb301432b0bdcaf1c1055}{%
           family={Schmidt},
           familyi={S\bibinitperiod},
           given={Richard},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{4}{}{%
        {{hash=e9f88c93976cdbfebbbf1a74d6b83bce}{%
           family={Chan},
           familyi={C\bibinitperiod},
           given={Wai\bibnamedelima Meng},
           giveni={W\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=eefe9047b32b1473660e0345f4f3994d}{%
           family={Chin},
           familyi={C\bibinitperiod},
           given={Kwee\bibnamedelima Nyet},
           giveni={K\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=af65b08b3672eb527865413087d26a02}{%
           family={Bhatt},
           familyi={B\bibinitperiod},
           given={Sunil},
           giveni={S\bibinitperiod}}}%
        {{hash=042b5e95daefb806e9ecd564d177f43a}{%
           family={Walker},
           familyi={W\bibinitperiod},
           given={Izumi},
           giveni={I\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {DE GRUYTER}%
      }
      \strng{namehash}{cd7c519acadcb301432b0bdcaf1c1055}
      \strng{fullhash}{cd7c519acadcb301432b0bdcaf1c1055}
      \strng{bibnamehash}{cd7c519acadcb301432b0bdcaf1c1055}
      \strng{authorbibnamehash}{cd7c519acadcb301432b0bdcaf1c1055}
      \strng{authornamehash}{cd7c519acadcb301432b0bdcaf1c1055}
      \strng{authorfullhash}{cd7c519acadcb301432b0bdcaf1c1055}
      \strng{editorbibnamehash}{4962fdf8198dd64d7b46acbf3e7908be}
      \strng{editornamehash}{2a8c68678f6ecd6c207709742790137e}
      \strng{editorfullhash}{4962fdf8198dd64d7b46acbf3e7908be}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Perspectives on {{Individual Characteristics}} and {{Foreign Language Education}}}
      \field{day}{13}
      \field{isbn}{978-1-61451-095-6 978-1-61451-093-2}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Chapter 2. {{Attention}}, Awareness, and Individual Differences in Language Learning}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{27\bibrangedash 50}
      \range{pages}{24}
      \verb{doi}
      \verb 10.1515/9781614510932.27
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/YN6L4LEJ/Schmidt - 2012 - Chapter 2. Attention, awareness, and individual differences in language learning.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.degruyter.com/document/doi/10.1515/9781614510932.27/html
      \endverb
      \verb{url}
      \verb https://www.degruyter.com/document/doi/10.1515/9781614510932.27/html
      \endverb
    \endentry
    \entry{shahinPhonologicalLevelMispronunciationDetection2024}{inproceedings}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=0c7156b7d12b3f54bf73144e3f8df1cb}{%
           family={Shahin},
           familyi={S\bibinitperiod},
           given={Mostafa},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=01669a796f1778a99974ace6951d8c8f}{%
           family={Ahmed},
           familyi={A\bibinitperiod},
           given={Beena},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{056bcd09ae12be14cc10fedd6d106d04}
      \strng{fullhash}{056bcd09ae12be14cc10fedd6d106d04}
      \strng{bibnamehash}{056bcd09ae12be14cc10fedd6d106d04}
      \strng{authorbibnamehash}{056bcd09ae12be14cc10fedd6d106d04}
      \strng{authornamehash}{056bcd09ae12be14cc10fedd6d106d04}
      \strng{authorfullhash}{056bcd09ae12be14cc10fedd6d106d04}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The automatic identification and analysis of pronunciation errors, known as mispronunciation detection and diagnosis (MDD), is vital in computer-aided pronunciation learning (CAPL) tools for second-language (L2) learning. Existing MDD methods focus on analyzing phonemes, but they can only detect categorical errors for phonemes with sufficient training data. Due to the unpredictable nature of non-native speakers’ pronunciation errors and limited training datasets, modelling all mispronunciations becomes impractical. Additionally, phoneme-level MDD approaches provide limited diagnostic information. In our proposed approach, we detect phonological features, breaking down phoneme production into elementary components related to the articulatory system, offering more informative feedback to learners. Applied to L2 English speech data, it outperformed traditional phoneme-level methods, reducing false acceptance rate (FAR), false rejection rate (FRR), and diagnostic error rate (DER).}
      \field{booktitle}{Interspeech 2024}
      \field{day}{1}
      \field{eventtitle}{Interspeech 2024}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Phonological-{{Level Mispronunciation Detection}} and {{Diagnosis}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2024}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{307\bibrangedash 311}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2024-2217
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/F4SEIXYG/Shahin and Ahmed - 2024 - Phonological-Level Mispronunciation Detection and Diagnosis.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2024/shahin24_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2024/shahin24_interspeech.html
      \endverb
    \endentry
    \entry{sheenCorrectiveFeedbackLearner2004}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=c83df9ba65e6158ccc757f6eff865f1c}{%
           family={Sheen},
           familyi={S\bibinitperiod},
           given={YoungHee},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{c83df9ba65e6158ccc757f6eff865f1c}
      \strng{fullhash}{c83df9ba65e6158ccc757f6eff865f1c}
      \strng{bibnamehash}{c83df9ba65e6158ccc757f6eff865f1c}
      \strng{authorbibnamehash}{c83df9ba65e6158ccc757f6eff865f1c}
      \strng{authornamehash}{c83df9ba65e6158ccc757f6eff865f1c}
      \strng{authorfullhash}{c83df9ba65e6158ccc757f6eff865f1c}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper reports similarities and differences in teachers’ corrective feedback and learners’ uptake across instructional settings. Four communicative classroom settings - French Immersion, Canada ESL, New Zealand ESL and Korean EFL - were examined using Lyster and Ranta’s taxonomy of teachers’ corrective feedback moves and learner uptake. The results indicate that recasts were the most frequent feedback type in all four contexts but were much more frequent in the Korean EFL and New Zealand ESL classrooms (83\% and 68\%, respectively) than in the Canadian Immersion and ESL classrooms (55\% for both). Also, the rates for both uptake and repair following recasts were greater in the New Zealand and Korean settings than in the Canadian contexts. The findings of this study suggest that the extent to which recasts lead to learner uptake and repair may be greater in contexts where the focus of the recasts is more salient, as with reduced/partial recasts, and where students are oriented to attending to linguistic form rather than meaning. The study underscores the importance of considering the influence of context on corrective feedback and learner uptake.}
      \field{issn}{1362-1688, 1477-0954}
      \field{journaltitle}{Language Teaching Research}
      \field{langid}{english}
      \field{month}{7}
      \field{number}{3}
      \field{shortjournal}{Language Teaching Research}
      \field{title}{Corrective Feedback and Learner Uptake in Communicative Classrooms across Instructional Settings}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{8}
      \field{year}{2004}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{263\bibrangedash 300}
      \range{pages}{38}
      \verb{doi}
      \verb 10.1191/1362168804lr146oa
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/SW5MRK2C/Sheen - 2004 - Corrective feedback and learner uptake in communicative classrooms across instructional settings.pdf
      \endverb
      \verb{urlraw}
      \verb https://journals.sagepub.com/doi/10.1191/1362168804lr146oa
      \endverb
      \verb{url}
      \verb https://journals.sagepub.com/doi/10.1191/1362168804lr146oa
      \endverb
    \endentry
    \entry{shenNaturalTTSSynthesis2018}{online}{}
      \name{author}{13}{}{%
        {{un=0,uniquepart=base,hash=7f1a9ef81d98cf013191d02e3e5c98ce}{%
           family={Shen},
           familyi={S\bibinitperiod},
           given={Jonathan},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=79b11327e6066baac1563390e41c13f2}{%
           family={Pang},
           familyi={P\bibinitperiod},
           given={Ruoming},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=79806915dad52902a35bf2249c791110}{%
           family={Weiss},
           familyi={W\bibinitperiod},
           given={Ron\bibnamedelima J.},
           giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=29ea22df63f174ac629e9ef100b40484}{%
           family={Schuster},
           familyi={S\bibinitperiod},
           given={Mike},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5a9f30e0c0441d2aea255916ff375e8c}{%
           family={Jaitly},
           familyi={J\bibinitperiod},
           given={Navdeep},
           giveni={N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9cebeff55132aa441f26afb504ef6a29}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Zongheng},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c0d10aaf985cebf8d0497e1828f9313f}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Zhifeng},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9a4f4a1ff661cd600eb26523a5ba8bb4}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Yu},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fc399f85ccdd18f7c16d2cd99a42d132}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yuxuan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=12dfe1f59c012973b161655e19ed9754}{%
           family={Skerry-Ryan},
           familyi={S\bibinithyphendelim R\bibinitperiod},
           given={R.\bibnamedelimi J.},
           giveni={R\bibinitperiod\bibinitdelim J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7195887e1fff23cbe4d4606880c8f0da}{%
           family={Saurous},
           familyi={S\bibinitperiod},
           given={Rif\bibnamedelima A.},
           giveni={R\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ba97da1b498d9addeebed6465a90f567}{%
           family={Agiomyrgiannakis},
           familyi={A\bibinitperiod},
           given={Yannis},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1fc7a40d6072b1bb1d4e56d14ef88e2f}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Yonghui},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8d4617b05e2f79838cb66a3e3cb5d42a}
      \strng{fullhash}{6ef17f2a9192d257352423e822cee667}
      \strng{bibnamehash}{6ef17f2a9192d257352423e822cee667}
      \strng{authorbibnamehash}{6ef17f2a9192d257352423e822cee667}
      \strng{authornamehash}{8d4617b05e2f79838cb66a3e3cb5d42a}
      \strng{authorfullhash}{6ef17f2a9192d257352423e822cee667}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper describes Tacotron 2, a neural network architecture for speech synthesis directly from text. The system is composed of a recurrent sequence-to-sequence feature prediction network that maps character embeddings to mel-scale spectrograms, followed by a modified WaveNet model acting as a vocoder to synthesize time-domain waveforms from those spectrograms. Our model achieves a mean opinion score (MOS) of 4.53 comparable to a MOS of 4.58 for professionally recorded speech. To validate our design choices, we present ablation studies of key components of our system and evaluate the impact of using mel spectrograms as the conditioning input to WaveNet instead of linguistic, duration, and F0 features. We further show that using this compact acoustic intermediate representation allows for a significant reduction in the size of the WaveNet architecture.}
      \field{day}{16}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{2}
      \field{pubstate}{prepublished}
      \field{title}{Natural {{TTS Synthesis}} by {{Conditioning WaveNet}} on {{Mel Spectrogram Predictions}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.1712.05884
      \endverb
      \verb{eprint}
      \verb 1712.05884
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/LFGHGH2P/Shen et al. - 2018 - Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1712.05884
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1712.05884
      \endverb
      \keyw{Computer Science - Computation and Language}
    \endentry
    \entry{sjons2022articulation}{thesis}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=9de2927425255c2e8eb8cfe32cdb5204}{%
           family={Sjons},
           familyi={S\bibinitperiod},
           given={Johan},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {Stockholm University}%
      }
      \strng{namehash}{9de2927425255c2e8eb8cfe32cdb5204}
      \strng{fullhash}{9de2927425255c2e8eb8cfe32cdb5204}
      \strng{bibnamehash}{9de2927425255c2e8eb8cfe32cdb5204}
      \strng{authorbibnamehash}{9de2927425255c2e8eb8cfe32cdb5204}
      \strng{authornamehash}{9de2927425255c2e8eb8cfe32cdb5204}
      \strng{authorfullhash}{9de2927425255c2e8eb8cfe32cdb5204}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Articulation Rate and Surprisal in Swedish Child-Directed Speech}
      \field{type}{phdthesis}
      \field{year}{2022}
      \field{dateera}{ce}
      \verb{file}
      \verb /home/pccady/Zotero/storage/ANDVW38Q/Sjons - 2022 - Articulation rate and surprisal in swedish child-directed speech.pdf
      \endverb
    \endentry
    \entry{snesarevaPalatalizationDublinIrish2016}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=eed11c3c57e1ab35beb1d22b87f1cfc1}{%
           family={Snesareva},
           familyi={S\bibinitperiod},
           given={Marina},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{eed11c3c57e1ab35beb1d22b87f1cfc1}
      \strng{fullhash}{eed11c3c57e1ab35beb1d22b87f1cfc1}
      \strng{bibnamehash}{eed11c3c57e1ab35beb1d22b87f1cfc1}
      \strng{authorbibnamehash}{eed11c3c57e1ab35beb1d22b87f1cfc1}
      \strng{authornamehash}{eed11c3c57e1ab35beb1d22b87f1cfc1}
      \strng{authorfullhash}{eed11c3c57e1ab35beb1d22b87f1cfc1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper focuses on palatalization in Irish spoken by Dublin-based bilinguals with English as their first language. It has already been pointed out that English phonetics affects Irish speakers even when Irish is their first language, especially in case of palatalization. The extent of English influence on palatalization in Dublin Irish and the possible reasons behind its inconsistent use acquire special prominence not only in terms of phonetics, but also because in Irish palatalization performs phonological functions.}
      \field{issn}{18770428}
      \field{journaltitle}{Procedia - Social and Behavioral Sciences}
      \field{langid}{english}
      \field{month}{12}
      \field{shortjournal}{Procedia - Social and Behavioral Sciences}
      \field{shorttitle}{Palatalization in {{Dublin Irish}}}
      \field{title}{Palatalization in {{Dublin Irish}}: {{The Extent}} of {{Phonetic Interference}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{236}
      \field{year}{2016}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{213\bibrangedash 218}
      \range{pages}{6}
      \verb{doi}
      \verb 10.1016/j.sbspro.2016.12.009
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/JZPBE6KT/Snesareva - 2016 - Palatalization in Dublin Irish The Extent of Phonetic Interference.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S1877042816316421
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S1877042816316421
      \endverb
    \endentry
    \entry{stanleyImprovingL1specificPhonological2012}{inproceedings}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=b50b5bded680360b853d1d5b6d0116cb}{%
           family={Stanley},
           familyi={S\bibinitperiod},
           given={Theban},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fe07bbdd675b552857076fd97a6157a4}{%
           family={Hacioglu},
           familyi={H\bibinitperiod},
           given={Kadri},
           giveni={K\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{b462c81534c678214ec1d1ee1c0a71ef}
      \strng{fullhash}{b462c81534c678214ec1d1ee1c0a71ef}
      \strng{bibnamehash}{b462c81534c678214ec1d1ee1c0a71ef}
      \strng{authorbibnamehash}{b462c81534c678214ec1d1ee1c0a71ef}
      \strng{authornamehash}{b462c81534c678214ec1d1ee1c0a71ef}
      \strng{authorfullhash}{b462c81534c678214ec1d1ee1c0a71ef}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{With the increasing use of technology in classrooms, computer assisted pronunciation training (CAPT) is becoming a vital tool in language learning. In this paper, we present a system that takes advantage of data from learners of a specific L1 to better model phonological errors at various levels in the system. At the lexical level, a statistical machine translation approach is used to model common phonological errors produced by a specific L1 population. At the acoustic level, L1-dependent maximum likelihood (ML) nonnative models and discriminative training are explored. In our experiments, use of a Korean language dependent nonnative lexicon gives us diagnostic abilities that did not exist in our baseline configuration. Replacing the native ML acoustic model with the L1-dependent nonnative model produces relative improvements of 27–37\% in precision for phone detection/identification tasks. We also propose a constrained variant of minimum phone error (MPE) training which is better adapted to phone detection/diagnosis. This technique produces 5–6\% relative improvement in precision in comparison to ML nonnative acoustic models.}
      \field{booktitle}{Interspeech 2012}
      \field{day}{9}
      \field{eventtitle}{Interspeech 2012}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Improving {{L1-specific}} Phonological Error Diagnosis in Computer Assisted Pronunciation Training}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2012}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{827\bibrangedash 830}
      \range{pages}{4}
      \verb{doi}
      \verb 10.21437/Interspeech.2012-251
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/2S32QJ7Y/Stanley and Hacioglu - 2012 - Improving L1-specific phonological error diagnosis in computer assisted pronunciation training.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2012/stanley12_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2012/stanley12_interspeech.html
      \endverb
    \endentry
    \entry{stensonModernIrishComprehensive2020}{book}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=aeab60ee2a2aea121a5a5c961283fa1e}{%
           family={Stenson},
           familyi={S\bibinitperiod},
           given={Nancy},
           giveni={N\bibinitperiod},
           givenun=0}}%
      }
      \list{location}{1}{%
        {London ; New York}%
      }
      \list{publisher}{1}{%
        {Routledge, Taylor \& Francis}%
      }
      \strng{namehash}{aeab60ee2a2aea121a5a5c961283fa1e}
      \strng{fullhash}{aeab60ee2a2aea121a5a5c961283fa1e}
      \strng{bibnamehash}{aeab60ee2a2aea121a5a5c961283fa1e}
      \strng{authorbibnamehash}{aeab60ee2a2aea121a5a5c961283fa1e}
      \strng{authornamehash}{aeab60ee2a2aea121a5a5c961283fa1e}
      \strng{authorfullhash}{aeab60ee2a2aea121a5a5c961283fa1e}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{"Modern Irish: A Comprehensive Grammar is a complete reference guide to modern Irish grammar, providing a thorough overview of the language. Key features include: - highly systematic coverage of all levels of structure: sound system, word formation, sentence construction and connection of sentences - authentic examples and English translations which provide an accessible insight into the mechanics of the language - an extensive index, numbered sections, cross-references and summary charts which provide readers with easy access to the information. Modern Irish: A Comprehensive Grammar is an essential reference source for the learner and user of Irish. It is ideal for use in schools, colleges, universities, and adult classes of all types"--}
      \field{isbn}{978-1-138-23652-3 978-1-138-23651-6}
      \field{pagetotal}{304}
      \field{series}{Routledge Comprehensive Grammars}
      \field{shorttitle}{Modern {{Irish}}}
      \field{title}{Modern {{Irish}}: A Comprehensive Grammar}
      \field{year}{2020}
      \field{dateera}{ce}
      \keyw{Grammar,Irish language}
    \endentry
    \entry{strikComparingDifferentApproaches2009}{article}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=a872bcf73b844088551245ffed26cc56}{%
           family={Strik},
           familyi={S\bibinitperiod},
           given={Helmer},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=be97fb7cadd57f7a5a115de881c824c9}{%
           family={Truong},
           familyi={T\bibinitperiod},
           given={Khiet},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7cd5b9e836e2f027ca0adfb24cbe31c1}{%
           family={De\bibnamedelima Wet},
           familyi={D\bibinitperiod\bibinitdelim W\bibinitperiod},
           given={Febe},
           giveni={F\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6a712139715a50e15afa4f4800444e61}{%
           family={Cucchiarini},
           familyi={C\bibinitperiod},
           given={Catia},
           giveni={C\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{aca829b0bc607b38146d254cfa0197c5}
      \strng{fullhash}{6a08cc3e92fbf2c7e0368518c6b716eb}
      \strng{bibnamehash}{6a08cc3e92fbf2c7e0368518c6b716eb}
      \strng{authorbibnamehash}{6a08cc3e92fbf2c7e0368518c6b716eb}
      \strng{authornamehash}{aca829b0bc607b38146d254cfa0197c5}
      \strng{authorfullhash}{6a08cc3e92fbf2c7e0368518c6b716eb}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{One of the biggest challenges in designing computer assisted language learning (CALL) applications that provide automatic feedback on pronunciation errors consists in reliably detecting the pronunciation errors at such a detailed level that the information provided can be useful to learners. In our research we investigate pronunciation errors frequently made by foreigners learning Dutch as a second language. In the present paper we focus on the velar fricative /x/ and the velar plosive /k/. We compare four types of classifiers that can be used to detect erroneous pronunciations of these phones: two acoustic–phonetic classifiers (one of which employs Linear Discriminant Analysis (LDA)), a classifier based on cepstral coefficients in combination with LDA, and one based on confidence measures (the socalled Goodness Of Pronunciation score). The best results were obtained for the two LDA classifiers which produced accuracy levels of about 85–93\%.}
      \field{issn}{01676393}
      \field{journaltitle}{Speech Communication}
      \field{langid}{english}
      \field{month}{10}
      \field{number}{10}
      \field{shortjournal}{Speech Communication}
      \field{title}{Comparing Different Approaches for Automatic Pronunciation Error Detection}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{51}
      \field{year}{2009}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{845\bibrangedash 852}
      \range{pages}{8}
      \verb{doi}
      \verb 10.1016/j.specom.2009.05.007
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/A4ZQD7E6/Strik et al. - 2009 - Comparing different approaches for automatic pronunciation error detection.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639309000715
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639309000715
      \endverb
    \endentry
    \entry{sudhakaraImprovedGoodnessPronunciation2019}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=f36a4821643956d50d4b9505c58f0344}{%
           family={Sudhakara},
           familyi={S\bibinitperiod},
           given={Sweekar},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=94d5e460bfce3644cdff483dbbc6a223}{%
           family={Ramanathi},
           familyi={R\bibinitperiod},
           given={Manoj\bibnamedelima Kumar},
           giveni={M\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f94077dae863ce11da0aad066debe414}{%
           family={Yarra},
           familyi={Y\bibinitperiod},
           given={Chiranjeevi},
           giveni={C\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=9e67c79791f4342655524f0998195c32}{%
           family={Ghosh},
           familyi={G\bibinitperiod},
           given={Prasanta\bibnamedelima Kumar},
           giveni={P\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{e709808c7683cbfc00fe39f26697800f}
      \strng{fullhash}{25018c96d1c2b68a6f858e3191fb8eb3}
      \strng{bibnamehash}{25018c96d1c2b68a6f858e3191fb8eb3}
      \strng{authorbibnamehash}{25018c96d1c2b68a6f858e3191fb8eb3}
      \strng{authornamehash}{e709808c7683cbfc00fe39f26697800f}
      \strng{authorfullhash}{25018c96d1c2b68a6f858e3191fb8eb3}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Goodness of pronunciation (GoP) is typically formulated with Gaussian mixture model-hidden Markov model (GMM-HMM) based acoustic models considering HMM state transition probabilities (STPs) and GMM likelihoods of context dependent phonemes. On the other hand, deep neural network (DNN)HMM based acoustic models employed sub-phonemic (senone) posteriors instead of GMM likelihoods along with STPs. However, each senone is shared across many states; thus, there is no one-to-one correspondence between them. In order to circumvent this, most of the existing works have proposed modifications to the GoP formulation considering only posteriors neglecting the STPs. In this work, we derive a formulation for the GoP and it results in the formulation involving both senone posteriors and STPs. Further, we illustrate the steps to implement the proposed GoP formulation in Kaldi, a state-of-the-art automatic speech recognition toolkit. Experiments are conducted on English data collected from Indian speakers using acoustic models trained with native English data from LibriSpeech and Fisher-English corpora. The highest improvement in the correlation coefficient between the scores from the formulations and the expert ratings is found to be 14.89\% (relative) better with the proposed approach compared to the best of the existing formulations that don’t include STPs.}
      \field{booktitle}{Interspeech 2019}
      \field{day}{15}
      \field{eventtitle}{Interspeech 2019}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{An {{Improved Goodness}} of {{Pronunciation}} ({{GoP}}) {{Measure}} for {{Pronunciation Evaluation}} with {{DNN-HMM System Considering HMM Transition Probabilities}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2019}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{954\bibrangedash 958}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2019-2363
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/3K5FF3IE/Sudhakara et al. - 2019 - An Improved Goodness of Pronunciation (GoP) Measure for Pronunciation Evaluation with DNN-HMM System.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2019/sudhakara19_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2019/sudhakara19_interspeech.html
      \endverb
    \endentry
    \entry{thomsonEffectivenessL2Pronunciation2014}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=d2b8c613a1d43b06f88e81effebff62d}{%
           family={Thomson},
           familyi={T\bibinitperiod},
           given={Ron},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=155f46df0a0e1e520536d4a9bbd38b10}{%
           family={Derwing},
           familyi={D\bibinitperiod},
           given={Tracey},
           giveni={T\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{5cfdea3ec7e834a8fffb766b8a109450}
      \strng{fullhash}{5cfdea3ec7e834a8fffb766b8a109450}
      \strng{bibnamehash}{5cfdea3ec7e834a8fffb766b8a109450}
      \strng{authorbibnamehash}{5cfdea3ec7e834a8fffb766b8a109450}
      \strng{authornamehash}{5cfdea3ec7e834a8fffb766b8a109450}
      \strng{authorfullhash}{5cfdea3ec7e834a8fffb766b8a109450}
      \field{sortinit}{T}
      \field{sortinithash}{9af77f0292593c26bde9a56e688eaee9}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{Research on the efficacy of second language (L2) pronunciation instruction has produced mixed results, despite reports of significant improvement in many studies. Possible explanations for divergent outcomes include learner individual differences, goals and foci of instruction, type and duration of instructional input, and assessment procedures. After identifying key concepts, we survey 75 L2 pronunciation studies, particularly their methods and results. Despite a move towards emphasizing speech intelligibility and comprehensibility, most research surveyed promoted native-like pronunciation as the target. Although most studies entailed classroom instruction, many featured Computer Assisted Pronunciation Teaching (CAPT). Segmentals were studied more often than suprasegmentals. The amount of instruction required to effect change was related to researchers’ goals; interventions focusing on a single feature were generally shorter than those addressing more issues. Reading-aloud tasks were the most common form of assessment; very few studies measured spontaneous speech. The attribution of improvement as a result of instruction was compromised in some instances by lack of a control group. We summarize our findings, highlight limitations of current research, and offer suggestions for future directions.}
      \field{day}{8}
      \field{journaltitle}{Applied Linguistics}
      \field{month}{12}
      \field{shortjournal}{Applied Linguistics}
      \field{shorttitle}{The {{Effectiveness}} of {{L2 Pronunciation Instruction}}}
      \field{title}{The {{Effectiveness}} of {{L2 Pronunciation Instruction}}: {{A Narrative Review}}}
      \field{volume}{2014}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{pages}{1\bibrangedash 20}
      \range{pages}{20}
      \verb{doi}
      \verb 10.1093/applin/amu076
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/WY9M4BSP/Thomson and Derwing - 2014 - The Effectiveness of L2 Pronunciation Instruction A Narrative Review.pdf
      \endverb
    \endentry
    \entry{vanpatten2007theories}{book}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=5dad7fd42138609b19f1e534ea10744b}{%
           family={VanPatten},
           familyi={V\bibinitperiod},
           given={Bill},
           giveni={B\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{5dad7fd42138609b19f1e534ea10744b}
      \strng{fullhash}{5dad7fd42138609b19f1e534ea10744b}
      \strng{bibnamehash}{5dad7fd42138609b19f1e534ea10744b}
      \strng{authorbibnamehash}{5dad7fd42138609b19f1e534ea10744b}
      \strng{authornamehash}{5dad7fd42138609b19f1e534ea10744b}
      \strng{authorfullhash}{5dad7fd42138609b19f1e534ea10744b}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Theories in Second Language Acquisition}
      \verb{file}
      \verb /home/pccady/Zotero/storage/UF4M8DVL/VanPatten - Theories in second language acquisition.pdf
      \endverb
    \endentry
    \entry{volodina2016proceedings}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=3e4e0bd253c6fa903192501cd0db5859}{%
           family={Volodina},
           familyi={V\bibinitperiod},
           given={Elena},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2a961b4774dbd28c16b95bdbc43eaec0}{%
           family={Grigonytė},
           familyi={G\bibinitperiod},
           given={Gintarė},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=20f6c2c4a1bb76224136d4a806557939}{%
           family={Pilán},
           familyi={P\bibinitperiod},
           given={Ildikó},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=eb69ffbbaaa0a49a23deba128ec8a533}{%
           family={Björkenstam},
           familyi={B\bibinitperiod},
           given={Kristina\bibnamedelima Nilsson},
           giveni={K\bibinitperiod\bibinitdelim N\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=988b6ed52c15071707763c22ddb001ef}{%
           family={Borin},
           familyi={B\bibinitperiod},
           given={Lars},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{7a4f1e27dd5d038aeeeaa9517e108a86}
      \strng{fullhash}{c0d2d14e951cbc20b84098836017e150}
      \strng{bibnamehash}{c0d2d14e951cbc20b84098836017e150}
      \strng{authorbibnamehash}{c0d2d14e951cbc20b84098836017e150}
      \strng{authornamehash}{7a4f1e27dd5d038aeeeaa9517e108a86}
      \strng{authorfullhash}{c0d2d14e951cbc20b84098836017e150}
      \field{sortinit}{V}
      \field{sortinithash}{afb52128e5b4dc4b843768c0113d673b}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proceedings of the Joint Workshop on {{NLP}} for Computer Assisted Language Learning and {{NLP}} for Language Acquisition}
      \field{title}{Proceedings of the Joint Workshop on {{NLP}} for Computer Assisted Language Learning and {{NLP}} for Language Acquisition}
      \field{year}{2016}
      \field{dateera}{ce}
      \verb{file}
      \verb /home/pccady/Zotero/storage/W76J2LTZ/Volodina et al. - 2016 - Proceedings of the joint workshop on NLP for computer assisted language learning and NLP for languag.pdf
      \endverb
    \endentry
    \entry{weiMitigatingNeuralNetwork2022}{online}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=f84c52f1e3ed1b39d62e9f34cd8514e7}{%
           family={Wei},
           familyi={W\bibinitperiod},
           given={Hongxin},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=785343510b882973c9054a0580f9787a}{%
           family={Xie},
           familyi={X\bibinitperiod},
           given={Renchunzi},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f72448b448f784a30f7d333a8eee90be}{%
           family={Cheng},
           familyi={C\bibinitperiod},
           given={Hao},
           giveni={H\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=982000f6b712816d06ad05fb231cb6db}{%
           family={Feng},
           familyi={F\bibinitperiod},
           given={Lei},
           giveni={L\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=96a30a4deee57f534cac5fa8cea3ae4f}{%
           family={An},
           familyi={A\bibinitperiod},
           given={Bo},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=06f816641758a5f532df3e6f297cfc97}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Yixuan},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{b85b71eca7bf23095a3d52a82a6e027b}
      \strng{fullhash}{8b0678dd2fb33425141c9cce4116e469}
      \strng{bibnamehash}{8b0678dd2fb33425141c9cce4116e469}
      \strng{authorbibnamehash}{8b0678dd2fb33425141c9cce4116e469}
      \strng{authornamehash}{b85b71eca7bf23095a3d52a82a6e027b}
      \strng{authorfullhash}{8b0678dd2fb33425141c9cce4116e469}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Detecting out-of-distribution inputs is critical for the safe deployment of machine learning models in the real world. However, neural networks are known to suffer from the overconfidence issue, where they produce abnormally high confidence for both in- and out-of-distribution inputs. In this work, we show that this issue can be mitigated through Logit Normalization (LogitNorm)—a simple fix to the cross-entropy loss—by enforcing a constant vector norm on the logits in training. Our method is motivated by the analysis that the norm of the logit keeps increasing during training, leading to overconfident output. Our key idea behind LogitNorm is thus to decouple the influence of output’s norm during network optimization. Trained with LogitNorm, neural networks produce highly distinguishable confidence scores between in- and out-of-distribution data. Extensive experiments demonstrate the superiority of LogitNorm, reducing the average FPR95 by up to 42.30\% on common benchmarks.}
      \field{day}{24}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{6}
      \field{pubstate}{prepublished}
      \field{title}{Mitigating {{Neural Network Overconfidence}} with {{Logit Normalization}}}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2205.09310
      \endverb
      \verb{eprint}
      \verb 2205.09310
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/DJ8YF4ZJ/Wei et al. - 2022 - Mitigating Neural Network Overconfidence with Logit Normalization.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2205.09310
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2205.09310
      \endverb
      \keyw{Computer Science - Machine Learning}
    \endentry
    \entry{wittPhonelevelPronunciationScoring2000}{article}{}
      \name{author}{2}{}{%
        {{un=1,uniquepart=given,hash=eb8598065a3986294697bcd1374ba8e9}{%
           family={Witt},
           familyi={W\bibinitperiod},
           given={S.M},
           giveni={S\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=a2e82d07331f4acd94f2fc333219f56f}{%
           family={Young},
           familyi={Y\bibinitperiod},
           given={S.J},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8e264d2d03bc3dbe83d02b7fd8b8494f}
      \strng{fullhash}{8e264d2d03bc3dbe83d02b7fd8b8494f}
      \strng{bibnamehash}{8e264d2d03bc3dbe83d02b7fd8b8494f}
      \strng{authorbibnamehash}{8e264d2d03bc3dbe83d02b7fd8b8494f}
      \strng{authornamehash}{8e264d2d03bc3dbe83d02b7fd8b8494f}
      \strng{authorfullhash}{8e264d2d03bc3dbe83d02b7fd8b8494f}
      \field{extraname}{1}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper investigates a method of automatic pronunciation scoring for use in computer-assisted language learning (CALL) systems. The method utilises a likelihood-based `Goodness of Pronunciation' (GOP) measure which is extended to include individual thresholds for each phone based on both averaged native conÆdence scores and on rejection statistics provided by human judges. Further improvements are obtained by incorporating models of the subject’s native language and by augmenting the recognition networks to include expected pronunciation errors. The various GOP measures are assessed using a specially recorded database of non-native speakers which has been annotated to mark phone-level pronunciation errors. Since pronunciation assessment is highly subjective, a set of four performance measures has been designed, each of them measuring di erent aspects of how well computer-derived phone-level scores agree with human scores. These performance measures are used to cross-validate the reference annotations and to assess the basic GOP algorithm and its reÆnements. The experimental results suggest that a likelihood-based pronunciation scoring metric can achieve usable performance, especially after applying the various enhancements. ” 2000 Elsevier Science B.V. All rights reserved.}
      \field{issn}{01676393}
      \field{journaltitle}{Speech Communication}
      \field{langid}{english}
      \field{month}{2}
      \field{number}{2--3}
      \field{shortjournal}{Speech Communication}
      \field{title}{Phone-Level Pronunciation Scoring and Assessment for Interactive Language Learning}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{volume}{30}
      \field{year}{2000}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{95\bibrangedash 108}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1016/S0167-6393(99)00044-8
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/KF2BIY5D/Witt and Young - 2000 - Phone-level pronunciation scoring and assessment for interactive language learning.pdf
      \endverb
      \verb{urlraw}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639399000448
      \endverb
      \verb{url}
      \verb https://linkinghub.elsevier.com/retrieve/pii/S0167639399000448
      \endverb
    \endentry
    \entry{witt2014computer}{incollection}{}
      \name{author}{2}{}{%
        {{un=1,uniquepart=given,hash=9cfeed3b7403bbe850575db8230ebcf1}{%
           family={Witt},
           familyi={W\bibinitperiod},
           given={Silke},
           giveni={S\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=4e4fb887c4c9f76e33e3eb48bbe7a7d6}{%
           family={Young},
           familyi={Y\bibinitperiod},
           given={Steve},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {Routledge}%
      }
      \strng{namehash}{93db4fc1823c77a38c3e152fd7ac7adf}
      \strng{fullhash}{93db4fc1823c77a38c3e152fd7ac7adf}
      \strng{bibnamehash}{93db4fc1823c77a38c3e152fd7ac7adf}
      \strng{authorbibnamehash}{93db4fc1823c77a38c3e152fd7ac7adf}
      \strng{authornamehash}{93db4fc1823c77a38c3e152fd7ac7adf}
      \strng{authorfullhash}{93db4fc1823c77a38c3e152fd7ac7adf}
      \field{extraname}{2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Language Teaching and Language Technology}
      \field{title}{Computer-Assisted Pronunciation Teaching Based on Automatic Speech Recognition}
      \field{year}{2014}
      \field{dateera}{ce}
      \field{pages}{25\bibrangedash 35}
      \range{pages}{11}
      \verb{file}
      \verb /home/pccady/Zotero/storage/T7GISXBL/Witt and Young - 2014 - Computer-assisted pronunciation teaching based on automatic speech recognition.pdf
      \endverb
    \endentry
    \entry{wittAutomaticErrorDetection}{article}{}
      \name{author}{1}{}{%
        {{un=1,uniquepart=given,hash=8771981b917eebb0673ebba6c1fb8465}{%
           family={Witt},
           familyi={W\bibinitperiod},
           given={Silke\bibnamedelima M},
           giveni={S\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=1}}%
      }
      \strng{namehash}{8771981b917eebb0673ebba6c1fb8465}
      \strng{fullhash}{8771981b917eebb0673ebba6c1fb8465}
      \strng{bibnamehash}{8771981b917eebb0673ebba6c1fb8465}
      \strng{authorbibnamehash}{8771981b917eebb0673ebba6c1fb8465}
      \strng{authornamehash}{8771981b917eebb0673ebba6c1fb8465}
      \strng{authorfullhash}{8771981b917eebb0673ebba6c1fb8465}
      \field{extraname}{1}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{labeldatesource}{nodate}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper discusses the state of the art of research in computer assisted pronunciation teaching as of early 2012. A discussion of all major components contributing to pronunciation assessment is presented. This is followed by a summary of existing research to date. Additionally, an overview is given on the use of this research in commercial language learning software. This is followed by a discussion of remaining challenges and possible directions of future research.}
      \field{langid}{english}
      \field{title}{Automatic {{Error Detection}} in {{Pronunciation Training}}: {{Where}} We Are and Where We Need to Go}
      \verb{file}
      \verb /home/pccady/Zotero/storage/LI6LMXJY/Witt - Automatic Error Detection in Pronunciation Training Where we are and where we need to go.pdf
      \endverb
    \endentry
    \entry{witt2000use}{thesis}{}
      \name{author}{1}{}{%
        {{un=1,uniquepart=given,hash=fb013fd0e9521b94f0aa97654431bb58}{%
           family={Witt},
           familyi={W\bibinitperiod},
           given={Silke\bibnamedelima Maren},
           giveni={S\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=1}}%
      }
      \strng{namehash}{fb013fd0e9521b94f0aa97654431bb58}
      \strng{fullhash}{fb013fd0e9521b94f0aa97654431bb58}
      \strng{bibnamehash}{fb013fd0e9521b94f0aa97654431bb58}
      \strng{authorbibnamehash}{fb013fd0e9521b94f0aa97654431bb58}
      \strng{authornamehash}{fb013fd0e9521b94f0aa97654431bb58}
      \strng{authorfullhash}{fb013fd0e9521b94f0aa97654431bb58}
      \field{extraname}{2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Use of Speech Recognition in Computer-Assisted Language Learning.}
      \field{type}{phdthesis}
      \field{year}{2000}
      \field{dateera}{ce}
      \verb{file}
      \verb /home/pccady/Zotero/storage/ZR5EB4JA/Witt - 2000 - Use of speech recognition in computer-assisted language learning..pdf
      \endverb
    \endentry
    \entry{wuTransformerBasedEndtoEnd2021}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=0,uniquepart=base,hash=2c032fffcaf61913e652860509600f1d}{%
           family={Wu},
           familyi={W\bibinitperiod},
           given={Minglin},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7112bd5b38def4a55168243f6bc5e41b}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Kun},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=f60eaedf0859f064e3be6c223474f4ad}{%
           family={Leung},
           familyi={L\bibinitperiod},
           given={Wai-Kim},
           giveni={W\bibinithyphendelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8659b27d7c10074faa44f75f234ade20}{%
           family={Meng},
           familyi={M\bibinitperiod},
           given={Helen},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{805773564618653aaf480740d0cae8e3}
      \strng{fullhash}{26d13fbdb997a861a2683f740627b1d2}
      \strng{bibnamehash}{26d13fbdb997a861a2683f740627b1d2}
      \strng{authorbibnamehash}{26d13fbdb997a861a2683f740627b1d2}
      \strng{authornamehash}{805773564618653aaf480740d0cae8e3}
      \strng{authorfullhash}{26d13fbdb997a861a2683f740627b1d2}
      \field{sortinit}{W}
      \field{sortinithash}{4315d78024d0cea9b57a0c6f0e35ed0d}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper introduces two Transformer-based architectures for Mispronunciation Detection and Diagnosis (MDD). The first Transformer architecture (T-1) is a standard setup with an encoder, a decoder, a projection part and the Cross Entropy (CE) loss. T-1 takes in Mel-Frequency Cepstral Coefficients (MFCC) as input. The second architecture (T-2) is based on wav2vec 2.0, a pretraining framework. T-2 is composed of a CNN feature encoder, several Transformer blocks capturing contextual speech representations, a projection part and the Connectionist Temporal Classification (CTC) loss. Unlike T-1, T-2 takes in raw audio data as input. Both models are trained in an end-to-end manner. Experiments are conducted on the CU-CHLOE corpus, where T-1 achieves a Phone Error Rate (PER) of 8.69\% and F-measure of 77.23\%; and T-2 achieves a PER of 5.97\% and F-measure of 80.98\%. Both models significantly outperform the previously proposed AGPM and CNN-RNN-CTC models, with PERs at 11.1\% and 12.1\% respectively, and F-measures at 72.61\% and 74.65\% respectively.}
      \field{booktitle}{Interspeech 2021}
      \field{day}{30}
      \field{eventtitle}{Interspeech 2021}
      \field{langid}{english}
      \field{month}{8}
      \field{title}{Transformer {{Based End-to-End Mispronunciation Detection}} and {{Diagnosis}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{3954\bibrangedash 3958}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2021-1467
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/NDHLED7D/Wu et al. - 2021 - Transformer Based End-to-End Mispronunciation Detection and Diagnosis.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2021/wu21h_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2021/wu21h_interspeech.html
      \endverb
    \endentry
    \entry{xuIterativePseudoLabelingSpeech2020}{inproceedings}{}
      \name{author}{6}{}{%
        {{un=1,uniquepart=given,hash=f1f086561872e5a943563c890f3c3bef}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Qiantong},
           giveni={Q\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=ff52bf054c22b0389132223a63bdf688}{%
           family={Likhomanenko},
           familyi={L\bibinitperiod},
           given={Tatiana},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1894f466c3378a461fafebdc0915354d}{%
           family={Kahn},
           familyi={K\bibinitperiod},
           given={Jacob},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b0b92970ca8a68ab09fa412b36dbf6f3}{%
           family={Hannun},
           familyi={H\bibinitperiod},
           given={Awni},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a345e20a460089c920bb74098ed450db}{%
           family={Synnaeve},
           familyi={S\bibinitperiod},
           given={Gabriel},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=133261178beda1dc3991e0e1dfd5a791}{%
           family={Collobert},
           familyi={C\bibinitperiod},
           given={Ronan},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{2c2cd7eb5e6757498dde62da21777076}
      \strng{fullhash}{4ad66bf54f2fabf279bfa5c6f9d5d10d}
      \strng{bibnamehash}{4ad66bf54f2fabf279bfa5c6f9d5d10d}
      \strng{authorbibnamehash}{4ad66bf54f2fabf279bfa5c6f9d5d10d}
      \strng{authornamehash}{2c2cd7eb5e6757498dde62da21777076}
      \strng{authorfullhash}{4ad66bf54f2fabf279bfa5c6f9d5d10d}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Interspeech 2020}
      \field{day}{25}
      \field{eventtitle}{Interspeech 2020}
      \field{langid}{english}
      \field{month}{10}
      \field{title}{Iterative {{Pseudo-Labeling}} for {{Speech Recognition}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2020}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{1006\bibrangedash 1010}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2020-1800
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/9H4BDAHD/Xu et al. - 2020 - Iterative Pseudo-Labeling for Speech Recognition.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2020/xu20b_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2020/xu20b_interspeech.html
      \endverb
    \endentry
    \entry{xuExploreWav2vec202021}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=1,uniquepart=given,hash=735a0efe1b96f39e882754dd113acaed}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Xiaoshuo},
           giveni={X\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=7c94e42161b92c82625e88d3cc45b0c3}{%
           family={Kang},
           familyi={K\bibinitperiod},
           given={Yueteng},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0aae49ee0ebbc1cbff4221cb56d30fe7}{%
           family={Cao},
           familyi={C\bibinitperiod},
           given={Songjun},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=86728d3a00a7b01605eba98ae7c69da3}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Binghuai},
           giveni={B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cc6bf34c92d9cf6e693ab9eeadabc22c}{%
           family={Ma},
           familyi={M\bibinitperiod},
           given={Long},
           giveni={L\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{40402bf1ca43187f788bc9f51f45f796}
      \strng{fullhash}{ef98da73391b2e51fe7ee2556f1847a0}
      \strng{bibnamehash}{ef98da73391b2e51fe7ee2556f1847a0}
      \strng{authorbibnamehash}{ef98da73391b2e51fe7ee2556f1847a0}
      \strng{authornamehash}{40402bf1ca43187f788bc9f51f45f796}
      \strng{authorfullhash}{ef98da73391b2e51fe7ee2556f1847a0}
      \field{sortinit}{X}
      \field{sortinithash}{1965c258adceecf23ce3d67b05113442}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{This paper presents an initial attempt to use self-supervised learning for Mispronunciaiton Detection. Unlike existing methods that use speech recognition corpus to train models, we exploit unlabeled data and utilize a self-supervised learning technique, Wav2vec 2.0, for pretraining. After the pretraining process, the training process only requires a little pronunciationlabeled data for finetuning. Formulating Mispronunciation Detection as a binary classification task, we add convolutional and pooling layers on the top of the pretrained model to detect mispronunciations of the given prompted texts within the alignment segmentations. The training process is simple and effective. Several experiments are conducted to validate the effectiveness of the pretrained method. Our approach outperforms existing methods on a public dataset L2-ARCTIC with a F1 value of 0.610.}
      \field{booktitle}{Interspeech 2021}
      \field{day}{30}
      \field{eventtitle}{Interspeech 2021}
      \field{langid}{english}
      \field{month}{8}
      \field{title}{Explore Wav2vec 2.0 for {{Mispronunciation Detection}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4428\bibrangedash 4432}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2021-777
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/EMRXJ9JC/Xu et al. - 2021 - Explore wav2vec 2.0 for Mispronunciation Detection.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2021/xu21k_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2021/xu21k_interspeech.html
      \endverb
    \endentry
    \entry{yangImprovingMispronunciationDetection2022}{inproceedings}{}
      \name{author}{5}{}{%
        {{un=0,uniquepart=base,hash=894d24868762ea184b41b616f5ac6146}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Mu},
           giveni={M\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=229ccbc4de88b0894d6c8ccc1cc1a07d}{%
           family={Hirschi},
           familyi={H\bibinitperiod},
           given={Kevin},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=6b0ce9d2dfde9b4f5dc95ee77378fb1a}{%
           family={Looney},
           familyi={L\bibinitperiod},
           given={Stephen\bibnamedelima Daniel},
           giveni={S\bibinitperiod\bibinitdelim D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=1c4ca69976252d241408a60f35ffbe0a}{%
           family={Kang},
           familyi={K\bibinitperiod},
           given={Okim},
           giveni={O\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=c8cb2e9d80db3a476154be24112cb732}{%
           family={Hansen},
           familyi={H\bibinitperiod},
           given={John\bibnamedelima H.L.},
           giveni={J\bibinitperiod\bibinitdelim H\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{cbc37a2e398833c404c5305ff7c0e41b}
      \strng{fullhash}{bef550dec247d5e1e8905ecdef4a6acf}
      \strng{bibnamehash}{bef550dec247d5e1e8905ecdef4a6acf}
      \strng{authorbibnamehash}{bef550dec247d5e1e8905ecdef4a6acf}
      \strng{authornamehash}{cbc37a2e398833c404c5305ff7c0e41b}
      \strng{authorfullhash}{bef550dec247d5e1e8905ecdef4a6acf}
      \field{sortinit}{Y}
      \field{sortinithash}{fd67ad5a9ef0f7456bdd9aab10fe1495}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Current leading mispronunciation detection and diagnosis (MDD) systems achieve promising performance via end-to-end phoneme recognition. One challenge of such end-to-end solutions is the scarcity of human-annotated phonemes on natural L2 speech. In this work, we leverage unlabeled L2 speech via a pseudo-labeling (PL) procedure and extend the fine-tuning approach based on pre-trained self-supervised learning (SSL) models. Specifically, we use Wav2vec 2.0 as our SSL model, and fine-tune it using original labeled L2 speech samples plus the created pseudo-labeled L2 speech samples. Our pseudo labels are dynamic and are produced by an ensemble of the online model on-the-fly, which ensures that our model is robust to pseudo label noise. We show that fine-tuning with pseudo labels achieves a 5.35\% phoneme error rate reduction and 2.48\% MDD F1 score improvement over a labeled-samples-only finetuning baseline. The proposed PL method is also shown to outperform conventional offline PL methods. Compared to the state-of-the-art MDD systems, our MDD solution produces a more accurate and consistent phonetic error diagnosis. In addition, we conduct an open test on a separate UTD-4Accents dataset, where our system recognition outputs show a strong correlation with human perception, based on accentedness and intelligibility.}
      \field{booktitle}{Interspeech 2022}
      \field{day}{18}
      \field{eventtitle}{Interspeech 2022}
      \field{langid}{english}
      \field{month}{9}
      \field{title}{Improving {{Mispronunciation Detection}} with {{Wav2vec2-based Momentum Pseudo-Labeling}} for {{Accentedness}} and {{Intelligibility Assessment}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4481\bibrangedash 4485}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2022-11039
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/YKI5Y5R7/Yang et al. - 2022 - Improving Mispronunciation Detection with Wav2vec2-based Momentum Pseudo-Labeling for Accentedness a.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2022/yang22v_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2022/yang22v_interspeech.html
      \endverb
    \endentry
    \entry{zeyerWhyDoesCTC2021}{online}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=39a3c2f529d907699f9fa20711e1dac9}{%
           family={Zeyer},
           familyi={Z\bibinitperiod},
           given={Albert},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=b9c2eaa2f0f77590a890988afefaf75b}{%
           family={Schlüter},
           familyi={S\bibinitperiod},
           given={Ralf},
           giveni={R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cf68a4c2b64db77cc898cdc9fbdeb0c4}{%
           family={Ney},
           familyi={N\bibinitperiod},
           given={Hermann},
           giveni={H\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e7e53c35217607a8aa392a5dd0dd78e9}
      \strng{fullhash}{93cb6a2a36b8ab6cdfa077f3eafee16b}
      \strng{bibnamehash}{93cb6a2a36b8ab6cdfa077f3eafee16b}
      \strng{authorbibnamehash}{93cb6a2a36b8ab6cdfa077f3eafee16b}
      \strng{authornamehash}{e7e53c35217607a8aa392a5dd0dd78e9}
      \strng{authorfullhash}{93cb6a2a36b8ab6cdfa077f3eafee16b}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The peaky behavior of CTC models is well known experimentally. However, an understanding about why peaky behavior occurs is missing, and whether this is a good property. We provide a formal analysis of the peaky behavior and gradient descent convergence properties of the CTC loss and related training criteria. Our analysis provides a deep understanding why peaky behavior occurs and when it is suboptimal. On a simple example which should be trivial to learn for any model, we prove that a feed-forward neural network trained with CTC from uniform initialization converges towards peaky behavior with a 100\% error rate. Our analysis further explains why CTC only works well together with the blank label. We further demonstrate that peaky behavior does not occur on other related losses including a label prior model, and that this improves convergence.}
      \field{day}{3}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{6}
      \field{pubstate}{prepublished}
      \field{title}{Why Does {{CTC}} Result in Peaky Behavior?}
      \field{urlday}{16}
      \field{urlmonth}{6}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2105.14849
      \endverb
      \verb{eprint}
      \verb 2105.14849
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/4ZZED8DN/Zeyer et al. - 2021 - Why does CTC result in peaky behavior.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2105.14849
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2105.14849
      \endverb
      \keyw{Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing,Mathematics - Statistics Theory,Statistics - Statistics Theory}
    \endentry
    \entry{zhangL2GENNeuralPhoneme2022}{inproceedings}{}
      \name{author}{4}{}{%
        {{un=1,uniquepart=given,hash=b48f4b3efffa9842e785d9b8414e08a1}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=5549973af41d7b156b09a6f0257c6d38}{%
           family={Ganesan},
           familyi={G\bibinitperiod},
           given={Ashwinkumar},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=03ffbb2f4e7d3e052b4d4d6ac05dd699}{%
           family={Campbell},
           familyi={C\bibinitperiod},
           given={Sarah},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d6f2d5b085340bf4faa87e419694bf1f}{%
           family={Korzekwa},
           familyi={K\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{eed09720b43ab7888e4ac97cae0d3073}
      \strng{fullhash}{2a039378ed415a7473432dfc68b3f7e5}
      \strng{bibnamehash}{2a039378ed415a7473432dfc68b3f7e5}
      \strng{authorbibnamehash}{2a039378ed415a7473432dfc68b3f7e5}
      \strng{authornamehash}{eed09720b43ab7888e4ac97cae0d3073}
      \strng{authorfullhash}{2a039378ed415a7473432dfc68b3f7e5}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, we study the problem of generating mispronounced speech mimicking non-native (L2) speakers learning English as a Second Language (ESL) for the mispronunciation detection and diagnosis (MDD) task. The paper is motivated by the widely observed yet not well addressed data sparsity issue in MDD research where both L2 speech audio and its finegrained phonetic annotations are difficult to obtain, leading to unsatisfactory mispronunciation feedback accuracy. We propose L2-GEN, a new data augmentation framework to generate L2 phoneme sequences that capture realistic mispronunciation patterns by devising an unique machine translation-based sequence paraphrasing model. A novel diversified and preferenceaware decoding algorithm is proposed to generalize L2-GEN to handle both unseen words and new learner population with very limited L2 training data. A contrastive augmentation technique is further designed to optimize MDD performance improvements with the generated synthetic L2 data. We evaluate L2-GEN on public L2-ARCTIC and SpeechOcean762 datasets. The results have shown that L2-GEN leads to up to 3.9\%, and 5.0\% MDD F1-score improvements in in-domain and out-ofdomain scenarios respectively.}
      \field{booktitle}{Interspeech 2022}
      \field{day}{18}
      \field{eventtitle}{Interspeech 2022}
      \field{langid}{english}
      \field{month}{9}
      \field{shorttitle}{L2-{{GEN}}}
      \field{title}{L2-{{GEN}}: {{A Neural Phoneme Paraphrasing Approach}} to {{L2 Speech Synthesis}} for {{Mispronunciation Diagnosis}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2022}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{4317\bibrangedash 4321}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2022-209
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/WTAWKCMN/Zhang et al. - 2022 - L2-GEN A Neural Phoneme Paraphrasing Approach to L2 Speech Synthesis for Mispronunciation Diagnosis.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2022/zhang22_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2022/zhang22_interspeech.html
      \endverb
    \endentry
    \entry{zhangSpeechocean762OpenSourceNonnative2021}{online}{}
      \name{author}{9}{}{%
        {{un=1,uniquepart=given,hash=00c840ad7096e9810dfa1c382608124b}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Junbo},
           giveni={J\bibinitperiod},
           givenun=1}}%
        {{un=0,uniquepart=base,hash=13d224d3833718175fd79538c6aac650}{%
           family={Zhang},
           familyi={Z\bibinitperiod},
           given={Zhiwen},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d99a74619b2dceb2e1ed1db25d90c50e}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yongqing},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=32989ee7d8e7a646576f194c804531af}{%
           family={Yan},
           familyi={Y\bibinitperiod},
           given={Zhiyong},
           giveni={Z\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=ef915ab28d60d4cb634389aff136204d}{%
           family={Song},
           familyi={S\bibinitperiod},
           given={Qiong},
           giveni={Q\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=440327a7f8ff1aa438db8103b422624e}{%
           family={Huang},
           familyi={H\bibinitperiod},
           given={Yukai},
           giveni={Y\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=815a2cdb03036dc2884fcf0472f759cf}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Ke},
           giveni={K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=e37bd3eba929f71a8a0351899f3870d5}{%
           family={Povey},
           familyi={P\bibinitperiod},
           given={Daniel},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a44af477e42cc4d9bbc346304bdd8525}{%
           family={Wang},
           familyi={W\bibinitperiod},
           given={Yujun},
           giveni={Y\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{a90f922302ff3ab243ac14d96c978f22}
      \strng{fullhash}{5b44fb2d2f7502bd90dbb55238f5b15e}
      \strng{bibnamehash}{5b44fb2d2f7502bd90dbb55238f5b15e}
      \strng{authorbibnamehash}{5b44fb2d2f7502bd90dbb55238f5b15e}
      \strng{authornamehash}{a90f922302ff3ab243ac14d96c978f22}
      \strng{authorfullhash}{5b44fb2d2f7502bd90dbb55238f5b15e}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{This paper introduces a new open-source speech corpus named “speechocean762” designed for pronunciation assessment use, consisting of 5000 English utterances from 250 non-native speakers, where half of the speakers are children. Five experts annotated each of the utterances at sentence-level, wordlevel and phoneme-level. A baseline system is released in open source to illustrate the phoneme-level pronunciation assessment workflow on this corpus. This corpus is allowed to be used freely for commercial and non-commercial purposes. It is available for free download from OpenSLR, and the corresponding baseline system is published in the Kaldi speech recognition toolkit.}
      \field{day}{2}
      \field{eprintclass}{cs}
      \field{eprinttype}{arXiv}
      \field{langid}{english}
      \field{month}{6}
      \field{pubstate}{prepublished}
      \field{shorttitle}{Speechocean762}
      \field{title}{Speechocean762: {{An Open-Source Non-native English Speech Corpus For Pronunciation Assessment}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2021}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \verb{doi}
      \verb 10.48550/arXiv.2104.01378
      \endverb
      \verb{eprint}
      \verb 2104.01378
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/8YRR74DH/Zhang et al. - 2021 - speechocean762 An Open-Source Non-native English Speech Corpus For Pronunciation Assessment.pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/2104.01378
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/2104.01378
      \endverb
      \keyw{Computer Science - Computation and Language,Computer Science - Sound,Electrical Engineering and Systems Science - Audio and Speech Processing}
    \endentry
    \entry{zhaoL2ARCTICNonnativeEnglish2018}{inproceedings}{}
      \name{author}{7}{}{%
        {{un=0,uniquepart=base,hash=7b514c29bb94ad3f6e0f8fa6d91ddc45}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Guanlong},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=62f5ee7c50b20b10748edcc6d6b2a75a}{%
           family={Sonsaat},
           familyi={S\bibinitperiod},
           given={Sinem},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5f4d6b72078f3537a6490860e4e03440}{%
           family={Silpachai},
           familyi={S\bibinitperiod},
           given={Alif},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=aaee64873c4e7ca415346cc6dc22739a}{%
           family={Lucic},
           familyi={L\bibinitperiod},
           given={Ivana},
           giveni={I\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=8437f7c06aa97452cc3eb069268ccdb7}{%
           family={Chukharev-Hudilainen},
           familyi={C\bibinithyphendelim H\bibinitperiod},
           given={Evgeny},
           giveni={E\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=224bb0e557cdfc275a192894f9c32603}{%
           family={Levis},
           familyi={L\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=0e7c2c39d97457715a7465a75cb42fca}{%
           family={Gutierrez-Osuna},
           familyi={G\bibinithyphendelim O\bibinitperiod},
           given={Ricardo},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{1}{%
        {ISCA}%
      }
      \strng{namehash}{6a48e59200872b0f83fee47d6fd53544}
      \strng{fullhash}{f90d2448d17a714a2ed9c6c12ff9c638}
      \strng{bibnamehash}{f90d2448d17a714a2ed9c6c12ff9c638}
      \strng{authorbibnamehash}{f90d2448d17a714a2ed9c6c12ff9c638}
      \strng{authornamehash}{6a48e59200872b0f83fee47d6fd53544}
      \strng{authorfullhash}{f90d2448d17a714a2ed9c6c12ff9c638}
      \field{sortinit}{Z}
      \field{sortinithash}{96892c0b0a36bb8557c40c49813d48b3}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{shorttitle}
      \field{abstract}{In this paper, we introduce L2-ARCTIC, a speech corpus of non-native English that is intended for research in voice conversion, accent conversion, and mispronunciation detection. This initial release includes recordings from ten non-native speakers of English whose first languages (L1s) are Hindi, Korean, Mandarin, Spanish, and Arabic, each L1 containing recordings from one male and one female speaker. Each speaker recorded approximately one hour of read speech from the Carnegie Mellon University ARCTIC prompts, from which we generated orthographic and forced-aligned phonetic transcriptions. In addition, we manually annotated 150 utterances per speaker to identify three types of mispronunciation errors: substitutions, deletions, and additions, making it a valuable resource not only for research in voice conversion and accent conversion but also in computer-assisted pronunciation training. The corpus is publicly accessible at https://psi.engr.tamu.edu/l2-arctic-corpus/.}
      \field{booktitle}{Interspeech 2018}
      \field{day}{2}
      \field{eventtitle}{Interspeech 2018}
      \field{langid}{english}
      \field{month}{9}
      \field{shorttitle}{L2-{{ARCTIC}}}
      \field{title}{L2-{{ARCTIC}}: {{A Non-native English Speech Corpus}}}
      \field{urlday}{4}
      \field{urlmonth}{4}
      \field{urlyear}{2025}
      \field{year}{2018}
      \field{dateera}{ce}
      \field{urldateera}{ce}
      \field{pages}{2783\bibrangedash 2787}
      \range{pages}{5}
      \verb{doi}
      \verb 10.21437/Interspeech.2018-1110
      \endverb
      \verb{file}
      \verb /home/pccady/Zotero/storage/IFZLMRKT/Zhao et al. - 2018 - L2-ARCTIC A Non-native English Speech Corpus.pdf
      \endverb
      \verb{urlraw}
      \verb https://www.isca-archive.org/interspeech_2018/zhao18b_interspeech.html
      \endverb
      \verb{url}
      \verb https://www.isca-archive.org/interspeech_2018/zhao18b_interspeech.html
      \endverb
    \endentry
  \enddatalist
  \missing{Li2011ThePA}
  \missing{ardila2019common}
  \missing{deichler2024mm}
  \missing{garofolo1993timit}
  \missing{graves2006connectionist}
  \missing{hardison2005second}
  \missing{inter alia}
  \missing{joshi2020state}
  \missing{zhang2022l2gen}
\endrefsection
\endinput

